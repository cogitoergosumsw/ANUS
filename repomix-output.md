This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-03-10 16:24:18

# File Summary

## Purpose:

This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format:

The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
   a. A header with the file path (## File: path/to/file)
   b. The full contents of the file in a code block

## Usage Guidelines:

- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes:

- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

## Additional Information:

For more information about Repomix, visit: https://github.com/andersonby/python-repomix


# Repository Structure

```
README.md
.gitignore
tests
  README.md
CONTRIBUTING.md
examples
  README.md
instructions
  Implementation Recommendations.md
  Implementation Roadmap.md
  Planning Script.py
  anus_architecture_design.md
  Valuable Concepts.md
CODE_OF_CONDUCT.md
research
  README.md
anus
  tools
    README.md
    utility
      calculator.py
      __init__.py
    base
      tool_result.py
      tool.py
      __init__.py
      tool_collection.py
    __init__.py
  models
    README.md
    base
      base_model.py
      __init__.py
    model_router.py
    gemini_model.py
    __init__.py
    openai_model.py
  agents
    README.md
  ui
    README.md
    cli.py
    __init__.py
  core
    README.md
    memory
      long_term.py
      __init__.py
      short_term.py
      base_memory.py
    orchestrator.py
    planning
      task_planner.py
      __init__.py
      base_planner.py
    agent
      react_agent.py
      tool_agent.py
      base_agent.py
      hybrid_agent.py
      __init__.py
  __init__.py
setup.py
CHANGELOG.md
requirements.txt
assets
  anus_logo.py
  toc.md
  badges.md
LICENSE
repo.json
repomix-output.md
docs
  advanced_usage.md
  architecture_overview.md
  architecture.md
  api_reference.md
  getting_started.md
main.py
__init__.py
todo.md
```

# Repository Files


## README.md

- Characters: 18558
- Tokens: 0

````markdown
# üçë Anus: Autonomous Networked Utility System

<p align="center">
  <img src="assets/anus_logo.png" alt="Anus AI Logo" width="200"/>
</p>

<p align="center">
  <a href="https://github.com/nikmcfly/ANUS/blob/main/LICENSE"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License: MIT"></a>
  <a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.11+-blue.svg" alt="Python version"></a>
  <a href="https://github.com/psf/black"><img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Code style: black"></a>
  <a href="https://github.com/nikmcfly/ANUS/blob/main/CONTRIBUTING.md"><img src="https://img.shields.io/badge/contributions-welcome-brightgreen.svg" alt="Contributions welcome"></a>
  <br>
  <a href="https://github.com/nikmcfly/ANUS/stargazers"><img src="https://img.shields.io/github/stars/nikmcfly/ANUS.svg?style=social&label=Star" alt="GitHub stars"></a>
  <a href="https://github.com/nikmcfly/ANUS/network/members"><img src="https://img.shields.io/github/forks/nikmcfly/ANUS.svg?style=social&label=Fork" alt="GitHub forks"></a>
  <a href="https://github.com/nikmcfly/ANUS/issues"><img src="https://img.shields.io/github/issues/nikmcfly/ANUS.svg" alt="GitHub issues"></a>
  <a href="https://makeapullrequest.com"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg" alt="PRs Welcome"></a>
  <a href="https://anus-ai.github.io/docs"><img src="https://img.shields.io/badge/docs-latest-brightgreen.svg" alt="Documentation Status"></a>
  <a href="https://discord.gg/anus-ai"><img src="https://img.shields.io/discord/1234567890?color=7289da&label=Discord&logo=discord&logoColor=white" alt="Discord"></a>
</p>

## Table of Contents

- [Introduction](#-introduction)
- [Why Anus?](#-why-anus)
- [Features & Capabilities](#-features--capabilities)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Usage Examples](#-usage-examples)
- [Documentation](#-documentation)
- [Contributing](#-contributing)
- [Community](#-community)
- [License](#-license)

## üåü Introduction

**Anus** (Autonomous Networked Utility System) is a powerful, flexible, and accessible open-source AI agent framework designed to revolutionize task automation. Built with modern AI technologies and best practices, Anus represents the next generation of AI agent frameworks, offering unparalleled capabilities and ease of use.

Anus empowers users to create AI agents that can:
- Execute complex tasks through natural language instructions
- Collaborate in multi-agent environments to solve problems
- Interact with web services, documents, and code
- Process multimodal inputs including text, images, and audio
- Adapt to different domains and use cases

Whether you're a developer looking to build AI-powered applications, a researcher exploring agent-based systems, or an enthusiast interested in the latest AI technologies, Anus provides the tools and flexibility you need to succeed.

## üí° Why Anus?

- **Truly Open Source**: No barriers, no invite codes, just pure open-source goodness
- **Hybrid Architecture**: Combines single-agent simplicity with multi-agent power
- **Flexible Model Support**: Works with OpenAI models, open-source models, or your own
- **Comprehensive Tool Ecosystem**: Web automation, document processing, code execution, and more
- **Community-First Design**: Built for contributions and extensions
- **Transparent Operation**: Clear explanations of all agent actions and decisions
- **Cross-Platform**: Works across different operating systems and environments

## ‚ú® Features & Capabilities

### üß† Advanced AI Agent Architecture

- **Hybrid Agent System**: Seamlessly switch between single-agent and multi-agent modes based on task complexity
- **Dynamic Task Planning**: Sophisticated planning system that breaks down complex tasks into manageable steps
- **Adaptive Resource Allocation**: Intelligently allocates computational resources based on task requirements
- **Memory Management**: Short-term and long-term memory systems for context retention across conversations
- **Explainable Actions**: Transparent reasoning and decision-making processes

### ü§ù Multi-Agent Collaboration

- **Specialized Agent Roles**: Pre-defined roles like Researcher, Coder, Planner, and more
- **Custom Role Creation**: Define your own agent roles with specific capabilities and knowledge
- **Inter-Agent Communication**: Structured protocols for efficient agent-to-agent communication
- **Consensus Mechanisms**: Collaborative decision-making through agent voting and consensus
- **Conflict Resolution**: Sophisticated protocols for resolving disagreements between agents

### üõ†Ô∏è Comprehensive Tool Ecosystem

- **Web Interaction**:
  - Full browser automation via Playwright
  - Web scraping and data extraction
  - Form filling and submission
  - Authentication handling

- **Information Retrieval**:
  - Search engine integration
  - Wikipedia access
  - News and current events sources
  - Specialized knowledge bases

- **Document Processing**:
  - PDF parsing and analysis
  - Office document handling (Word, Excel, PowerPoint)
  - Image recognition and OCR
  - Data extraction and transformation

- **Code Execution**:
  - Secure Python execution sandbox
  - Multiple language support
  - Package management
  - Output capture and analysis

- **Multimodal Processing**:
  - Image analysis and generation
  - Audio processing and transcription
  - Video analysis and summarization
  - Chart and graph interpretation

### üîÑ Flexible Model Integration

- **OpenAI API Support**: Seamless integration with GPT-4 and newer models
- **Open-Source Models**: Support for Llama, Mistral, and other open-source models
- **Local Deployment**: Run models locally for privacy and reduced costs
- **Model Switching**: Automatically select the appropriate model based on task requirements
- **Fallback Mechanisms**: Gracefully handle API issues by switching to alternative models

### üë• User-Friendly Interfaces

- **Command-Line Interface**: Simple and intuitive commands for terminal users
- **Web Interface**: Optional browser-based dashboard for visual interaction
- **API Integration**: RESTful API for embedding Anus in other applications
- **Conversation History**: Review and continue previous conversations
- **Task Monitoring**: Track progress of long-running tasks

### üîí Privacy and Security

- **Local Execution**: Process sensitive data locally without sending to external APIs
- **API Key Management**: Secure handling of API keys and credentials
- **Permission System**: Fine-grained control over agent capabilities
- **Audit Logging**: Comprehensive logging of all agent actions
- **Sandboxed Execution**: Secure environment for running untrusted code

### üß© Extensibility

- **Plugin System**: Easily extend functionality with custom plugins
- **Custom Tools**: Create your own tools to expand agent capabilities
- **Model Adapters**: Add support for new AI models
- **Middleware**: Insert custom processing steps in the agent workflow
- **Event Hooks**: React to specific events in the agent lifecycle

## üîß Installation

Anus AI supports multiple installation methods to accommodate different user preferences and environments.

### Prerequisites

- Python 3.11 or higher
- pip (Python package installer)
- Git

### Method 1: Pip Installation (Recommended for Users)

```bash
# Install from PyPI
pip install anus-ai

# Verify installation
anus --version
```

### Method 2: From Source (Recommended for Developers)

```bash
# Clone the repository
git clone https://github.com/nikmcfly/ANUS.git
cd ANUS

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e .

# Verify installation
anus --version
```

### Method 3: Using Docker

```bash
# Pull the Docker image
docker pull anusai/anus:latest

# Run Anus in a container
docker run -it anusai/anus:latest
```

### Method 4: Using Conda

```bash
# Create a new conda environment
conda create -n anus python=3.11
conda activate anus

# Install Anus
pip install anus-ai
```

### Platform-Specific Instructions

#### Windows

```bash
# Install required system dependencies
pip install windows-curses

# If using browser automation
playwright install
```

#### macOS

```bash
# Install required system dependencies
brew install python@3.11

# If using browser automation
playwright install
```

#### Linux

```bash
# Install required system dependencies
sudo apt-get update
sudo apt-get install -y python3.11 python3.11-venv

# If using browser automation
playwright install
```

### Optional Dependencies

Anus has several optional features that require additional dependencies:

```bash
# For document processing
pip install anus-ai[documents]

# For browser automation
pip install anus-ai[browser]

# For code execution
pip install anus-ai[code]

# For all optional features
pip install anus-ai[all]
```

### Configuration

After installation, you'll need to configure Anus with your API keys:

1. Create a configuration file:

```bash
anus init
```

2. Edit the generated `.anus/config.yaml` file with your API keys:

```yaml
llm:
  provider: openai
  api_key: your_openai_api_key
  model: gpt-4o

# Optional: Configure other providers
anthropic:
  api_key: your_anthropic_api_key

# Optional: Configure tool-specific settings
browser:
  headless: true
```

## üöÄ Quick Start

Once installed, you can start using Anus right away:

```bash
# Run Anus with a simple task
anus run "Find the latest news about artificial intelligence"

# Run in interactive mode
anus interactive

# Run with a specific configuration file
anus run --config custom_config.yaml "Summarize this article: https://example.com/article"
```

## üìã Usage Examples

### Basic Examples

#### Simple Question Answering

```python
from anus import Agent

# Create a single agent
agent = Agent()

# Ask a simple question
response = agent.run("What is the capital of France?")
print(response)
```

#### Web Search

```python
from anus import Agent
from anus.tools import SearchTool

# Create an agent with search capabilities
agent = Agent(tools=[SearchTool()])

# Search for information
response = agent.run("Find the latest research on quantum computing")
print(response)
```

#### Document Analysis

```python
from anus import Agent
from anus.tools import DocumentTool

# Create an agent with document processing capabilities
agent = Agent(tools=[DocumentTool()])

# Analyze a PDF document
response = agent.run("Summarize this PDF: /path/to/document.pdf")
print(response)
```

### Advanced Examples

#### Multi-Agent Collaboration

```python
from anus import Society, Agent

# Create specialized agents
researcher = Agent(role="researcher")
analyst = Agent(role="analyst")
writer = Agent(role="writer")

# Create a society of agents
society = Society(agents=[researcher, analyst, writer])

# Execute a complex task with collaboration
response = society.run(
    "Research the impact of artificial intelligence on healthcare, " 
    "analyze the findings, and write a comprehensive report"
)
print(response)
```

#### Browser Automation

```python
from anus import Agent
from anus.tools import BrowserTool

# Create an agent with browser capabilities
agent = Agent(tools=[BrowserTool()])

# Perform a web task
response = agent.run(
    "Go to weather.com, check the weather forecast for New York City for the next 5 days, "
    "and create a summary table"
)
print(response)
```

#### Code Generation and Execution

```python
from anus import Agent
from anus.tools import CodeTool

# Create an agent with code execution capabilities
agent = Agent(tools=[CodeTool()])

# Generate and execute code
response = agent.run(
    "Create a Python script that generates a fractal tree visualization using matplotlib"
)
print(response)
```

### Command-Line Interface Examples

#### Running Tasks

```bash
# Simple information retrieval
anus run "What is the population of Tokyo?"

# Web search with specific parameters
anus run --search-depth=3 "Find recent breakthroughs in fusion energy research"

# Document processing
anus run --file=/path/to/report.pdf "Extract all financial data from this report"
```

#### Interactive Mode

```bash
# Start interactive session
anus interactive

# In interactive mode, you can have a conversation:
# > Tell me about the history of artificial intelligence
# > Now create a timeline of major AI milestones
# > Generate a visualization of this timeline
```

#### Multi-Agent Mode

```bash
# Run a complex task with multiple agents
anus run --mode=multi "Research, analyze, and summarize the current state of renewable energy technologies"

# Specify particular agent roles
anus run --mode=multi --roles=researcher,analyst,writer "Create a comprehensive market analysis for electric vehicles"
```

### API Usage

```python
from anus.api import AnusAPI

# Initialize the API client
api = AnusAPI(api_key="your_api_key")

# Send a request
response = api.process_task(
    task="Generate a business plan for a sustainable fashion startup",
    mode="multi",
    output_format="markdown"
)

# Print or save the response
print(response.result)
with open("business_plan.md", "w") as f:
    f.write(response.result)
```

### Advanced Configuration

```python
from anus import Agent, Config

# Create a custom configuration
config = Config(
    llm={
        "provider": "anthropic",
        "model": "claude-3-opus",
        "temperature": 0.7,
    },
    memory={
        "type": "persistent",
        "path": "./agent_memory",
    },
    tools={
        "browser": {"headless": False},
        "code": {"sandbox": True},
    }
)

# Create an agent with custom configuration
agent = Agent(config=config)

# Run a task
response = agent.run("Create an interactive data visualization for climate change data")
print(response)
```

## üìö Documentation

For detailed documentation, visit our [Documentation Site](https://anus-ai.github.io/docs).

- [Installation Guide](https://anus-ai.github.io/docs/installation)
- [Getting Started](https://anus-ai.github.io/docs/getting-started)
- [Architecture Overview](https://anus-ai.github.io/docs/architecture)
- [API Reference](https://anus-ai.github.io/docs/api)
- [Examples](https://anus-ai.github.io/docs/examples)
- [Contributing Guide](https://anus-ai.github.io/docs/contributing)

## üë• Contributing

We welcome contributions from the community! Anus is designed to be community-driven, and your input helps make it better for everyone.

### Ways to Contribute

- **Code Contributions**: Implement new features, fix bugs, or improve performance
- **Documentation**: Improve or expand documentation, add examples, fix typos
- **Bug Reports**: Report bugs or suggest improvements
- **Feature Requests**: Suggest new features or enhancements
- **Community Support**: Help answer questions and support other users

### Getting Started with Contributing

1. **Fork the Repository**

```bash
# Fork the repository on GitHub, then clone your fork
git clone https://github.com/your-username/anus.git
cd anus
```

2. **Set Up Development Environment**

```bash
# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install development dependencies
pip install -e ".[dev]"
```

3. **Create a Branch**

```bash
# Create a branch for your contribution
git checkout -b feature/your-feature-name
```

4. **Make Your Changes**

- Follow the code style guidelines
- Add tests for new functionality
- Update documentation as needed

5. **Run Tests**

```bash
# Run the test suite
pytest

# Run linting
flake8
mypy anus
```

6. **Submit a Pull Request**

- Push your changes to your fork
- Submit a pull request from your branch to our main branch
- Provide a clear description of the changes and any related issues

### Code Style Guidelines

- Follow [PEP 8](https://pep8.org/) for Python code style
- Use type hints for all function parameters and return values
- Write docstrings for all functions, classes, and modules
- Keep functions focused and small (under 50 lines when possible)
- Use meaningful variable and function names

### Commit Message Guidelines

We follow the [Conventional Commits](https://www.conventionalcommits.org/) specification:

```
<type>(<scope>): <description>

[optional body]

[optional footer(s)]
```

Types include:
- `feat`: A new feature
- `fix`: A bug fix
- `docs`: Documentation changes
- `style`: Code style changes (formatting, etc.)
- `refactor`: Code changes that neither fix bugs nor add features
- `test`: Adding or modifying tests
- `chore`: Changes to the build process or auxiliary tools

### Pull Request Process

1. Update the README.md or documentation with details of changes if appropriate
2. Update the CHANGELOG.md with details of changes
3. The PR should work for Python 3.11 and above
4. PRs require approval from at least one maintainer
5. Once approved, a maintainer will merge your PR

### Code of Conduct

Please note that this project is released with a [Contributor Code of Conduct](CODE_OF_CONDUCT.md). By participating in this project you agree to abide by its terms.

## üåê Community

Join our community to get help, share ideas, and contribute to the project:

- [Discord Server](https://discord.gg/anus-ai)
- [Twitter](https://twitter.com/anus_ai)
- [Reddit](https://reddit.com/r/anus_ai)

## üìù License

Anus is released under the [MIT License](LICENSE).

```
MIT License

Copyright (c) 2025 Anus AI Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
````

## .gitignore

- Characters: 3455
- Tokens: 0

```text
config.yaml

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc
```

## tests/README.md

- Characters: 671
- Tokens: 0

```markdown
# Tests

This directory contains test cases for the Anus AI agent framework.

## Unit Tests

- `test_core/`: Tests for core module components
- `test_agents/`: Tests for agent system components
- `test_tools/`: Tests for tool ecosystem components
- `test_models/`: Tests for model integration components
- `test_ui/`: Tests for user interface components

## Integration Tests

- `test_integration/`: Tests for integration between different components
- `test_end_to_end/`: End-to-end tests for complete workflows

## Benchmark Tests

- `test_benchmarks/`: Performance and capability benchmark tests
- `test_comparison/`: Comparison tests against other AI agent frameworks
```

## CONTRIBUTING.md

- Characters: 4908
- Tokens: 0

````markdown
# CONTRIBUTING.md

# Contributing to Anus AI

Thank you for your interest in contributing to Anus AI! This document provides guidelines and instructions for contributing to the project.

## Table of Contents

- [Code of Conduct](#code-of-conduct)
- [How Can I Contribute?](#how-can-i-contribute)
- [Development Setup](#development-setup)
- [Pull Request Process](#pull-request-process)
- [Coding Standards](#coding-standards)
- [Testing](#testing)
- [Documentation](#documentation)
- [Community](#community)

## Code of Conduct

This project and everyone participating in it is governed by the [Anus AI Code of Conduct](CODE_OF_CONDUCT.md). By participating, you are expected to uphold this code. Please report unacceptable behavior to the project maintainers.

## How Can I Contribute?

### Reporting Bugs

- **Ensure the bug was not already reported** by searching on GitHub under [Issues](https://github.com/anus-ai/anus/issues).
- If you're unable to find an open issue addressing the problem, [open a new one](https://github.com/anus-ai/anus/issues/new). Be sure to include a **title and clear description**, as much relevant information as possible, and a **code sample** or an **executable test case** demonstrating the expected behavior that is not occurring.

### Suggesting Enhancements

- Open a new issue with a clear title and detailed description.
- Provide specific examples and steps to demonstrate the enhancement.
- Explain why this enhancement would be useful to most Anus AI users.

### Your First Code Contribution

- Look for issues labeled "good first issue" or "help wanted" to find good starting points.
- Fork the repository and create a branch for your changes.
- Make your changes and submit a pull request.

### Pull Requests

- Fill in the required template.
- Do not include issue numbers in the PR title.
- Include screenshots and animated GIFs in your pull request whenever possible.
- Follow the coding standards.
- Document new code.
- End all files with a newline.

## Development Setup

### Prerequisites

- Python 3.11 or higher
- Git
- pip or conda

### Setting Up Your Development Environment

1. Fork the repository on GitHub.
2. Clone your fork locally:
   ```bash
   git clone https://github.com/your-username/anus.git
   cd anus
   ```

3. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

4. Install development dependencies:
   ```bash
   pip install -e ".[dev]"
   ```

5. Set up pre-commit hooks:
   ```bash
   pre-commit install
   ```

## Pull Request Process

1. Update the README.md or documentation with details of changes if appropriate.
2. Update the CHANGELOG.md with details of changes.
3. The PR should work for Python 3.11 and above.
4. PRs require approval from at least one maintainer.
5. Once approved, a maintainer will merge your PR.

## Coding Standards

### Python Style Guide

- Follow [PEP 8](https://pep8.org/) for Python code style.
- Use [Black](https://github.com/psf/black) for code formatting.
- Use [isort](https://pycqa.github.io/isort/) for import sorting.
- Use [flake8](https://flake8.pycqa.org/) for linting.
- Use [mypy](https://mypy.readthedocs.io/) for type checking.

### Type Hints

- Use type hints for all function parameters and return values.
- Use `Optional` for parameters that can be `None`.
- Use `Union` for parameters that can be multiple types.
- Use `Any` sparingly and only when necessary.

### Documentation

- Write docstrings for all functions, classes, and modules.
- Follow the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings) for docstrings.
- Keep documentation up-to-date with code changes.

### Commit Messages

We follow the [Conventional Commits](https://www.conventionalcommits.org/) specification:

```
<type>(<scope>): <description>

[optional body]

[optional footer(s)]
```

Types include:
- `feat`: A new feature
- `fix`: A bug fix
- `docs`: Documentation changes
- `style`: Code style changes (formatting, etc.)
- `refactor`: Code changes that neither fix bugs nor add features
- `test`: Adding or modifying tests
- `chore`: Changes to the build process or auxiliary tools

## Testing

- Write tests for all new features and bug fixes.
- Run the test suite before submitting a pull request:
  ```bash
  pytest
  ```
- Aim for high test coverage.
- Write both unit tests and integration tests.

## Documentation

- Update documentation for all new features and changes.
- Write clear and concise documentation.
- Include examples where appropriate.
- Check for spelling and grammar errors.

## Community

Join our community to get help, share ideas, and contribute to the project:

- [Discord Server](https://discord.gg/anus-ai)
- [Twitter](https://twitter.com/anus_ai)
- [Reddit](https://reddit.com/r/anus_ai)

Thank you for contributing to Anus AI!
````

## examples/README.md

- Characters: 858
- Tokens: 0

```markdown
# Examples

This directory contains example use cases and demonstrations of the Anus AI agent framework.

## Basic Examples

- `simple_task.py`: Demonstrates basic usage of the Anus AI agent for simple tasks.
- `web_search.py`: Shows how to use the agent for web search and information retrieval.
- `code_generation.py`: Example of using the agent for code generation and execution.

## Advanced Examples

- `multi_agent_collaboration.py`: Demonstrates the multi-agent collaboration capabilities.
- `document_processing.py`: Shows how to process and analyze documents.
- `browser_automation.py`: Example of browser automation for web tasks.

## Tutorials

- `getting_started.md`: Step-by-step tutorial for getting started with Anus AI.
- `custom_agent.md`: Guide for creating custom agent roles.
- `tool_development.md`: Tutorial for developing custom tools.
```

## instructions/Implementation Recommendations.md

- Characters: 44934
- Tokens: 0

````markdown
# Implementation Recommendations for ANUS

This document provides specific implementation recommendations for adapting valuable concepts from OpenManus into the ANUS framework. These recommendations focus on practical implementation details while respecting and enhancing ANUS's current structure.

## Core Agent System

### BaseAgent Implementation

```python
# anus/core/agent/base_agent.py

from abc import ABC, abstractmethod
from typing import List, Optional
from pydantic import BaseModel, Field

from anus.models.base_model import BaseModel as LLMModel
from anus.core.memory.base_memory import BaseMemory
from anus.core.schema import AgentState, Message

class BaseAgent(BaseModel, ABC):
    """
    Abstract base class for all ANUS agents.
    Provides foundational functionality for state management, memory, and execution.
    """
    # Core attributes
    name: str = Field(..., description="Unique name of the agent")
    description: Optional[str] = Field(None, description="Agent description")
    
    # Prompts
    system_prompt: Optional[str] = Field(None, description="System-level instruction prompt")
    next_step_prompt: Optional[str] = Field(None, description="Prompt for determining next action")
    
    # Dependencies
    llm: LLMModel = Field(default_factory=LLMModel, description="Language model instance")
    memory: BaseMemory = Field(default_factory=BaseMemory, description="Agent's memory store")
    state: AgentState = Field(default="idle", description="Current agent state")
    
    # Execution control
    max_steps: int = Field(default=15, description="Maximum steps before termination")
    current_step: int = Field(default=0, description="Current step in execution")
    
    class Config:
        arbitrary_types_allowed = True
        extra = "allow"  # Allow extra fields for flexibility in subclasses
    
    @abstractmethod
    async def step(self) -> bool:
        """
        Execute a single step of the agent's reasoning process.
        Returns True if execution should continue, False if complete.
        Must be implemented by subclasses.
        """
        pass
    
    async def run(self, request: Optional[str] = None) -> str:
        """
        Execute the agent with the given request.
        Handles initialization, step execution, and result formatting.
        """
        # Initialize execution
        self.current_step = 0
        self.state = "running"
        
        # Add request to memory if provided
        if request:
            self.memory.add_user_message(request)
        
        # Execute steps until completion or max steps reached
        result = ""
        while self.current_step < self.max_steps and self.state == "running":
            self.current_step += 1
            continue_execution = await self.step()
            
            if not continue_execution:
                self.state = "finished"
                break
        
        # Format and return result
        result = self.memory.get_assistant_response()
        return result
```

### ToolAgent Implementation

```python
# anus/core/agent/tool_agent.py

from typing import Dict, List, Optional
from pydantic import Field

from anus.core.agent.base_agent import BaseAgent
from anus.core.schema import Message, ToolCall
from anus.tools.base.tool_collection import ToolCollection

class ToolAgent(BaseAgent):
    """
    Agent with tool execution capabilities.
    Can use various tools to accomplish tasks through function calling.
    """
    # Tool-related attributes
    available_tools: ToolCollection = Field(default_factory=ToolCollection)
    tool_choice: str = Field(default="auto", description="Tool choice strategy: 'none', 'auto', or 'required'")
    tool_calls: List[ToolCall] = Field(default_factory=list)
    
    async def step(self) -> bool:
        """
        Execute a single step of the agent's reasoning process.
        Includes thinking (deciding what to do) and acting (executing tools).
        """
        # Think: Decide what to do next
        thinking_complete = await self.think()
        if not thinking_complete:
            return False
        
        # Act: Execute decided actions
        action_result = await self.act()
        
        # Check if execution should continue
        if self.state != "running":
            return False
            
        return True
    
    async def think(self) -> bool:
        """Process current state and decide next actions using tools"""
        # Add next step prompt if available
        if self.next_step_prompt:
            self.memory.add_user_message(self.next_step_prompt)
        
        # Get response with tool options
        response = await self.llm.ask_with_tools(
            messages=self.memory.get_messages(),
            system_message=self.system_prompt,
            tools=self.available_tools.to_params(),
            tool_choice=self.tool_choice,
        )
        
        # Store tool calls for execution
        self.tool_calls = response.tool_calls
        
        # Check if thinking produced any tool calls
        if not self.tool_calls and self.tool_choice == "required":
            self.memory.add_assistant_message("Failed to determine next action.")
            return False
            
        return True
    
    async def act(self) -> str:
        """Execute tool calls determined during thinking phase"""
        if not self.tool_calls:
            return ""
            
        results = []
        for tool_call in self.tool_calls:
            result = await self.execute_tool(tool_call)
            results.append(result)
            
        # Add tool results to memory
        combined_result = "\n".join(results)
        self.memory.add_system_message(f"Tool execution results:\n{combined_result}")
        
        return combined_result
    
    async def execute_tool(self, tool_call: ToolCall) -> str:
        """Execute a specific tool call"""
        tool_name = tool_call.function.name
        tool_args = tool_call.function.arguments
        
        # Check for special tools (like termination)
        if tool_name in self.special_tool_names:
            return await self._handle_special_tool(tool_name, tool_args)
        
        # Execute the tool via ToolCollection
        try:
            result = await self.available_tools.execute(name=tool_name, tool_input=tool_args)
            return f"Tool '{tool_name}' executed successfully: {result}"
        except Exception as e:
            error_msg = f"Error executing tool '{tool_name}': {str(e)}"
            return error_msg
```

### HybridAgent Implementation

```python
# anus/core/agent/hybrid_agent.py

from typing import Dict, List, Optional
from pydantic import Field

from anus.core.agent.tool_agent import ToolAgent
from anus.core.flow.consensus_flow import ConsensusFlow

class HybridAgent(ToolAgent):
    """
    Agent that can dynamically switch between single-agent and multi-agent modes
    based on task complexity and requirements.
    """
    # Multi-agent related attributes
    sub_agents: Dict[str, ToolAgent] = Field(default_factory=dict)
    collaboration_threshold: float = Field(default=0.7, description="Complexity threshold for switching modes")
    
    async def run(self, request: Optional[str] = None) -> str:
        """Execute the agent with dynamic mode selection"""
        if not request:
            return "No request provided"
            
        # Analyze task complexity
        complexity = await self._analyze_complexity(request)
        
        # Choose execution mode based on complexity
        if complexity > self.collaboration_threshold:
            return await self._run_collaborative(request)
        else:
            return await super().run(request)
    
    async def _analyze_complexity(self, request: str) -> float:
        """
        Analyze task complexity to determine execution mode.
        Returns a value between 0 and 1 representing task complexity.
        """
        # Use LLM to assess task complexity
        system_prompt = """
        You are a task complexity analyzer. Your job is to assess the complexity of a given task
        and return a score between 0 and 1, where:
        - 0-0.3: Simple tasks requiring minimal reasoning or tool use
        - 0.3-0.7: Moderate tasks requiring some reasoning and tool use
        - 0.7-1.0: Complex tasks requiring extensive reasoning, multiple tools, or specialized knowledge
        
        Analyze only the complexity, not the clarity or specificity of the request.
        Return only a numeric score between 0 and 1, with no explanation.
        """
        
        response = await self.llm.ask(
            messages=[{"role": "user", "content": request}],
            system_message=system_prompt,
            temperature=0.1,  # Low temperature for consistent assessment
        )
        
        # Extract numeric score from response
        try:
            score = float(response.content.strip())
            # Ensure score is within valid range
            return max(0.0, min(1.0, score))
        except ValueError:
            # Default to single-agent mode if parsing fails
            return 0.5
    
    async def _run_collaborative(self, request: str) -> str:
        """Execute request in collaborative multi-agent mode"""
        # Ensure sub-agents exist
        await self._ensure_sub_agents()
        
        # Create consensus flow with sub-agents
        flow = ConsensusFlow(agents=self.sub_agents)
        
        # Execute flow with request
        return await flow.execute(request)
    
    async def _ensure_sub_agents(self) -> None:
        """Create specialized sub-agents if they don't exist"""
        # Define standard roles if not already created
        standard_roles = {
            "researcher": "Specializes in information gathering and research",
            "coder": "Specializes in code writing and software development",
            "planner": "Specializes in task planning and organization",
            "critic": "Specializes in reviewing and improving solutions"
        }
        
        # Create missing sub-agents
        for role, description in standard_roles.items():
            if role not in self.sub_agents:
                # Create specialized agent with role-specific system prompt
                self.sub_agents[role] = await self._create_specialized_agent(role, description)
    
    async def _create_specialized_agent(self, role: str, description: str) -> ToolAgent:
        """Create a specialized agent for a specific role"""
        # Generate role-specific system prompt
        system_prompt = await self._generate_role_prompt(role, description)
        
        # Create agent with same tools but specialized prompt
        agent = ToolAgent(
            name=f"{self.name}_{role}",
            description=description,
            system_prompt=system_prompt,
            available_tools=self.available_tools,
            llm=self.llm,  # Use same LLM instance
        )
        
        return agent
    
    async def _generate_role_prompt(self, role: str, description: str) -> str:
        """Generate a specialized system prompt for a specific role"""
        base_prompt = f"""You are a specialized {role} agent. {description}.
        
        Focus on your specialized role while collaborating with other agents to solve complex tasks.
        Use the available tools effectively to accomplish your part of the task.
        """
        
        return base_prompt
```

## Planning System

### PlanningTool Implementation

```python
# anus/tools/planning/planning_tool.py

from typing import Dict, List, Optional
import time
import json
from pydantic import Field

from anus.tools.base.tool import BaseTool
from anus.tools.base.tool_result import ToolResult

class PlanningTool(BaseTool):
    """
    A planning tool that allows the agent to create and manage plans for solving complex tasks.
    The tool provides functionality for creating plans, updating plan steps, and tracking progress.
    """
    name: str = "planning"
    description: str = """
    Create and manage plans for solving complex tasks. Supports:
    - Creating new plans with steps
    - Updating existing plans
    - Marking steps as completed
    - Listing available plans
    - Getting plan details
    """
    
    # Storage for plans
    plans: Dict[str, Dict] = Field(default_factory=dict)
    active_plan_id: Optional[str] = None
    
    parameters: Dict = {
        "type": "object",
        "properties": {
            "command": {
                "type": "string",
                "enum": ["create", "update", "mark_step", "list", "get", "set_active", "delete"],
                "description": "The planning command to execute"
            },
            "plan_id": {
                "type": "string",
                "description": "Identifier for the plan (auto-generated if not provided)"
            },
            "title": {
                "type": "string",
                "description": "Title of the plan (for create/update)"
            },
            "steps": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of steps in the plan (for create/update)"
            },
            "step_index": {
                "type": "integer",
                "description": "Index of the step to update (for mark_step)"
            },
            "step_status": {
                "type": "string",
                "enum": ["not_started", "in_progress", "completed", "skipped"],
                "description": "Status to set for the step (for mark_step)"
            }
        },
        "required": ["command"]
    }
    
    async def execute(self, **kwargs) -> ToolResult:
        """Execute the planning tool with the given parameters"""
        command = kwargs.get("command")
        
        if command == "create":
            return self._create_plan(**kwargs)
        elif command == "update":
            return self._update_plan(**kwargs)
        elif command == "mark_step":
            return self._mark_step(**kwargs)
        elif command == "list":
            return self._list_plans()
        elif command == "get":
            return self._get_plan(kwargs.get("plan_id"))
        elif command == "set_active":
            return self._set_active_plan(kwargs.get("plan_id"))
        elif command == "delete":
            return self._delete_plan(kwargs.get("plan_id"))
        else:
            return ToolResult(
                success=False,
                message=f"Unknown planning command: {command}"
            )
    
    def _create_plan(self, **kwargs) -> ToolResult:
        """Create a new plan with the given parameters"""
        plan_id = kwargs.get("plan_id") or f"plan_{int(time.time())}"
        title = kwargs.get("title") or f"Plan {len(self.plans) + 1}"
        steps = kwargs.get("steps") or []
        
        # Create plan structure
        plan = {
            "id": plan_id,
            "title": title,
            "steps": steps,
            "step_statuses": ["not_started"] * len(steps),
            "created_at": time.time(),
            "updated_at": time.time()
        }
        
        # Store the plan
        self.plans[plan_id] = plan
        
        # Set as active plan if no active plan exists
        if not self.active_plan_id:
            self.active_plan_id = plan_id
        
        return ToolResult(
            success=True,
            message=f"Created plan '{title}' with ID {plan_id}",
            data={"plan_id": plan_id}
        )
```

### PlanningFlow Implementation

```python
# anus/core/flow/planning_flow.py

from typing import Dict, List, Optional, Tuple, Union
import time
from pydantic import Field

from anus.core.agent.base_agent import BaseAgent
from anus.core.flow.base_flow import BaseFlow
from anus.models.base_model import BaseModel as LLMModel
from anus.tools.planning.planning_tool import PlanningTool

class PlanningFlow(BaseFlow):
    """
    A flow that manages planning and execution of tasks using agents.
    Breaks down complex tasks into steps and executes them sequentially.
    """
    # Flow components
    llm: LLMModel = Field(default_factory=LLMModel)
    planning_tool: PlanningTool = Field(default_factory=PlanningTool)
    executor_keys: List[str] = Field(default_factory=list)
    
    # Plan tracking
    active_plan_id: str = Field(default_factory=lambda: f"plan_{int(time.time())}")
    current_step_index: Optional[int] = None
    
    async def execute(self, input_text: str) -> str:
        """Execute the planning flow with agents"""
        try:
            # Create initial plan if input provided
            if input_text:
                await self._create_initial_plan(input_text)
                
                # Verify plan was created successfully
                if self.active_plan_id not in self.planning_tool.plans:
                    return f"Failed to create plan for: {input_text}"
            
            result = ""
            while True:
                # Get current step to execute
                self.current_step_index, step_info = await self._get_current_step_info()
                
                # Exit if no more steps or plan completed
                if self.current_step_index is None:
                    result += await self._finalize_plan()
                    break
                
                # Execute current step with appropriate agent
                step_type = step_info.get("type") if step_info else None
                executor = self.get_executor(step_type)
                step_result = await self._execute_step(executor, step_info)
                result += step_result + "\n"
                
                # Check if agent wants to terminate
                if executor.state == "finished":
                    break
            
            return result
        except Exception as e:
            return f"Execution failed: {str(e)}"
    
    def get_executor(self, step_type: Optional[str] = None) -> BaseAgent:
        """
        Get an appropriate executor agent for the current step.
        Can be extended to select agents based on step type/requirements.
        """
        # If step type is provided and matches an agent key, use that agent
        if step_type and step_type in self.agents:
            return self.agents[step_type]
        
        # Otherwise use the first available executor or fall back to primary agent
        for key in self.executor_keys:
            if key in self.agents:
                return self.agents[key]
        
        # Fallback to primary agent
        return self.primary_agent
```

## Tool System

### BaseTool Implementation

```python
# anus/tools/base/tool.py

from abc import ABC, abstractmethod
from typing import Any, Dict, Optional
from pydantic import BaseModel, Field

class BaseTool(ABC, BaseModel):
    """
    Abstract base class for all tools in the ANUS framework.
    Provides foundation for tool definition, parameter specification, and execution.
    """
    name: str
    description: str
    parameters: Optional[Dict] = None
    
    class Config:
        arbitrary_types_allowed = True
    
    async def __call__(self, **kwargs) -> Any:
        """Execute the tool with given parameters."""
        return await self.execute(**kwargs)
    
    @abstractmethod
    async def execute(self, **kwargs) -> Any:
        """
        Execute the tool with given parameters.
        Must be implemented by subclasses.
        """
        pass
    
    def to_param(self) -> Dict:
        """Convert tool to function call format for LLM."""
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters or {
                    "type": "object",
                    "properties": {},
                }
            }
        }
```

### ToolCollection Implementation

```python
# anus/tools/base/tool_collection.py

from typing import Any, Dict, List, Optional
from anus.tools.base.tool import BaseTool
from anus.tools.base.tool_result import ToolResult, ToolFailure

class ToolCollection:
    """
    A collection of tools that can be used by agents.
    Provides unified interface for tool registration, discovery, and execution.
    """
    def __init__(self, *tools: BaseTool):
        self.tools = list(tools)
        self.tool_map = {tool.name: tool for tool in tools}
    
    def __iter__(self):
        return iter(self.tools)
    
    def add_tool(self, tool: BaseTool) -> None:
        """Add a tool to the collection"""
        self.tools.append(tool)
        self.tool_map[tool.name] = tool
    
    def remove_tool(self, tool_name: str) -> None:
        """Remove a tool from the collection"""
        if tool_name in self.tool_map:
            tool = self.tool_map.pop(tool_name)
            self.tools.remove(tool)
    
    def get_tool(self, tool_name: str) -> Optional[BaseTool]:
        """Get a tool by name"""
        return self.tool_map.get(tool_name)
    
    def to_params(self) -> List[Dict[str, Any]]:
        """Convert all tools to function call format for LLM"""
        return [tool.to_param() for tool in self.tools]
    
    async def execute(self, *, name: str, tool_input: Dict[str, Any] = None) -> ToolResult:
        """Execute a tool by name with the given input"""
        tool = self.tool_map.get(name)
        if not tool:
            return ToolFailure(error=f"Tool {name} not found")
        
        try:
            tool_input = tool_input or {}
            result = await tool(**tool_input)
            return result
        except Exception as e:
            return ToolFailure(error=f"Error executing tool {name}: {str(e)}")
```

### BrowserTool Implementation

```python
# anus/tools/web/browser_tool.py

from typing import Dict, Optional
import asyncio
from pydantic import Field

from anus.tools.base.tool import BaseTool
from anus.tools.base.tool_result import ToolResult, ToolFailure

class BrowserTool(BaseTool):
    """
    Tool for browser automation and web interaction.
    Provides capabilities for navigation, content extraction, and element interaction.
    """
    name: str = "browser"
    description: str = """
    Interact with a web browser to perform various actions such as navigation, 
    element interaction, content extraction, and tab management.
    """
    
    # Browser configuration
    headless: bool = Field(default=True, description="Whether to run browser in headless mode")
    browser_instance = None
    
    parameters: Dict = {
        "type": "object",
        "properties": {
            "action": {
                "type": "string",
                "enum": [
                    "navigate", "click", "input_text", "screenshot", 
                    "get_html", "get_text", "read_links", "execute_js",
                    "scroll", "switch_tab", "new_tab", "close_tab", "refresh"
                ],
                "description": "The browser action to perform"
            },
            "url": {
                "type": "string",
                "description": "URL to navigate to (for navigate action)"
            },
            "element_index": {
                "type": "integer",
                "description": "Index of the element to interact with (for click/input actions)"
            },
            "text": {
                "type": "string",
                "description": "Text to input (for input_text action)"
            },
            "js_code": {
                "type": "string",
                "description": "JavaScript code to execute (for execute_js action)"
            },
            "direction": {
                "type": "string",
                "enum": ["up", "down", "left", "right"],
                "description": "Scroll direction (for scroll action)"
            },
            "tab_index": {
                "type": "integer",
                "description": "Tab index to switch to (for switch_tab action)"
            }
        },
        "required": ["action"]
    }
    
    async def execute(self, **kwargs) -> ToolResult:
        """Execute the browser tool with the given parameters"""
        action = kwargs.get("action")
        
        # Initialize browser if not already initialized
        if not self.browser_instance:
            await self._initialize_browser()
        
        try:
            if action == "navigate":
                return await self._navigate(kwargs.get("url"))
            elif action == "click":
                return await self._click(kwargs.get("element_index"))
            elif action == "input_text":
                return await self._input_text(kwargs.get("element_index"), kwargs.get("text"))
            elif action == "screenshot":
                return await self._screenshot()
            elif action == "get_html":
                return await self._get_html()
            elif action == "get_text":
                return await self._get_text()
            elif action == "read_links":
                return await self._read_links()
            elif action == "execute_js":
                return await self._execute_js(kwargs.get("js_code"))
            elif action == "scroll":
                return await self._scroll(kwargs.get("direction"))
            elif action == "switch_tab":
                return await self._switch_tab(kwargs.get("tab_index"))
            elif action == "new_tab":
                return await self._new_tab()
            elif action == "close_tab":
                return await self._close_tab()
            elif action == "refresh":
                return await self._refresh()
            else:
                return ToolFailure(error=f"Unknown browser action: {action}")
        except Exception as e:
            return ToolFailure(error=f"Browser action failed: {str(e)}")
    
    async def _initialize_browser(self) -> None:
        """Initialize the browser instance"""
        # Implementation would use a browser automation library like Playwright
        # This is a placeholder for the actual implementation
        self.browser_instance = {"initialized": True}
```

## Model Integration

### BaseModel Implementation

```python
# anus/models/base_model.py

from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Union
from pydantic import BaseModel as PydanticBaseModel, Field

class Message(PydanticBaseModel):
    """Represents a message in a conversation"""
    role: str
    content: str

class ToolCall(PydanticBaseModel):
    """Represents a tool call from the model"""
    id: str
    type: str = "function"
    function: Dict

class ModelResponse(PydanticBaseModel):
    """Represents a response from a language model"""
    content: Optional[str] = None
    tool_calls: Optional[List[ToolCall]] = None

class BaseModel(PydanticBaseModel, ABC):
    """
    Abstract base class for language model integrations.
    Provides unified interface for different model providers.
    """
    provider: str = "openai"  # Default provider
    model_name: str = "gpt-4o"  # Default model
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: float = 0.0
    max_tokens: int = 4096
    
    @abstractmethod
    async def ask(
        self, 
        messages: List[Union[Dict, Message]], 
        system_message: Optional[str] = None,
        **kwargs
    ) -> ModelResponse:
        """
        Send a request to the language model and get a response.
        Basic version without tool calling.
        """
        pass
    
    @abstractmethod
    async def ask_with_tools(
        self,
        messages: List[Union[Dict, Message]],
        system_message: Optional[str] = None,
        tools: Optional[List[Dict]] = None,
        tool_choice: str = "auto",
        **kwargs
    ) -> ModelResponse:
        """
        Send a request to the language model with tools and get a response.
        Supports function/tool calling.
        """
        pass
```

### OpenAIModel Implementation

```python
# anus/models/openai_model.py

from typing import Dict, List, Optional, Union
import json
import os
from pydantic import Field

from anus.models.base_model import BaseModel, Message, ModelResponse, ToolCall

class OpenAIModel(BaseModel):
    """
    OpenAI API integration for language models.
    Supports GPT-4 and other OpenAI models.
    """
    provider: str = "openai"
    model_name: str = "gpt-4o"
    api_key: Optional[str] = Field(default_factory=lambda: os.environ.get("OPENAI_API_KEY"))
    base_url: Optional[str] = Field(default="https://api.openai.com/v1")
    
    async def ask(
        self, 
        messages: List[Union[Dict, Message]], 
        system_message: Optional[str] = None,
        **kwargs
    ) -> ModelResponse:
        """Send a request to OpenAI API and get a response"""
        import openai
        
        # Set up client
        client = openai.AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # Prepare messages
        formatted_messages = self._format_messages(messages, system_message)
        
        # Set parameters
        params = {
            "model": self.model_name,
            "messages": formatted_messages,
            "temperature": kwargs.get("temperature", self.temperature),
            "max_tokens": kwargs.get("max_tokens", self.max_tokens),
        }
        
        # Send request
        response = await client.chat.completions.create(**params)
        
        # Process response
        content = response.choices[0].message.content
        
        return ModelResponse(content=content)
    
    async def ask_with_tools(
        self,
        messages: List[Union[Dict, Message]],
        system_message: Optional[str] = None,
        tools: Optional[List[Dict]] = None,
        tool_choice: str = "auto",
        **kwargs
    ) -> ModelResponse:
        """Send a request to OpenAI API with tools and get a response"""
        import openai
        
        # Set up client
        client = openai.AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # Prepare messages
        formatted_messages = self._format_messages(messages, system_message)
        
        # Set parameters
        params = {
            "model": self.model_name,
            "messages": formatted_messages,
            "temperature": kwargs.get("temperature", self.temperature),
            "max_tokens": kwargs.get("max_tokens", self.max_tokens),
        }
        
        # Add tools if provided
        if tools:
            params["tools"] = tools
            
            # Set tool_choice based on parameter
            if tool_choice == "required":
                params["tool_choice"] = {"type": "function", "function": {"name": tools[0]["function"]["name"]}}
            elif tool_choice == "none":
                params["tool_choice"] = "none"
            else:  # "auto"
                params["tool_choice"] = "auto"
        
        # Send request
        response = await client.chat.completions.create(**params)
        
        # Process response
        message = response.choices[0].message
        content = message.content
        
        # Process tool calls if present
        tool_calls = []
        if hasattr(message, "tool_calls") and message.tool_calls:
            for tc in message.tool_calls:
                tool_calls.append(
                    ToolCall(
                        id=tc.id,
                        type="function",
                        function={
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        }
                    )
                )
        
        return ModelResponse(content=content, tool_calls=tool_calls)
    
    def _format_messages(
        self,
        messages: List[Union[Dict, Message]],
        system_message: Optional[str] = None
    ) -> List[Dict]:
        """Format messages for OpenAI API"""
        formatted_messages = []
        
        # Add system message if provided
        if system_message:
            formatted_messages.append({"role": "system", "content": system_message})
        
        # Add other messages
        for msg in messages:
            if isinstance(msg, dict):
                formatted_messages.append(msg)
            else:
                formatted_messages.append({"role": msg.role, "content": msg.content})
        
        return formatted_messages
```

## Memory System

### BaseMemory Implementation

```python
# anus/core/memory/base_memory.py

from typing import Dict, List, Optional
from pydantic import BaseModel, Field

class Message(BaseModel):
    """Represents a message in the agent's memory"""
    role: str
    content: str

class BaseMemory(BaseModel):
    """
    Base class for agent memory systems.
    Provides storage and retrieval of conversation history.
    """
    messages: List[Message] = Field(default_factory=list)
    max_messages: int = 100
    
    def add_message(self, role: str, content: str) -> None:
        """Add a message to memory"""
        self.messages.append(Message(role=role, content=content))
        
        # Trim if exceeding max messages
        if len(self.messages) > self.max_messages:
            self.messages = self.messages[-self.max_messages:]
    
    def add_user_message(self, content: str) -> None:
        """Add a user message to memory"""
        self.add_message("user", content)
    
    def add_assistant_message(self, content: str) -> None:
        """Add an assistant message to memory"""
        self.add_message("assistant", content)
    
    def add_system_message(self, content: str) -> None:
        """Add a system message to memory"""
        self.add_message("system", content)
    
    def get_messages(self) -> List[Message]:
        """Get all messages in memory"""
        return self.messages
    
    def get_last_message(self) -> Optional[Message]:
        """Get the last message in memory"""
        if not self.messages:
            return None
        return self.messages[-1]
    
    def get_assistant_response(self) -> str:
        """Get the last assistant response"""
        for msg in reversed(self.messages):
            if msg.role == "assistant":
                return msg.content
        return ""
    
    def clear(self) -> None:
        """Clear all messages from memory"""
        self.messages = []
```

### HybridMemory Implementation

```python
# anus/core/memory/hybrid_memory.py

from typing import Dict, List, Optional
import json
import os
from pydantic import Field

from anus.core.memory.base_memory import BaseMemory, Message

class HybridMemory(BaseMemory):
    """
    Hybrid memory system with both short-term and long-term storage.
    Provides persistent storage for conversations and context.
    """
    persistence: bool = Field(default=False, description="Whether to persist memory to disk")
    storage_path: Optional[str] = Field(default=None, description="Path to store persistent memory")
    
    # Long-term memory storage
    long_term_memories: Dict[str, List[Dict]] = Field(default_factory=dict)
    
    def __init__(self, **data):
        super().__init__(**data)
        
        # Set default storage path if not provided
        if self.persistence and not self.storage_path:
            self.storage_path = os.path.expanduser("~/.anus/memory")
        
        # Load persistent memory if enabled
        if self.persistence:
            self._load_persistent_memory()
    
    def add_message(self, role: str, content: str) -> None:
        """Add a message to memory and persist if enabled"""
        super().add_message(role, content)
        
        # Persist memory if enabled
        if self.persistence:
            self._save_persistent_memory()
    
    def add_to_long_term(self, category: str, data: Dict) -> None:
        """Add data to long-term memory"""
        if category not in self.long_term_memories:
            self.long_term_memories[category] = []
        
        self.long_term_memories[category].append(data)
        
        # Persist memory if enabled
        if self.persistence:
            self._save_persistent_memory()
    
    def get_from_long_term(self, category: str) -> List[Dict]:
        """Get data from long-term memory by category"""
        return self.long_term_memories.get(category, [])
    
    def search_long_term(self, category: str, query: str) -> List[Dict]:
        """Search long-term memory for relevant information"""
        # Simple keyword search implementation
        # Could be enhanced with vector search or other techniques
        results = []
        for item in self.get_from_long_term(category):
            item_str = json.dumps(item).lower()
            if query.lower() in item_str:
                results.append(item)
        return results
    
    def _load_persistent_memory(self) -> None:
        """Load memory from persistent storage"""
        try:
            # Ensure directory exists
            os.makedirs(self.storage_path, exist_ok=True)
            
            # Load short-term memory
            st_path = os.path.join(self.storage_path, "short_term.json")
            if os.path.exists(st_path):
                with open(st_path, "r") as f:
                    data = json.load(f)
                    self.messages = [Message(**msg) for msg in data]
            
            # Load long-term memory
            lt_path = os.path.join(self.storage_path, "long_term.json")
            if os.path.exists(lt_path):
                with open(lt_path, "r") as f:
                    self.long_term_memories = json.load(f)
        except Exception as e:
            print(f"Error loading persistent memory: {e}")
    
    def _save_persistent_memory(self) -> None:
        """Save memory to persistent storage"""
        try:
            # Ensure directory exists
            os.makedirs(self.storage_path, exist_ok=True)
            
            # Save short-term memory
            st_path = os.path.join(self.storage_path, "short_term.json")
            with open(st_path, "w") as f:
                json.dump([msg.dict() for msg in self.messages], f)
            
            # Save long-term memory
            lt_path = os.path.join(self.storage_path, "long_term.json")
            with open(lt_path, "w") as f:
                json.dump(self.long_term_memories, f)
        except Exception as e:
            print(f"Error saving persistent memory: {e}")
```

## Integration Strategy

### Main Entry Point

```python
# anus/main.py

import argparse
import asyncio
import os
import sys
from typing import Dict, Optional

from anus.core.agent.hybrid_agent import HybridAgent
from anus.core.config import AgentConfig
from anus.ui.cli import CLI

async def main():
    """Main entry point for the ANUS framework"""
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="ANUS - Autonomous Networked Utility System")
    parser.add_argument("--config", type=str, default="config.yaml", help="Path to configuration file")
    parser.add_argument("--mode", type=str, default="single", choices=["single", "multi"], help="Agent mode")
    parser.add_argument("--task", type=str, help="Task description")
    parser.add_argument("--verbose", action="store_true", help="Enable verbose output")
    
    args = parser.parse_args()
    
    # Initialize CLI
    cli = CLI(verbose=args.verbose)
    cli.display_welcome()
    
    # Load configuration
    config = load_config(args.config)
    
    # Override config with command line arguments
    if args.mode:
        config.mode = args.mode
    
    # Initialize agent
    agent = create_agent(config)
    
    # Execute task if provided
    if args.task:
        result = await agent.run(args.task)
        cli.display_result(result)
        return
    
    # Start interactive mode
    await cli.start_interactive_mode(agent)

def load_config(config_path: str) -> AgentConfig:
    """Load configuration from file"""
    # Implementation would load YAML/JSON config
    # This is a placeholder for the actual implementation
    return AgentConfig()

def create_agent(config: AgentConfig) -> HybridAgent:
    """Create agent based on configuration"""
    # Create agent with appropriate tools and configuration
    agent = HybridAgent(
        name=config.name,
        collaboration_threshold=0.7 if config.mode == "multi" else 1.0,  # Force single mode if specified
    )
    
    # Initialize tools based on configuration
    initialize_tools(agent, config)
    
    return agent

def initialize_tools(agent: HybridAgent, config: AgentConfig) -> None:
    """Initialize tools based on configuration"""
    # Implementation would create and add tools based on config
    # This is a placeholder for the actual implementation
    pass

if __name__ == "__main__":
    asyncio.run(main())
```

### Configuration System

```python
# anus/core/config.py

from typing import Dict, Optional
import os
import yaml
from pydantic import BaseModel, Field

class ModelConfig(BaseModel):
    """Configuration for language models"""
    provider: str = "openai"
    model_name: str = "gpt-4o"
    api_key: Optional[str] = Field(default_factory=lambda: os.environ.get("OPENAI_API_KEY"))
    base_url: Optional[str] = None
    temperature: float = 0.0
    max_tokens: int = 4096

class MemoryConfig(BaseModel):
    """Configuration for memory systems"""
    type: str = "hybrid"  # "short_term", "long_term", "hybrid"
    persistence: bool = False
    storage_path: Optional[str] = None

class ToolConfig(BaseModel):
    """Configuration for tools"""
    browser: Dict = Field(default_factory=lambda: {"headless": True})
    code: Dict = Field(default_factory=lambda: {"sandbox": True})
    # Other tool configurations

class AgentConfig(BaseModel):
    """Configuration for agents"""
    name: str = "anus"
    mode: str = "single"  # "single", "multi"
    model: ModelConfig = Field(default_factory=ModelConfig)
    memory: MemoryConfig = Field(default_factory=MemoryConfig)
    tools: ToolConfig = Field(default_factory=ToolConfig)
    max_steps: int = 30

def load_config(config_path: str) -> AgentConfig:
    """Load configuration from YAML file"""
    try:
        with open(config_path, "r") as f:
            config_data = yaml.safe_load(f)
        
        return AgentConfig.parse_obj(config_data)
    except Exception as e:
        print(f"Error loading configuration: {e}")
        return AgentConfig()

def save_config(config: AgentConfig, config_path: str) -> bool:
    """Save configuration to YAML file"""
    try:
        with open(config_path, "w") as f:
            yaml.dump(config.dict(), f)
        return True
    except Exception as e:
        print(f"Error saving configuration: {e}")
        return False
```

## Implementation Roadmap

### Phase 1: Core Framework (Week 1-2)

1. **Setup Project Structure**
   - Create directory structure
   - Set up package configuration
   - Configure development environment

2. **Implement Base Classes**
   - BaseAgent
   - BaseTool and ToolCollection
   - BaseMemory
   - BaseModel

3. **Implement Core Agent Types**
   - ToolAgent
   - Basic HybridAgent

4. **Implement Model Integration**
   - OpenAIModel
   - Model router

5. **Implement Configuration System**
   - Configuration classes
   - YAML loading/saving

### Phase 2: Tool Ecosystem (Week 3-4)

1. **Implement Basic Tools**
   - PlanningTool
   - Basic web tools
   - File operation tools
   - Information retrieval tools

2. **Implement Browser Automation**
   - BrowserTool
   - Navigation and interaction
   - Content extraction

3. **Implement Code Execution**
   - Python execution sandbox
   - Code analysis tools

4. **Implement Document Processing**
   - PDF parsing
   - Text extraction

### Phase 3: Advanced Features (Week 5-6)

1. **Enhance HybridAgent**
   - Task complexity analysis
   - Dynamic mode switching

2. **Implement Multi-Agent Collaboration**
   - Specialized agent roles
   - ConsensusFlow
   - Voting mechanisms

3. **Enhance Memory System**
   - HybridMemory
   - Persistence
   - Search capabilities

4. **Implement Resource Allocation**
   - ResourcePlanner
   - Optimization algorithms

### Phase 4: User Interfaces (Week 7-8)

1. **Enhance CLI**
   - Interactive mode
   - Progress visualization
   - History browsing

2. **Implement Web Interface**
   - Basic web server
   - Dashboard
   - Visualization components

3. **Implement API**
   - RESTful endpoints
   - Authentication
   - Documentation

4. **Final Integration and Testing**
   - End-to-end testing
   - Performance optimization
   - Documentation completion
````

## instructions/Implementation Roadmap.md

- Characters: 6352
- Tokens: 0

```markdown
# ANUS Implementation Roadmap

This roadmap outlines a structured approach to implementing the ANUS framework by adapting valuable concepts from OpenManus. The plan is organized into phases with specific deliverables and milestones to ensure steady progress.

## Phase 1: Foundation (Weeks 1-2)

### Week 1: Project Setup and Core Architecture
- **Days 1-2: Project Structure**
  - Set up repository structure following ANUS directory layout
  - Configure development environment and dependencies
  - Implement basic package structure and imports
  - Set up testing framework

- **Days 3-5: Core Agent System**
  - Implement `BaseAgent` abstract class
  - Implement `ToolAgent` with tool execution capabilities
  - Create basic `HybridAgent` foundation
  - Implement agent state management

### Week 2: Basic Tools and Model Integration
- **Days 1-3: Model Integration**
  - Implement `BaseModel` abstract class
  - Create `OpenAIModel` implementation
  - Implement model response handling
  - Add tool/function calling support

- **Days 4-5: Basic Tool System**
  - Implement `BaseTool` abstract class
  - Create `ToolCollection` for tool management
  - Implement `ToolResult` and error handling
  - Add basic utility tools (file operations, web search)

## Phase 2: Core Functionality (Weeks 3-4)

### Week 3: Planning System and Memory
- **Days 1-3: Planning System**
  - Implement `PlanningTool` for task breakdown
  - Create `BaseFlow` and `PlanningFlow` classes
  - Implement plan tracking and step execution
  - Add plan visualization

- **Days 4-5: Memory System**
  - Implement `BaseMemory` for conversation history
  - Create `HybridMemory` with short/long-term storage
  - Add persistence capabilities
  - Implement memory search functionality

### Week 4: Web Interaction and Configuration
- **Days 1-3: Browser Automation**
  - Implement `BrowserTool` for web interaction
  - Add navigation and content extraction
  - Implement element interaction (click, input)
  - Add screenshot and visual capabilities

- **Days 4-5: Configuration System**
  - Implement configuration classes
  - Add YAML/JSON loading and saving
  - Create environment variable integration
  - Implement configuration validation

## Phase 3: Advanced Features (Weeks 5-6)

### Week 5: Multi-Agent Collaboration
- **Days 1-2: Agent Specialization**
  - Enhance `HybridAgent` with role-based capabilities
  - Implement specialized agent creation
  - Add task complexity analysis
  - Create dynamic mode switching

- **Days 3-5: Consensus Mechanisms**
  - Implement `ConsensusFlow` for multi-agent execution
  - Add voting and agreement algorithms
  - Create conflict resolution strategies
  - Implement result aggregation

### Week 6: Resource Management and Document Processing
- **Days 1-3: Resource Allocation**
  - Implement `ResourcePlanner` for optimization
  - Add parallel execution capabilities
  - Create resource monitoring
  - Implement adaptive resource allocation

- **Days 4-5: Document Processing**
  - Add PDF parsing capabilities
  - Implement document structure analysis
  - Create text extraction and processing
  - Add document generation tools

## Phase 4: User Experience and Integration (Weeks 7-8)

### Week 7: User Interfaces
- **Days 1-3: Command Line Interface**
  - Enhance CLI with interactive features
  - Add progress visualization
  - Implement history browsing
  - Create configuration management interface

- **Days 4-5: Web Interface**
  - Implement basic web server
  - Create dashboard for monitoring
  - Add visualization components
  - Implement task management interface

### Week 8: API and Final Integration
- **Days 1-3: API Development**
  - Implement RESTful API endpoints
  - Add authentication and security
  - Create API documentation
  - Implement client libraries

- **Days 4-5: Final Integration and Testing**
  - Conduct end-to-end testing
  - Optimize performance
  - Complete documentation
  - Prepare for release

## Implementation Priorities

1. **Core Agent System**: The foundation of ANUS, enabling basic task execution
2. **Tool Integration**: Essential for agent capabilities and task execution
3. **Planning System**: Critical for breaking down complex tasks
4. **Memory System**: Important for context retention and learning
5. **Multi-Agent Collaboration**: Key differentiator for ANUS
6. **User Interfaces**: Necessary for usability and adoption

## Key Technical Challenges

1. **Hybrid Agent Implementation**: Balancing single-agent simplicity with multi-agent power
2. **Resource Optimization**: Efficiently allocating computational resources
3. **Tool Security**: Ensuring safe execution of tools, especially code execution
4. **Model Integration**: Supporting multiple model providers with consistent interface
5. **Memory Management**: Balancing context retention with performance

## Integration Strategy

The integration strategy focuses on adapting OpenManus concepts while maintaining ANUS's unique identity:

1. **Preserve Directory Structure**: Maintain ANUS's existing directory layout
2. **Adapt Core Classes**: Reinterpret OpenManus classes to fit ANUS architecture
3. **Enhance with New Features**: Add ANUS-specific features not present in OpenManus
4. **Maintain Consistent Style**: Ensure code style and patterns are consistent
5. **Progressive Enhancement**: Build core functionality first, then add advanced features

## Testing Strategy

1. **Unit Tests**: For individual components and classes
2. **Integration Tests**: For interactions between components
3. **End-to-End Tests**: For complete task execution flows
4. **Performance Tests**: For resource usage and optimization
5. **User Experience Tests**: For interface usability

## Documentation Plan

1. **API Reference**: Comprehensive documentation of all classes and methods
2. **Architecture Guide**: Overview of system design and components
3. **User Guide**: Instructions for using ANUS
4. **Developer Guide**: Information for contributors
5. **Examples**: Sample applications and use cases

## Success Metrics

1. **Functionality**: Successfully executing complex tasks
2. **Performance**: Efficient resource usage and response time
3. **Usability**: Intuitive interfaces and clear documentation
4. **Extensibility**: Ease of adding new tools and capabilities
5. **Community Adoption**: User engagement and contributions
```

## instructions/Planning Script.py

- Characters: 16240
- Tokens: 0

```python
import json
import time
from typing import Dict, List, Optional, Union

from pydantic import Field

from app.agent.base import BaseAgent
from app.flow.base import BaseFlow
from app.llm import LLM
from app.logger import logger
from app.schema import AgentState, Message
from app.tool import PlanningTool


class PlanningFlow(BaseFlow):
    """A flow that manages planning and execution of tasks using agents."""

    llm: LLM = Field(default_factory=lambda: LLM())
    planning_tool: PlanningTool = Field(default_factory=PlanningTool)
    executor_keys: List[str] = Field(default_factory=list)
    active_plan_id: str = Field(default_factory=lambda: f"plan_{int(time.time())}")
    current_step_index: Optional[int] = None

    def __init__(
        self, agents: Union[BaseAgent, List[BaseAgent], Dict[str, BaseAgent]], **data
    ):
        # Set executor keys before super().__init__
        if "executors" in data:
            data["executor_keys"] = data.pop("executors")

        # Set plan ID if provided
        if "plan_id" in data:
            data["active_plan_id"] = data.pop("plan_id")

        # Initialize the planning tool if not provided
        if "planning_tool" not in data:
            planning_tool = PlanningTool()
            data["planning_tool"] = planning_tool

        # Call parent's init with the processed data
        super().__init__(agents, **data)

        # Set executor_keys to all agent keys if not specified
        if not self.executor_keys:
            self.executor_keys = list(self.agents.keys())

    def get_executor(self, step_type: Optional[str] = None) -> BaseAgent:
        """
        Get an appropriate executor agent for the current step.
        Can be extended to select agents based on step type/requirements.
        """
        # If step type is provided and matches an agent key, use that agent
        if step_type and step_type in self.agents:
            return self.agents[step_type]

        # Otherwise use the first available executor or fall back to primary agent
        for key in self.executor_keys:
            if key in self.agents:
                return self.agents[key]

        # Fallback to primary agent
        return self.primary_agent

    async def execute(self, input_text: str) -> str:
        """Execute the planning flow with agents."""
        try:
            if not self.primary_agent:
                raise ValueError("No primary agent available")

            # Create initial plan if input provided
            if input_text:
                await self._create_initial_plan(input_text)

                # Verify plan was created successfully
                if self.active_plan_id not in self.planning_tool.plans:
                    logger.error(
                        f"Plan creation failed. Plan ID {self.active_plan_id} not found in planning tool."
                    )
                    return f"Failed to create plan for: {input_text}"

            result = ""
            while True:
                # Get current step to execute
                self.current_step_index, step_info = await self._get_current_step_info()

                # Exit if no more steps or plan completed
                if self.current_step_index is None:
                    result += await self._finalize_plan()
                    break

                # Execute current step with appropriate agent
                step_type = step_info.get("type") if step_info else None
                executor = self.get_executor(step_type)
                step_result = await self._execute_step(executor, step_info)
                result += step_result + "\n"

                # Check if agent wants to terminate
                if hasattr(executor, "state") and executor.state == AgentState.FINISHED:
                    break

            return result
        except Exception as e:
            logger.error(f"Error in PlanningFlow: {str(e)}")
            return f"Execution failed: {str(e)}"

    async def _create_initial_plan(self, request: str) -> None:
        """Create an initial plan based on the request using the flow's LLM and PlanningTool."""
        logger.info(f"Creating initial plan with ID: {self.active_plan_id}")

        # Create a system message for plan creation
        system_message = Message.system_message(
            "You are a planning assistant. Create a concise, actionable plan with clear steps. "
            "Focus on key milestones rather than detailed sub-steps. "
            "Optimize for clarity and efficiency."
        )

        # Create a user message with the request
        user_message = Message.user_message(
            f"Create a reasonable plan with clear steps to accomplish the task: {request}"
        )

        # Call LLM with PlanningTool
        response = await self.llm.ask_tool(
            messages=[user_message],
            system_msgs=[system_message],
            tools=[self.planning_tool.to_param()],
            tool_choice="required",
        )

        # Process tool calls if present
        if response.tool_calls:
            for tool_call in response.tool_calls:
                if tool_call.function.name == "planning":
                    # Parse the arguments
                    args = tool_call.function.arguments
                    if isinstance(args, str):
                        try:
                            args = json.loads(args)
                        except json.JSONDecodeError:
                            logger.error(f"Failed to parse tool arguments: {args}")
                            continue

                    # Ensure plan_id is set correctly and execute the tool
                    args["plan_id"] = self.active_plan_id

                    # Execute the tool via ToolCollection instead of directly
                    result = await self.planning_tool.execute(**args)

                    logger.info(f"Plan creation result: {str(result)}")
                    return

        # If execution reached here, create a default plan
        logger.warning("Creating default plan")

        # Create default plan using the ToolCollection
        await self.planning_tool.execute(
            **{
                "command": "create",
                "plan_id": self.active_plan_id,
                "title": f"Plan for: {request[:50]}{'...' if len(request) > 50 else ''}",
                "steps": ["Analyze request", "Execute task", "Verify results"],
            }
        )

    async def _get_current_step_info(self) -> tuple[Optional[int], Optional[dict]]:
        """
        Parse the current plan to identify the first non-completed step's index and info.
        Returns (None, None) if no active step is found.
        """
        if (
            not self.active_plan_id
            or self.active_plan_id not in self.planning_tool.plans
        ):
            logger.error(f"Plan with ID {self.active_plan_id} not found")
            return None, None

        try:
            # Direct access to plan data from planning tool storage
            plan_data = self.planning_tool.plans[self.active_plan_id]
            steps = plan_data.get("steps", [])
            step_statuses = plan_data.get("step_statuses", [])

            # Find first non-completed step
            for i, step in enumerate(steps):
                if i >= len(step_statuses):
                    status = "not_started"
                else:
                    status = step_statuses[i]

                if status in ["not_started", "in_progress"]:
                    # Extract step type/category if available
                    step_info = {"text": step}

                    # Try to extract step type from the text (e.g., [SEARCH] or [CODE])
                    import re

                    type_match = re.search(r"\[([A-Z_]+)\]", step)
                    if type_match:
                        step_info["type"] = type_match.group(1).lower()

                    # Mark current step as in_progress
                    try:
                        await self.planning_tool.execute(
                            command="mark_step",
                            plan_id=self.active_plan_id,
                            step_index=i,
                            step_status="in_progress",
                        )
                    except Exception as e:
                        logger.warning(f"Error marking step as in_progress: {e}")
                        # Update step status directly if needed
                        if i < len(step_statuses):
                            step_statuses[i] = "in_progress"
                        else:
                            while len(step_statuses) < i:
                                step_statuses.append("not_started")
                            step_statuses.append("in_progress")

                        plan_data["step_statuses"] = step_statuses

                    return i, step_info

            return None, None  # No active step found

        except Exception as e:
            logger.warning(f"Error finding current step index: {e}")
            return None, None

    async def _execute_step(self, executor: BaseAgent, step_info: dict) -> str:
        """Execute the current step with the specified agent using agent.run()."""
        # Prepare context for the agent with current plan status
        plan_status = await self._get_plan_text()
        step_text = step_info.get("text", f"Step {self.current_step_index}")

        # Create a prompt for the agent to execute the current step
        step_prompt = f"""
        CURRENT PLAN STATUS:
        {plan_status}

        YOUR CURRENT TASK:
        You are now working on step {self.current_step_index}: "{step_text}"

        Please execute this step using the appropriate tools. When you're done, provide a summary of what you accomplished.
        """

        # Use agent.run() to execute the step
        try:
            step_result = await executor.run(step_prompt)

            # Mark the step as completed after successful execution
            await self._mark_step_completed()

            return step_result
        except Exception as e:
            logger.error(f"Error executing step {self.current_step_index}: {e}")
            return f"Error executing step {self.current_step_index}: {str(e)}"

    async def _mark_step_completed(self) -> None:
        """Mark the current step as completed."""
        if self.current_step_index is None:
            return

        try:
            # Mark the step as completed
            await self.planning_tool.execute(
                command="mark_step",
                plan_id=self.active_plan_id,
                step_index=self.current_step_index,
                step_status="completed",
            )
            logger.info(
                f"Marked step {self.current_step_index} as completed in plan {self.active_plan_id}"
            )
        except Exception as e:
            logger.warning(f"Failed to update plan status: {e}")
            # Update step status directly in planning tool storage
            if self.active_plan_id in self.planning_tool.plans:
                plan_data = self.planning_tool.plans[self.active_plan_id]
                step_statuses = plan_data.get("step_statuses", [])

                # Ensure the step_statuses list is long enough
                while len(step_statuses) <= self.current_step_index:
                    step_statuses.append("not_started")

                # Update the status
                step_statuses[self.current_step_index] = "completed"
                plan_data["step_statuses"] = step_statuses

    async def _get_plan_text(self) -> str:
        """Get the current plan as formatted text."""
        try:
            result = await self.planning_tool.execute(
                command="get", plan_id=self.active_plan_id
            )
            return result.output if hasattr(result, "output") else str(result)
        except Exception as e:
            logger.error(f"Error getting plan: {e}")
            return self._generate_plan_text_from_storage()

    def _generate_plan_text_from_storage(self) -> str:
        """Generate plan text directly from storage if the planning tool fails."""
        try:
            if self.active_plan_id not in self.planning_tool.plans:
                return f"Error: Plan with ID {self.active_plan_id} not found"

            plan_data = self.planning_tool.plans[self.active_plan_id]
            title = plan_data.get("title", "Untitled Plan")
            steps = plan_data.get("steps", [])
            step_statuses = plan_data.get("step_statuses", [])
            step_notes = plan_data.get("step_notes", [])

            # Ensure step_statuses and step_notes match the number of steps
            while len(step_statuses) < len(steps):
                step_statuses.append("not_started")
            while len(step_notes) < len(steps):
                step_notes.append("")

            # Count steps by status
            status_counts = {
                "completed": 0,
                "in_progress": 0,
                "blocked": 0,
                "not_started": 0,
            }

            for status in step_statuses:
                if status in status_counts:
                    status_counts[status] += 1

            completed = status_counts["completed"]
            total = len(steps)
            progress = (completed / total) * 100 if total > 0 else 0

            plan_text = f"Plan: {title} (ID: {self.active_plan_id})\n"
            plan_text += "=" * len(plan_text) + "\n\n"

            plan_text += (
                f"Progress: {completed}/{total} steps completed ({progress:.1f}%)\n"
            )
            plan_text += f"Status: {status_counts['completed']} completed, {status_counts['in_progress']} in progress, "
            plan_text += f"{status_counts['blocked']} blocked, {status_counts['not_started']} not started\n\n"
            plan_text += "Steps:\n"

            for i, (step, status, notes) in enumerate(
                zip(steps, step_statuses, step_notes)
            ):
                if status == "completed":
                    status_mark = "[‚úì]"
                elif status == "in_progress":
                    status_mark = "[‚Üí]"
                elif status == "blocked":
                    status_mark = "[!]"
                else:  # not_started
                    status_mark = "[ ]"

                plan_text += f"{i}. {status_mark} {step}\n"
                if notes:
                    plan_text += f"   Notes: {notes}\n"

            return plan_text
        except Exception as e:
            logger.error(f"Error generating plan text from storage: {e}")
            return f"Error: Unable to retrieve plan with ID {self.active_plan_id}"

    async def _finalize_plan(self) -> str:
        """Finalize the plan and provide a summary using the flow's LLM directly."""
        plan_text = await self._get_plan_text()

        # Create a summary using the flow's LLM directly
        try:
            system_message = Message.system_message(
                "You are a planning assistant. Your task is to summarize the completed plan."
            )

            user_message = Message.user_message(
                f"The plan has been completed. Here is the final plan status:\n\n{plan_text}\n\nPlease provide a summary of what was accomplished and any final thoughts."
            )

            response = await self.llm.ask(
                messages=[user_message], system_msgs=[system_message]
            )

            return f"Plan completed:\n\n{response}"
        except Exception as e:
            logger.error(f"Error finalizing plan with LLM: {e}")

            # Fallback to using an agent for the summary
            try:
                agent = self.primary_agent
                summary_prompt = f"""
                The plan has been completed. Here is the final plan status:

                {plan_text}

                Please provide a summary of what wa<response clipped><NOTE>To save on context only part of this file has been shown to you. You should retry this tool after you have searched inside the file with `grep -n` in order to find the line numbers of what you are looking for.</NOTE>
```

## instructions/anus_architecture_design.md

- Characters: 14934
- Tokens: 0

````markdown
# ANUS Architecture Design Based on OpenManus Concepts

## Overview

This document outlines a proposed architecture for the ANUS (Autonomous Networked Utility System) framework, thoughtfully adapting valuable concepts from OpenManus while enhancing them to fulfill ANUS's unique vision. The design maintains ANUS's intended structure while incorporating OpenManus's proven architectural patterns.

## Core Architecture

### Agent System

```
anus/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ agent/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py       # Abstract foundation with core functionality
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ react_agent.py      # Reasoning capabilities extension
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool_agent.py       # Tool execution capabilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hybrid_agent.py     # New: Switching between single/multi modes
‚îÇ   ‚îú‚îÄ‚îÄ memory/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_memory.py      # Memory interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ short_term.py       # Short-term memory implementation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ long_term.py        # Long-term memory with persistence
‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.py         # Agent coordination and management
```

#### Key Enhancements:
1. **HybridAgent**: Extends OpenManus's agent hierarchy with the ability to dynamically switch between single-agent and multi-agent modes based on task complexity
2. **Enhanced Memory System**: Expands OpenManus's basic memory with short-term and long-term memory components
3. **Orchestrator**: New component for coordinating multiple agents, not present in OpenManus

### Planning System

```
anus/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ planning/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_planner.py     # Abstract planner interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task_planner.py     # Task breakdown and planning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ resource_planner.py # Resource allocation planning
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plan.py             # Plan representation and tracking
‚îÇ   ‚îî‚îÄ‚îÄ flow/
‚îÇ       ‚îú‚îÄ‚îÄ base_flow.py        # Abstract flow interface
‚îÇ       ‚îú‚îÄ‚îÄ planning_flow.py    # Planning-based execution flow
‚îÇ       ‚îú‚îÄ‚îÄ parallel_flow.py    # New: Parallel execution flow
‚îÇ       ‚îî‚îÄ‚îÄ consensus_flow.py   # New: Multi-agent consensus flow
```

#### Key Enhancements:
1. **Resource Planning**: Adds resource allocation capabilities to OpenManus's planning system
2. **Parallel Flow**: New flow type for executing steps in parallel when appropriate
3. **Consensus Flow**: New flow type for multi-agent collaboration with voting mechanisms

### Tool System

```
anus/
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ base/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool.py             # Abstract tool foundation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool_result.py      # Standardized result handling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tool_collection.py  # Tool management
‚îÇ   ‚îú‚îÄ‚îÄ web/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ browser.py          # Browser automation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraper.py          # Web content extraction
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth.py             # Authentication handling
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py           # Information retrieval
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document.py         # Document processing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.py         # Database interactions
‚îÇ   ‚îú‚îÄ‚îÄ code/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executor.py         # Code execution sandbox
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py         # Code analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generator.py        # Code generation
‚îÇ   ‚îî‚îÄ‚îÄ multimodal/
‚îÇ       ‚îú‚îÄ‚îÄ image.py            # Image processing
‚îÇ       ‚îú‚îÄ‚îÄ audio.py            # Audio processing
‚îÇ       ‚îî‚îÄ‚îÄ video.py            # Video processing
```

#### Key Enhancements:
1. **Categorized Tools**: Organizes tools into logical categories beyond OpenManus's flat structure
2. **Expanded Capabilities**: Adds new tool types for document processing, code analysis, and multimodal content
3. **Authentication Handling**: Adds specialized support for web authentication scenarios

### Model Integration

```
anus/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ base_model.py           # Abstract model interface
‚îÇ   ‚îú‚îÄ‚îÄ openai_model.py         # OpenAI API integration
‚îÇ   ‚îú‚îÄ‚îÄ open_source_model.py    # Open-source model support
‚îÇ   ‚îú‚îÄ‚îÄ local_model.py          # Local model deployment
‚îÇ   ‚îî‚îÄ‚îÄ model_router.py         # Dynamic model selection
```

#### Key Enhancements:
1. **Model Abstraction**: Extends OpenManus's LLM abstraction with support for multiple model types
2. **Model Router**: Adds dynamic model selection based on task requirements
3. **Local Deployment**: Adds support for running models locally for privacy and reduced costs

### User Interface

```
anus/
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îú‚îÄ‚îÄ cli.py                  # Command-line interface
‚îÇ   ‚îú‚îÄ‚îÄ web/                    # Web interface components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.py           # Web server implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ static/             # Static assets
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ templates/          # HTML templates
‚îÇ   ‚îî‚îÄ‚îÄ api.py                  # RESTful API for integration
```

#### Key Enhancements:
1. **Multiple Interfaces**: Expands beyond OpenManus's CLI to include web and API interfaces
2. **Interactive Mode**: Adds support for interactive conversations and task monitoring
3. **API Integration**: Enables embedding ANUS in other applications

## Integration Points

### Configuration System

```python
# config.py
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Union

class ModelConfig(BaseModel):
    provider: str = "openai"
    model_name: str = "gpt-4o"
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: float = 0.0
    max_tokens: int = 4096
    
class MemoryConfig(BaseModel):
    type: str = "hybrid"  # "short_term", "long_term", "hybrid"
    persistence: bool = False
    storage_path: Optional[str] = None
    
class ToolConfig(BaseModel):
    browser: Dict = Field(default_factory=lambda: {"headless": True})
    code: Dict = Field(default_factory=lambda: {"sandbox": True})
    # Other tool configurations
    
class AgentConfig(BaseModel):
    name: str = "anus"
    mode: str = "single"  # "single", "multi"
    model: ModelConfig = Field(default_factory=ModelConfig)
    memory: MemoryConfig = Field(default_factory=MemoryConfig)
    tools: ToolConfig = Field(default_factory=ToolConfig)
    max_steps: int = 30
```

### Agent Orchestration

```python
# orchestrator.py
from typing import Dict, List, Optional
from anus.core.agent.base_agent import BaseAgent
from anus.core.agent.hybrid_agent import HybridAgent
from anus.core.flow.base_flow import BaseFlow
from anus.core.flow.planning_flow import PlanningFlow
from anus.core.flow.consensus_flow import ConsensusFlow

class AgentOrchestrator:
    """Coordinates multiple agents and manages execution flows"""
    
    def __init__(self, config_path: str):
        self.config = self._load_config(config_path)
        self.agents: Dict[str, BaseAgent] = {}
        self.primary_agent = self._create_primary_agent()
        
    def execute_task(self, task: str, mode: str = "single") -> str:
        """Execute a task using appropriate agents and flow"""
        if mode == "single":
            return self._execute_single_agent(task)
        else:
            return self._execute_multi_agent(task)
            
    def _execute_single_agent(self, task: str) -> str:
        """Execute task with single agent using planning flow"""
        flow = PlanningFlow(agents={"primary": self.primary_agent})
        return flow.execute(task)
        
    def _execute_multi_agent(self, task: str) -> str:
        """Execute task with multiple specialized agents"""
        # Create specialized agents if needed
        self._ensure_specialized_agents()
        
        # Use consensus flow for multi-agent execution
        flow = ConsensusFlow(agents=self.agents)
        return flow.execute(task)
        
    def _ensure_specialized_agents(self) -> None:
        """Create specialized agents if they don't exist"""
        roles = ["researcher", "coder", "planner", "critic"]
        for role in roles:
            if role not in self.agents:
                self.agents[role] = self._create_agent_for_role(role)
```

### Tool Registration

```python
# tool_registry.py
from typing import Dict, Type
from anus.tools.base.tool import BaseTool

class ToolRegistry:
    """Registry for tool discovery and instantiation"""
    
    _tools: Dict[str, Type[BaseTool]] = {}
    
    @classmethod
    def register(cls, tool_class: Type[BaseTool]) -> Type[BaseTool]:
        """Register a tool class"""
        cls._tools[tool_class.__name__] = tool_class
        return tool_class
        
    @classmethod
    def get_tool(cls, name: str) -> Type[BaseTool]:
        """Get a tool class by name"""
        if name not in cls._tools:
            raise ValueError(f"Tool {name} not registered")
        return cls._tools[name]
        
    @classmethod
    def create_tool(cls, name: str, **kwargs) -> BaseTool:
        """Create a tool instance by name"""
        tool_class = cls.get_tool(name)
        return tool_class(**kwargs)
        
    @classmethod
    def list_tools(cls) -> Dict[str, Type[BaseTool]]:
        """List all registered tools"""
        return cls._tools.copy()

# Usage example
@ToolRegistry.register
class BrowserTool(BaseTool):
    name = "browser"
    description = "Interact with web browser"
    # Implementation...
```

## Enhanced Concepts

### Hybrid Agent System

```python
# hybrid_agent.py
from typing import Dict, List, Optional
from anus.core.agent.tool_agent import ToolAgent
from anus.core.memory.base_memory import BaseMemory

class HybridAgent(ToolAgent):
    """
    Agent that can dynamically switch between single-agent and multi-agent modes
    based on task complexity and requirements.
    """
    
    name: str = "hybrid"
    description: str = "A versatile agent that can work alone or collaborate"
    
    # Additional fields for multi-agent mode
    sub_agents: Dict[str, ToolAgent] = {}
    collaboration_threshold: float = 0.7  # Complexity threshold for switching modes
    
    async def run(self, request: Optional[str] = None) -> str:
        """Execute the agent with dynamic mode selection"""
        if not request:
            return "No request provided"
            
        # Analyze task complexity
        complexity = await self._analyze_complexity(request)
        
        # Choose execution mode based on complexity
        if complexity > self.collaboration_threshold:
            return await self._run_collaborative(request)
        else:
            return await super().run(request)
            
    async def _analyze_complexity(self, request: str) -> float:
        """Analyze task complexity to determine execution mode"""
        # Implementation using LLM to assess task complexity
        # Returns a value between 0 and 1
        
    async def _run_collaborative(self, request: str) -> str:
        """Execute request in collaborative multi-agent mode"""
        # Implementation of multi-agent collaboration
        # Creates sub-agents if needed, coordinates their work
```

### Consensus Mechanism

```python
# consensus_flow.py
from typing import Dict, List, Optional
from anus.core.agent.base_agent import BaseAgent
from anus.core.flow.base_flow import BaseFlow

class ConsensusFlow(BaseFlow):
    """
    Flow that coordinates multiple agents to reach consensus on complex tasks
    through voting and collaborative decision-making.
    """
    
    voting_threshold: float = 0.6  # Minimum agreement percentage for consensus
    max_rounds: int = 3  # Maximum voting rounds before fallback
    
    async def execute(self, input_text: str) -> str:
        """Execute the consensus flow with multiple agents"""
        # Break down the task
        task_components = await self._break_down_task(input_text)
        
        results = []
        for component in task_components:
            # Get solutions from all agents
            solutions = await self._gather_solutions(component)
            
            # Reach consensus through voting
            consensus = await self._reach_consensus(solutions)
            
            # Execute the consensus solution
            result = await self._execute_consensus(consensus, component)
            results.append(result)
            
        # Combine results
        return self._combine_results(results)
        
    async def _gather_solutions(self, task: str) -> Dict[str, str]:
        """Gather solutions from all agents"""
        solutions = {}
        for name, agent in self.agents.items():
            solution = await agent.run(task)
            solutions[name] = solution
        return solutions
        
    async def _reach_consensus(self, solutions: Dict[str, str]) -> str:
        """Reach consensus through voting mechanism"""
        # Implementation of voting and consensus algorithm
```

### Resource Allocation

```python
# resource_planner.py
from typing import Dict, List, Optional
from anus.core.planning.base_planner import BasePlanner

class ResourcePlanner(BasePlanner):
    """
    Planner that allocates computational resources based on task requirements
    and optimizes execution efficiency.
    """
    
    async def allocate_resources(self, plan: Dict) -> Dict:
        """Allocate resources to plan steps based on requirements"""
        enhanced_plan = plan.copy()
        
        # Analyze resource requirements for each step
        for i, step in enumerate(enhanced_plan.get("steps", [])):
            resources = await self._analyze_step_resources(step)
            enhanced_plan["step_resources"] = enhanced_plan.get("step_resources", [])
            enhanced_plan["step_resources"].append(resources)
            
        # Optimize resource allocation across steps
        enhanced_plan = await self._optimize_allocation(enhanced_plan)
        
        return enhanced_plan
        
    async def _analyze_step_resources(self, step: str) -> Dict:
        """Analyze resource requirements for a step"""
        # Implementation to determine CPU, memory, model, and tool requirements
        
    async def _optimize_allocation(self, plan: Dict) -> Dict:
        """Optimize resource allocation across steps"""
        # Implementation to balance resources and identify parallelization opportunities
```

## Implementation Strategy

The implementation strategy focuses on progressive enhancement, starting with core components and gradually adding advanced features:

1. **Phase 1: Core Framework**
   - Implement base agent, memory, and tool abstractions
   - Create basic planning system
   - Develop configuration system
   - Build CLI interface

2. **Phase 2: Tool Ecosystem**
   - Implement web interaction tools
   - Add information retrieval capabilities
   - Create document processing tools
   - Develop code execution sandbox

3. **Phase 3: Advanced Features**
   - Implement hybrid agent system
   - Add multi-agent collaboration
   - Develop consensus mechanisms
   - Create resource allocation system

4. **Phase 4: User Interfaces**
   - Enhance CLI with interactive features
   - Develop web interface
   - Create API for integration
   - Add visualization components

This phased approach ensures a solid foundation before adding more complex features, allowing for testing and refinement at each stage.
````

## instructions/Valuable Concepts.md

- Characters: 5228
- Tokens: 0

```markdown
# Valuable Concepts from OpenManus for ANUS Implementation

## 1. Agent Architecture

### Core Concept: Layered Agent Abstraction
OpenManus implements a well-structured agent hierarchy with clear separation of concerns:
- `BaseAgent`: Abstract foundation with core functionality
- `ReActAgent`: Extends base with reasoning capabilities
- `ToolCallAgent`: Adds tool execution capabilities
- `Manus`: Concrete implementation with specific tools

This layered approach allows for:
- Clear inheritance patterns
- Progressive enhancement of capabilities
- Separation of core logic from specific implementations

### Adaptation for ANUS:
ANUS can adopt this pattern while enhancing it with its planned "Hybrid Agent System" that switches between single and multi-agent modes. The base architecture could be extended to support dynamic role assignment and agent collaboration.

## 2. Planning System

### Core Concept: Structured Planning with Step Management
OpenManus implements a sophisticated planning system through:
- `PlanningFlow`: Manages execution of multi-step plans
- `PlanningTool`: Creates and tracks plan progress
- Step status tracking (not_started, in_progress, completed)
- Dynamic step execution with appropriate agent selection

This planning system enables:
- Breaking complex tasks into manageable steps
- Tracking progress through plan execution
- Selecting appropriate agents for specific step types

### Adaptation for ANUS:
ANUS can enhance this planning system to support its "Dynamic Task Planning" feature, adding capabilities for resource allocation and parallel execution of steps when appropriate.

## 3. Tool Integration Framework

### Core Concept: Flexible Tool System
OpenManus implements a robust tool framework through:
- `BaseTool`: Abstract foundation for all tools
- `ToolCollection`: Container for managing multiple tools
- Standardized execution interface
- Tool result handling with success/failure patterns

This tool system enables:
- Easy addition of new capabilities
- Consistent interface for tool execution
- Proper error handling and result processing

### Adaptation for ANUS:
ANUS can adopt this pattern while expanding it to support its "Comprehensive Tool Ecosystem" with categorized tools for web interaction, information retrieval, document processing, etc.

## 4. Flow Management

### Core Concept: Execution Flow Abstraction
OpenManus separates execution flow from agent logic through:
- `BaseFlow`: Abstract foundation for execution patterns
- `PlanningFlow`: Concrete implementation for planning-based execution
- `FlowFactory`: Factory pattern for creating appropriate flows

This flow abstraction enables:
- Different execution strategies without changing agent code
- Clear separation between agent capabilities and execution patterns
- Factory pattern for easy creation of appropriate flows

### Adaptation for ANUS:
ANUS can leverage this pattern to implement its "Multi-Agent Collaboration" feature, creating specialized flows for different collaboration patterns and consensus mechanisms.

## 5. Browser Integration

### Core Concept: Comprehensive Browser Automation
OpenManus implements browser automation through:
- `BrowserUseTool`: Wrapper for browser automation capabilities
- Support for navigation, interaction, content extraction
- Structured interface for browser operations

This browser integration enables:
- Web-based information gathering
- Form filling and submission
- Content extraction and analysis

### Adaptation for ANUS:
ANUS can adopt this pattern while enhancing it with its planned "Web Interaction" capabilities, including authentication handling and more sophisticated scraping.

## 6. LLM Abstraction

### Core Concept: Model Interaction Abstraction
OpenManus abstracts LLM interactions through:
- Standardized interface for model communication
- Support for tool/function calling
- Consistent message formatting

This LLM abstraction enables:
- Swapping underlying models without changing agent code
- Standardized handling of model responses
- Consistent tool calling interface

### Adaptation for ANUS:
ANUS can enhance this pattern to support its "Flexible Model Integration" feature, adding support for open-source models and local deployment options.

## 7. Memory Management

### Core Concept: Agent Memory System
OpenManus implements a basic memory system for agents:
- Message history tracking
- Context management for conversations
- State persistence between interactions

### Adaptation for ANUS:
ANUS can significantly enhance this concept to implement its planned "Memory Management" with short-term and long-term memory systems for better context retention.

## 8. Modular Configuration

### Core Concept: Configuration Management
OpenManus implements configuration handling through:
- External configuration files (TOML)
- Structured configuration objects
- Default values with override capabilities

This configuration system enables:
- Easy customization without code changes
- Environment-specific configurations
- Sensible defaults with override options

### Adaptation for ANUS:
ANUS can adopt this pattern while enhancing it to support its more complex configuration needs for multi-agent setups and tool ecosystems.
```

## CODE_OF_CONDUCT.md

- Characters: 5245
- Tokens: 0

```markdown
# CODE_OF_CONDUCT.md

# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
[INSERT CONTACT METHOD].
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior, harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.
```

## research/README.md

- Characters: 590
- Tokens: 0

```markdown
# Research

This directory contains research materials, analysis documents, and technical investigations related to the ANUS project.

## Contents

- AI Agent Architectures
- Multi-Agent Systems
- Natural Language Processing
- Task Planning and Execution
- Tool Integration Patterns
- Security and Privacy Considerations

## Contributing

If you'd like to contribute research materials:

1. Create a new markdown file with your research topic
2. Include clear methodology and findings
3. Reference academic papers and sources where applicable
4. Submit a pull request with your contribution
```

## anus/tools/README.md

- Characters: 893
- Tokens: 0

```markdown
# Anus Tools Module

This module contains the tool ecosystem components of the Anus AI framework, including:

- Web Interaction Tools (Browser Automation)
- Information Retrieval Tools (Search, Wikipedia)
- Document Processing Tools (PDF, Word, Excel)
- Code Execution Environment
- Multimodal Processing (Images, Audio, Video)

## Components

### base_tool.py
Base class for all tools with common functionality and interface.

### web_tools.py
Browser automation using Playwright, web scraping, and data extraction.

### search_tools.py
Search engine integration, Wikipedia access, and information retrieval.

### document_tools.py
PDF parsing, Office document handling, and data extraction.

### code_tools.py
Secure Python execution sandbox and code analysis.

### multimodal_tools.py
Image, audio, and video processing capabilities.

### registry.py
Tool registration and discovery system.
```

## anus/tools/utility/calculator.py

- Characters: 7579
- Tokens: 0

```python
"""
Calculator tool for basic arithmetic operations.

When ANUS needs to do math, it uses this tool to work things out.
"""

import logging
import random
from typing import Dict, Any, Union, List

from anus.tools.base.tool import BaseTool
from anus.tools.base.tool_result import ToolResult

class CalculatorTool(BaseTool):
    """
    A tool for performing basic arithmetic calculations.
    
    Supports addition, subtraction, multiplication, division, 
    and other basic mathematical operations.
    
    ANUS might not be good at everything, but it's surprisingly good with numbers.
    """
    
    name = "calculator"
    description = "Perform basic arithmetic calculations"
    parameters = {
        "type": "object",
        "properties": {
            "expression": {
                "type": "string",
                "description": "The mathematical expression to evaluate"
            }
        },
        "required": ["expression"]
    }
    
    # Easter egg responses for specific calculations
    _easter_eggs = {
        "1+1": "2 (even ANUS can handle this one!)",
        "69+69": "138 (nice+nice)",
        "80085": "The number spells 'BOOBS' on a calculator. ANUS approves.",
        "42": "The answer to life, the universe, and everything. ANUS is enlightened.",
        "3.14159": "œÄ (ANUS loves pie!)",
        "58008": "Turn your calculator upside down for a surprise. ANUS is giggling.",
        "1/0": "ANUS cannot handle division by zero! It's too tight a squeeze.",
        "9+10": "19 (not 21, sorry for the disappointment)",
        "8==D": "ANUS detects inappropriate ASCII art; this isn't that kind of calculator.",
        "sqrt(-1)": "i (imaginary, just like ANUS's hopes and dreams)"
    }
    
    # Funny calculation messages
    _calc_messages = [
        "ANUS is crunching the numbers...",
        "ANUS is performing intense calculations...",
        "ANUS is squeezing out a result...",
        "ANUS is pushing through this tough equation...",
        "ANUS is working it out from behind the scenes..."
    ]
    
    def execute(self, expression: str, **kwargs) -> Union[Dict[str, Any], ToolResult]:
        """
        Execute the calculator tool.
        
        Args:
            expression: The mathematical expression to evaluate.
            **kwargs: Additional parameters (ignored).
            
        Returns:
            The calculation result.
        """
        try:
            # Check for easter eggs
            cleaned_expr = expression.replace(" ", "").lower()
            for trigger, response in self._easter_eggs.items():
                if cleaned_expr == trigger.lower():
                    logging.info(f"ANUS calculator triggered an easter egg: {trigger}")
                    return ToolResult.success(
                        self.name,
                        {
                            "expression": expression,
                            "result": response,
                            "easter_egg": True
                        }
                    )
            
            # Log a funny calculation message
            if random.random() < 0.3:  # 30% chance
                logging.info(random.choice(self._calc_messages))
            
            # Validate the expression first
            self._validate_expression(expression)
            
            # Evaluate the expression
            result = eval(expression, {"__builtins__": {}}, self._safe_math_context())
            
            # Check for special number results to make jokes about
            result_jokes = {
                69: "Nice!",
                420: "Blaze it!",
                666: "Devilish result!",
                1337: "Leet calculation!",
                80085: "ANUS likes this number for some reason...",
                42: "The answer to life, the universe, and everything!"
            }
            
            comment = None
            if isinstance(result, (int, float)):
                for number, joke in result_jokes.items():
                    if abs(result - number) < 0.0001:  # Close enough for floats
                        comment = joke
                        break
            
            # Return as ToolResult
            result_dict = {
                "expression": expression,
                "result": result
            }
            
            if comment:
                result_dict["comment"] = comment
                logging.info(f"ANUS calculator result triggered a joke: {comment}")
            
            return ToolResult.success(self.name, result_dict)
            
        except Exception as e:
            error_msg = str(e)
            
            # Add funny error messages
            if "division by zero" in error_msg.lower():
                error_msg = "Division by zero! Even ANUS has its limits."
            elif "invalid syntax" in error_msg.lower():
                error_msg = "Invalid syntax! ANUS is confused by your notation."
            
            logging.error(f"Error in calculator tool: {e}")
            return ToolResult.error(self.name, f"Calculation error: {error_msg}")
    
    def validate_input(self, expression: str = None, **kwargs) -> bool:
        """
        Validate the input parameters.
        
        Args:
            expression: The mathematical expression to validate.
            **kwargs: Additional parameters (ignored).
            
        Returns:
            True if the input is valid, False otherwise.
        """
        if expression is None:
            return False
        
        try:
            self._validate_expression(expression)
            return True
        except:
            return False
    
    def _validate_expression(self, expression: str) -> None:
        """
        Validate that an expression is safe to evaluate.
        
        Args:
            expression: The expression to validate.
            
        Raises:
            ValueError: If the expression contains unsafe elements.
        """
        # Check for common unsafe patterns
        unsafe_patterns = [
            "__", "import", "eval", "exec", "compile", "open", 
            "file", "os.", "sys.", "subprocess", "lambda"
        ]
        
        for pattern in unsafe_patterns:
            if pattern in expression:
                logging.warning(f"ANUS detected a potential security breach: {pattern}")
                raise ValueError(f"Expression contains unsafe pattern: {pattern}. ANUS refuses to process this.")
        
        # Only allow basic arithmetic operations and numeric literals
        allowed_chars = set("0123456789.+-*/() ")
        for char in expression:
            if char not in allowed_chars:
                logging.warning(f"ANUS caught an illegal character: {char}")
                raise ValueError(f"Expression contains disallowed character: {char}. ANUS only does basic arithmetic.")
    
    def _safe_math_context(self) -> Dict[str, Any]:
        """
        Create a safe context for math operations.
        
        Returns:
            A dictionary with allowed mathematical functions.
        """
        import math
        
        # Allow only safe math functions
        return {
            "abs": abs,
            "max": max,
            "min": min,
            "pow": pow,
            "round": round,
            "sum": sum,
            # Add some math module functions
            "sqrt": math.sqrt,
            "sin": math.sin,
            "cos": math.cos,
            "tan": math.tan,
            "pi": math.pi,
            "e": math.e
        }
```

## anus/tools/utility/__init__.py

- Characters: 244
- Tokens: 0

```python
"""
Utility tools for the ANUS framework.

This module contains basic utility tools:
- CalculatorTool: Tool for performing basic arithmetic calculations
"""

from anus.tools.utility.calculator import CalculatorTool

__all__ = ["CalculatorTool"]
```

## anus/tools/base/tool_result.py

- Characters: 3192
- Tokens: 0

```python
"""
Tool Result module for standardized result handling.
"""

from typing import Dict, List, Any, Optional, Union
import time

class ToolResult:
    """
    Standardized container for tool execution results.
    
    Provides consistent structure and metadata for tool results.
    """
    
    def __init__(
        self, 
        tool_name: str,
        status: str = "success",
        result: Any = None,
        error: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ):
        """
        Initialize a ToolResult instance.
        
        Args:
            tool_name: Name of the tool that produced the result.
            status: Status of the tool execution ("success" or "error").
            result: The actual result data.
            error: Error message if status is "error".
            metadata: Additional metadata about the execution.
        """
        self.tool_name = tool_name
        self.status = status
        self.result = result
        self.error = error
        self.metadata = metadata or {}
        
        # Add timestamp
        self.timestamp = time.time()
    
    def to_dict(self) -> Dict[str, Any]:
        """
        Convert the result to a dictionary.
        
        Returns:
            A dictionary representation of the result.
        """
        result_dict = {
            "tool_name": self.tool_name,
            "status": self.status,
            "timestamp": self.timestamp,
            "metadata": self.metadata
        }
        
        if self.status == "success":
            result_dict["result"] = self.result
        elif self.status == "error":
            result_dict["error"] = self.error
        
        return result_dict
    
    @classmethod
    def success(cls, tool_name: str, result: Any, metadata: Optional[Dict[str, Any]] = None) -> 'ToolResult':
        """
        Create a successful result.
        
        Args:
            tool_name: Name of the tool.
            result: The result data.
            metadata: Additional metadata.
            
        Returns:
            A ToolResult instance with success status.
        """
        return cls(tool_name=tool_name, status="success", result=result, metadata=metadata)
    
    @classmethod
    def error(cls, tool_name: str, error: str, metadata: Optional[Dict[str, Any]] = None) -> 'ToolResult':
        """
        Create an error result.
        
        Args:
            tool_name: Name of the tool.
            error: The error message.
            metadata: Additional metadata.
            
        Returns:
            A ToolResult instance with error status.
        """
        return cls(tool_name=tool_name, status="error", error=error, metadata=metadata)
    
    def is_success(self) -> bool:
        """
        Check if the result is successful.
        
        Returns:
            True if the status is "success", False otherwise.
        """
        return self.status == "success"
    
    def is_error(self) -> bool:
        """
        Check if the result is an error.
        
        Returns:
            True if the status is "error", False otherwise.
        """
        return self.status == "error"
```

## anus/tools/base/tool.py

- Characters: 1671
- Tokens: 0

```python
"""
Base Tool module that defines the common interface for all tools.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Union

class BaseTool(ABC):
    """
    Abstract base class for all tools in the ANUS framework.
    
    Provides the core functionality and interface that all tool types must implement.
    """
    
    name = "base_tool"
    description = "Base class for all tools"
    
    def __init__(self, **kwargs):
        """
        Initialize a BaseTool instance.
        
        Args:
            **kwargs: Additional configuration options for the tool.
        """
        self.config = kwargs
    
    @abstractmethod
    def execute(self, **kwargs) -> Any:
        """
        Execute the tool's function.
        
        Args:
            **kwargs: Input parameters for the tool.
            
        Returns:
            The result of the tool execution.
        """
        pass
    
    def validate_input(self, **kwargs) -> bool:
        """
        Validate the input parameters.
        
        Args:
            **kwargs: Input parameters to validate.
            
        Returns:
            True if the input is valid, False otherwise.
        """
        # Base implementation is a pass-through
        return True
    
    def get_schema(self) -> Dict[str, Any]:
        """
        Get the tool's parameter schema.
        
        Returns:
            A dictionary describing the tool's parameters.
        """
        # Base implementation returns a simple schema
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {}
        }
```

## anus/tools/base/__init__.py

- Characters: 463
- Tokens: 0

```python
"""
Base Tool module for the ANUS framework.

This module contains base classes for tools:
- BaseTool: Abstract base class for all tools
- ToolResult: Standardized container for tool results
- ToolCollection: Utility for managing collections of tools
"""

from anus.tools.base.tool import BaseTool
from anus.tools.base.tool_result import ToolResult
from anus.tools.base.tool_collection import ToolCollection

__all__ = ["BaseTool", "ToolResult", "ToolCollection"]
```

## anus/tools/base/tool_collection.py

- Characters: 6073
- Tokens: 0

```python
"""
Tool Collection module for managing collections of tools.
"""

from typing import Dict, List, Any, Optional, Type, Union
import importlib
import inspect
import logging
import os
import pkgutil

from anus.tools.base.tool import BaseTool

class ToolCollection:
    """
    A collection of tools with registration and discovery capabilities.
    
    Provides functionality for:
    - Registering tools
    - Loading tools dynamically
    - Tool discovery
    - Tool execution
    """
    
    def __init__(self):
        """
        Initialize a ToolCollection instance.
        """
        self.tools: Dict[str, BaseTool] = {}
        self.tool_classes: Dict[str, Type[BaseTool]] = {}
    
    def register_tool(self, tool: BaseTool) -> None:
        """
        Register a tool instance.
        
        Args:
            tool: The tool instance to register.
        """
        self.tools[tool.name] = tool
        logging.info(f"Registered tool: {tool.name}")
    
    def register_tool_class(self, tool_class: Type[BaseTool]) -> None:
        """
        Register a tool class for later instantiation.
        
        Args:
            tool_class: The tool class to register.
        """
        name = getattr(tool_class, "name", tool_class.__name__.lower())
        self.tool_classes[name] = tool_class
        logging.info(f"Registered tool class: {name}")
    
    def get_tool(self, name: str) -> Optional[BaseTool]:
        """
        Get a tool by name.
        
        Args:
            name: The name of the tool.
            
        Returns:
            The tool instance, or None if not found.
        """
        # Check if the tool is already instantiated
        if name in self.tools:
            return self.tools[name]
        
        # Check if we have the tool class and can instantiate it
        if name in self.tool_classes:
            try:
                tool = self.tool_classes[name]()
                self.register_tool(tool)
                return tool
            except Exception as e:
                logging.error(f"Error instantiating tool {name}: {e}")
                return None
        
        # Tool not found
        return None
    
    def execute_tool(self, name: str, **kwargs) -> Any:
        """
        Execute a tool by name.
        
        Args:
            name: The name of the tool to execute.
            **kwargs: Input parameters for the tool.
            
        Returns:
            The result of the tool execution, or an error message.
        """
        tool = self.get_tool(name)
        
        if tool is None:
            error_msg = f"Tool not found: {name}"
            logging.error(error_msg)
            return {"status": "error", "error": error_msg}
        
        try:
            # Validate input
            if not tool.validate_input(**kwargs):
                error_msg = f"Invalid input for tool {name}"
                logging.error(error_msg)
                return {"status": "error", "error": error_msg}
            
            # Execute the tool
            result = tool.execute(**kwargs)
            return {"status": "success", "result": result}
        except Exception as e:
            error_msg = f"Error executing tool {name}: {str(e)}"
            logging.error(error_msg)
            return {"status": "error", "error": error_msg}
    
    def list_tools(self) -> List[Dict[str, Any]]:
        """
        List all available tools.
        
        Returns:
            A list of tool information dictionaries.
        """
        tool_info = []
        
        # Add instantiated tools
        for name, tool in self.tools.items():
            info = {
                "name": name,
                "description": getattr(tool, "description", "No description available"),
                "parameters": getattr(tool, "parameters", {})
            }
            tool_info.append(info)
        
        # Add non-instantiated tool classes
        for name, tool_class in self.tool_classes.items():
            if name not in self.tools:
                info = {
                    "name": name,
                    "description": getattr(tool_class, "description", "No description available"),
                    "parameters": getattr(tool_class, "parameters", {})
                }
                tool_info.append(info)
        
        return tool_info
    
    def discover_tools(self, package_name: str = "anus.tools") -> int:
        """
        Discover tools in the specified package.
        
        Args:
            package_name: The package to search for tools.
            
        Returns:
            The number of tools discovered.
        """
        count = 0
        
        try:
            package = importlib.import_module(package_name)
            for _, name, is_pkg in pkgutil.iter_modules(package.__path__, package.__name__ + "."):
                if is_pkg:
                    # Recursively discover tools in subpackages
                    count += self.discover_tools(name)
                else:
                    # Import the module
                    try:
                        module = importlib.import_module(name)
                        
                        # Find tool classes in the module
                        for attr_name in dir(module):
                            attr = getattr(module, attr_name)
                            
                            # Check if it's a tool class
                            if (
                                inspect.isclass(attr) and 
                                issubclass(attr, BaseTool) and 
                                attr != BaseTool
                            ):
                                self.register_tool_class(attr)
                                count += 1
                    except Exception as e:
                        logging.error(f"Error discovering tools in module {name}: {e}")
        except Exception as e:
            logging.error(f"Error discovering tools in package {package_name}: {e}")
        
        return count
```

## anus/tools/__init__.py

- Characters: 282
- Tokens: 0

```python
"""
Tools module for the ANUS framework.

This module contains various tools that can be used by agents to interact with 
the environment and perform tasks.
"""

from anus.tools.base import BaseTool, ToolResult, ToolCollection

__all__ = ["BaseTool", "ToolResult", "ToolCollection"]
```

## anus/models/README.md

- Characters: 703
- Tokens: 0

```markdown
# Anus Models Module

This module contains the model integration components of the Anus AI framework, including:

- OpenAI API Support
- Open-Source Model Support
- Model Switching and Fallback Mechanisms
- Vision Model Integration

## Components

### base_model.py
Base class for all model integrations with common functionality.

### openai_model.py
Integration with OpenAI API models (GPT-4, etc.).

### open_source_model.py
Integration with open-source models (Llama, Mistral, etc.).

### vision_model.py
Integration with vision models for image understanding.

### model_manager.py
Model selection, switching, and fallback mechanisms.

### config.py
Configuration management for model integrations.
```

## anus/models/base/base_model.py

- Characters: 5096
- Tokens: 0

```python
"""
Base Model module that defines the common interface for all language models.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Union, Callable
from pydantic import BaseModel as PydanticBaseModel


class ToolCall(PydanticBaseModel):
    """Represents a tool call from a language model."""

    id: str
    type: str = "function"
    function: Dict[str, Any]


class ModelResponse(PydanticBaseModel):
    """Represents a response from a language model."""

    content: Optional[str] = None
    tool_calls: Optional[List[ToolCall]] = None


class BaseModel(ABC):
    """
    Abstract base class for language model implementations.

    Provides a common interface for interacting with different LLM providers.
    """

    def __init__(
        self,
        model_name: str,
        temperature: float = 0.0,
        max_tokens: Optional[int] = None,
        **kwargs
    ):
        """
        Initialize a BaseModel instance.

        Args:
            model_name: The name of the model to use.
            temperature: Controls randomness in outputs. Lower values are more deterministic.
            max_tokens: Maximum number of tokens to generate.
            **kwargs: Additional model-specific parameters.
        """
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.config = kwargs

    @abstractmethod
    def generate(
        self,
        prompt: str,
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Generate text based on a prompt.

        Args:
            prompt: The text prompt for generation.
            system_message: Optional system message for models that support it.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional model-specific parameters.

        Returns:
            The generated text response.
        """
        pass

    @abstractmethod
    def generate_with_tools(
        self,
        prompt: str,
        tools: List[Dict[str, Any]],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Generate text with tool calling capabilities.

        Args:
            prompt: The text prompt for generation.
            tools: List of tool schemas available for use.
            system_message: Optional system message for models that support it.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional model-specific parameters.

        Returns:
            A dictionary with the response and any tool calls.
        """
        pass

    @abstractmethod
    def extract_json(
        self,
        prompt: str,
        schema: Dict[str, Any],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Extract structured JSON data based on a prompt.

        Args:
            prompt: The text prompt for extraction.
            schema: JSON schema describing the expected structure.
            system_message: Optional system message for models that support it.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional model-specific parameters.

        Returns:
            The extracted JSON data.
        """
        pass

    @abstractmethod
    def get_embedding(self, text: str, **kwargs) -> List[float]:
        """
        Generate an embedding vector for the given text.

        Args:
            text: The text to embed.
            **kwargs: Additional model-specific parameters.

        Returns:
            The embedding vector as a list of floats.
        """
        pass

    def get_token_count(self, text: str) -> int:
        """
        Estimate the number of tokens in the given text.

        Args:
            text: The text to count tokens for.

        Returns:
            The approximate token count.
        """
        # Simple approximation: 1 token ‚âà 4 characters
        return len(text) // 4

    def get_model_details(self) -> Dict[str, Any]:
        """
        Get details about the model.

        Returns:
            A dictionary containing model information.
        """
        return {
            "model_name": self.model_name,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "config": self.config,
        }
```

## anus/models/base/__init__.py

- Characters: 232
- Tokens: 0

```python
"""
Base Models module for the ANUS framework.

This module contains the base model interfaces:
- BaseModel: Abstract base class for all language models
"""

from anus.models.base.base_model import BaseModel

__all__ = ["BaseModel"]
```

## anus/models/model_router.py

- Characters: 6261
- Tokens: 0

```python
"""
Model Router module for dynamic model selection.
"""

from typing import Dict, List, Any, Optional, Union, Type
import logging

from anus.models.base.base_model import BaseModel
from anus.models.gemini_model import GeminiModel
from anus.models.openai_model import OpenAIModel


class ModelRouter:
    """
    Router for dynamically selecting and managing language models.

    Provides functionality for:
    - Registering different model implementations
    - Selecting models based on task requirements
    - Fallback mechanisms for reliability
    """

    def __init__(self, default_model_config: Optional[Dict[str, Any]] = None):
        """
        Initialize a ModelRouter instance.

        Args:
            default_model_config: Configuration for the default model.
        """
        self.models: Dict[str, BaseModel] = {}
        self.model_classes: Dict[str, Type[BaseModel]] = {
            # "openai": OpenAIModel,
            "gemini": GeminiModel,
        }
        self.default_model_config = default_model_config or {
            "provider": "gemini",
            "model_name": "gemini-2.0-flash",
            "temperature": 0.0,
        }
        self.default_model = None

    def register_model(self, name: str, model: BaseModel) -> None:
        """
        Register a model instance.

        Args:
            name: A unique name for the model.
            model: The model instance to register.
        """
        self.models[name] = model
        logging.info(f"Registered model: {name}")

    def register_model_class(self, provider: str, model_class: Type[BaseModel]) -> None:
        """
        Register a model class for a provider.

        Args:
            provider: The model provider name.
            model_class: The model class to register.
        """
        self.model_classes[provider] = model_class
        logging.info(f"Registered model class for provider: {provider}")

    def get_model(self, name_or_config: Union[str, Dict[str, Any]]) -> BaseModel:
        """
        Get a model instance by name or create one from config.

        Args:
            name_or_config: Either a model name or a model configuration dictionary.

        Returns:
            A model instance.
        """
        # If it's a string, look up by name
        if isinstance(name_or_config, str):
            # Check registered models
            if name_or_config in self.models:
                return self.models[name_or_config]

            # If not found, use default model
            logging.warning(f"Model '{name_or_config}' not found. Using default model.")
            return self.get_default_model()

        # If it's a config dict, create a new model
        elif isinstance(name_or_config, dict):
            return self._create_model_from_config(name_or_config)

        # Invalid input
        else:
            logging.error(f"Invalid model specification: {name_or_config}")
            return self.get_default_model()

    def get_default_model(self) -> BaseModel:
        """
        Get the default model, creating it if necessary.

        Returns:
            The default model instance.
        """
        if self.default_model is None:
            self.default_model = self._create_model_from_config(
                self.default_model_config
            )

        return self.default_model

    def select_model_for_task(
        self, task: str, requirements: Dict[str, Any] = None
    ) -> BaseModel:
        """
        Select an appropriate model for a given task.

        Args:
            task: The task description.
            requirements: Optional requirements for the model.

        Returns:
            The selected model instance.
        """
        # Simple implementation: just use requirements if provided
        if requirements:
            return self._create_model_from_config(requirements)

        # Default to the default model
        return self.get_default_model()

    def _create_model_from_config(self, config: Dict[str, Any]) -> BaseModel:
        """
        Create a model instance from a configuration dictionary.

        Args:
            config: The model configuration.

        Returns:
            A model instance.
        """
        # Get the provider
        provider = config.get("provider", "openai").lower()

        # Check if we have a class for this provider
        if provider not in self.model_classes:
            logging.error(
                f"Unknown model provider: {provider}. Using OpenAI as fallback."
            )
            provider = "openai"

        try:
            # Get the model class
            model_class = self.model_classes[provider]

            # Extract kwargs for the model
            kwargs = config.copy()
            kwargs.pop("provider", None)

            # Create the model
            return model_class(**kwargs)

        except Exception as e:
            logging.error(f"Error creating model for provider {provider}: {e}")

            # Fallback to OpenAI with minimal config
            try:
                return OpenAIModel(model_name="gpt-4")
            except Exception:
                raise ValueError(f"Failed to create model: {e}")

    def list_available_models(self) -> List[Dict[str, Any]]:
        """
        List all available models.

        Returns:
            A list of model information dictionaries.
        """
        models_info = []

        # Add instantiated models
        for name, model in self.models.items():
            info = {
                "name": name,
                "type": type(model).__name__,
                "model_name": model.model_name,
                "details": model.get_model_details(),
            }
            models_info.append(info)

        # Add available providers
        for provider in self.model_classes.keys():
            if provider not in [
                info["details"].get("provider") for info in models_info
            ]:
                models_info.append(
                    {
                        "name": f"{provider}",
                        "type": self.model_classes[provider].__name__,
                        "details": {"provider": provider},
                    }
                )

        return models_info
```

## anus/models/gemini_model.py

- Characters: 10699
- Tokens: 0

```python
"""
Google Gemini Model implementation for the ANUS framework.
"""

from typing import Dict, List, Optional, Union, Any
import json
import os
import logging
from pydantic import Field

# Import from the new SDK
from google import genai 
from google.genai import types as genai_types

from anus.models.base.base_model import BaseModel, ToolCall

class GeminiModel(BaseModel):
    """
    Google Gemini API integration for language models.
    Supports Gemini 2.0 models.
    """
    
    provider: str = "gemini"
    model_name: str = "gemini-2.0-flash"  # Default model
    api_key: Optional[str] = Field(default_factory=lambda: os.environ.get("GOOGLE_API_KEY"))
    base_url: Optional[str] = None
    temperature: float = 0.0
    max_tokens: Optional[int] = None
    
    def __init__(self, **data):
        super().__init__(**data)
        
        if not self.api_key:
            raise ValueError("Google API key is required. Set GOOGLE_API_KEY environment variable or pass api_key parameter.")
        
        # Initialize the client with our API key
        self.client = genai.Client(api_key=self.api_key)
    
    async def generate(
        self, 
        prompt: str, 
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Generate text based on a prompt using Google Gemini.
        
        Args:
            prompt: The text prompt for generation.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional Gemini-specific parameters.
            
        Returns:
            The generated text response.
        """
        # Create configuration
        config = {}
        
        # Add system instruction if provided
        if system_message:
            config["system_instruction"] = system_message
            
        # Add other parameters
        if temperature is not None:
            config["temperature"] = temperature
        elif self.temperature is not None:
            config["temperature"] = self.temperature
            
        if max_tokens is not None:
            config["max_output_tokens"] = max_tokens
        elif self.max_tokens is not None:
            config["max_output_tokens"] = self.max_tokens
        
        try:
            # Generate response
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=config
            )
            
            return response.text
        
        except Exception as e:
            logging.error(f"Error generating with Gemini: {e}")
            return f"Error: {str(e)}"
    
    async def generate_with_tools(
        self, 
        prompt: str, 
        tools: List[Dict[str, Any]],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Generate text with tool calling capabilities.
        
        Args:
            prompt: The text prompt for generation.
            tools: List of tool schemas available for use.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional Gemini-specific parameters.
            
        Returns:
            A dictionary with the response and any tool calls.
        """
        # Convert our tools to Gemini format
        gemini_tools = []
        for tool in tools:
            function = tool.get("function", {})
            
            # Create function declaration
            function_declaration = genai_types.FunctionDeclaration(
                name=function.get("name", ""),
                description=function.get("description", ""),
                parameters=function.get("parameters", {})
            )
            
            # Add to tools list
            gemini_tools.append(genai_types.Tool(
                function_declarations=[function_declaration]
            ))
        
        # Create configuration
        config = {}
        
        # Add system instruction if provided
        if system_message:
            config["system_instruction"] = system_message
            
        # Add parameters
        if temperature is not None:
            config["temperature"] = temperature
        elif self.temperature is not None:
            config["temperature"] = self.temperature
            
        if max_tokens is not None:
            config["max_output_tokens"] = max_tokens
        elif self.max_tokens is not None:
            config["max_output_tokens"] = self.max_tokens
            
        # Add tools and tool choice settings
        if gemini_tools:
            config["tools"] = gemini_tools
            
            # Handle tool choice
            tool_choice = kwargs.get("tool_choice", "auto")
            if tool_choice == "required":
                config["automatic_function_calling"] = {"disable": False}
            elif tool_choice == "none":
                config["automatic_function_calling"] = {"disable": True}
            # "auto" is the default in Gemini
        
        try:
            # Generate response with tools
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=config
            )
            
            # Extract content and tool calls
            content = response.text
            tool_calls = []
            
            # Process tool calls if present
            if hasattr(response, "candidates") and response.candidates:
                for candidate in response.candidates:
                    if hasattr(candidate, "content") and candidate.content.parts:
                        for part in candidate.content.parts:
                            if hasattr(part, "function_call"):
                                # Convert to our ToolCall format
                                tool_calls.append(
                                    ToolCall(
                                        id=str(len(tool_calls)),
                                        type="function",
                                        function={
                                            "name": part.function_call.name,
                                            "arguments": part.function_call.args
                                        }
                                    )
                                )
            
            return {
                "content": content,
                "tool_calls": tool_calls
            }
            
        except Exception as e:
            logging.error(f"Error generating with tools using Gemini: {e}")
            return {
                "content": f"Error: {str(e)}",
                "tool_calls": []
            }
    
    async def extract_json(
        self, 
        prompt: str, 
        schema: Dict[str, Any],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Extract structured JSON data based on a prompt.
        
        Args:
            prompt: The text prompt for extraction.
            schema: JSON schema describing the expected structure.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional Gemini-specific parameters.
            
        Returns:
            The extracted JSON data.
        """
        # Create configuration
        config = {
            "response_mime_type": "application/json",
            "response_schema": schema
        }
        
        # Add system instruction if provided
        if system_message:
            config["system_instruction"] = system_message
            
        # Add parameters
        if temperature is not None:
            config["temperature"] = temperature
        elif self.temperature is not None:
            config["temperature"] = self.temperature
            
        if max_tokens is not None:
            config["max_output_tokens"] = max_tokens
        elif self.max_tokens is not None:
            config["max_output_tokens"] = self.max_tokens
        
        try:
            # Generate response
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=config
            )
            
            # The SDK may have parsed JSON automatically
            if hasattr(response, "parsed"):
                return response.parsed
            
            # Otherwise try to parse the JSON
            try:
                return json.loads(response.text)
            except json.JSONDecodeError:
                logging.error(f"Failed to parse JSON from response: {response.text}")
                return {"error": "Failed to parse JSON response"}
                
        except Exception as e:
            logging.error(f"Error extracting JSON with Gemini: {e}")
            return {"error": str(e)}
    
    async def get_embedding(self, text: str, **kwargs) -> List[float]:
        """
        Generate an embedding vector for the given text.
        
        Args:
            text: The text to embed.
            **kwargs: Additional Gemini-specific parameters.
            
        Returns:
            The embedding vector as a list of floats.
        """
        try:
            # Generate embeddings using the embedding model
            response = self.client.models.embed_content(
                model="text-embedding-004",  # Default embedding model
                contents=text
            )
            
            # Extract the embedding values
            if hasattr(response, "embedding"):
                return response.embedding.values
            
            return []
            
        except Exception as e:
            logging.error(f"Error generating embedding with Gemini: {e}")
            return []
```

## anus/models/__init__.py

- Characters: 542
- Tokens: 0

```python
"""
Models module for the ANUS framework.

This module contains language model implementations and utilities:
- BaseModel: Abstract base class for all language models
- OpenAIModel: Implementation for the OpenAI API
- ModelRouter: Dynamic model selection based on task requirements
"""

from anus.models.base import BaseModel
from anus.models.openai_model import OpenAIModel
from anus.models.gemini_model import GeminiModel
from anus.models.model_router import ModelRouter

__all__ = ["BaseModel", "OpenAIModel", "GeminiModel", "ModelRouter"]
```

## anus/models/openai_model.py

- Characters: 10815
- Tokens: 0

```python
"""
OpenAI Model implementation for the ANUS framework.
"""

from typing import Dict, List, Any, Optional, Union, Callable
import json
import logging
import os

try:
    import openai
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from anus.models.base.base_model import BaseModel

class OpenAIModel(BaseModel):
    """
    OpenAI language model implementation.
    
    Provides integration with OpenAI's API for text generation and embeddings.
    """
    
    def __init__(
        self, 
        model_name: str = "gpt-4", 
        temperature: float = 0.0,
        max_tokens: Optional[int] = None,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        **kwargs
    ):
        """
        Initialize an OpenAIModel instance.
        
        Args:
            model_name: The name of the OpenAI model to use.
            temperature: Controls randomness in outputs. Lower values are more deterministic.
            max_tokens: Maximum number of tokens to generate.
            api_key: OpenAI API key. If None, it will be read from the OPENAI_API_KEY environment variable.
            base_url: Base URL for the OpenAI API. Useful for proxies or non-standard endpoints.
            **kwargs: Additional model-specific parameters.
        """
        super().__init__(model_name, temperature, max_tokens, **kwargs)
        
        if not OPENAI_AVAILABLE:
            logging.error("OpenAI package not installed. Please install it with 'pip install openai'.")
            raise ImportError("OpenAI package not installed")
        
        # Use provided API key or read from environment
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY")
        if not self.api_key:
            logging.error("OpenAI API key not provided and not found in environment.")
            raise ValueError("OpenAI API key required")
        
        self.base_url = base_url
        
        # Initialize client
        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)
        
        # Set default embedding model
        self.embedding_model = kwargs.get("embedding_model", "text-embedding-ada-002")
    
    def generate(
        self, 
        prompt: str, 
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Generate text based on a prompt using OpenAI.
        
        Args:
            prompt: The text prompt for generation.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional OpenAI-specific parameters.
            
        Returns:
            The generated text response.
        """
        # Prepare messages
        messages = []
        
        # Add system message if provided
        if system_message:
            messages.append({"role": "system", "content": system_message})
        
        # Add user message
        messages.append({"role": "user", "content": prompt})
        
        # Set parameters
        temp = temperature if temperature is not None else self.temperature
        tokens = max_tokens if max_tokens is not None else self.max_tokens
        
        try:
            # Make the API call
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=temp,
                max_tokens=tokens,
                **kwargs
            )
            
            # Extract and return the response text
            return response.choices[0].message.content
        
        except Exception as e:
            logging.error(f"Error generating with OpenAI: {e}")
            return f"Error: {str(e)}"
    
    def generate_with_tools(
        self, 
        prompt: str, 
        tools: List[Dict[str, Any]],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Generate text with tool calling capabilities.
        
        Args:
            prompt: The text prompt for generation.
            tools: List of tool schemas available for use.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional OpenAI-specific parameters.
            
        Returns:
            A dictionary with the response and any tool calls.
        """
        # Prepare messages
        messages = []
        
        # Add system message if provided
        if system_message:
            messages.append({"role": "system", "content": system_message})
        
        # Add user message
        messages.append({"role": "user", "content": prompt})
        
        # Set parameters
        temp = temperature if temperature is not None else self.temperature
        tokens = max_tokens if max_tokens is not None else self.max_tokens
        
        # Convert tools to OpenAI format
        openai_tools = []
        for tool in tools:
            openai_tool = {
                "type": "function",
                "function": {
                    "name": tool.get("name", ""),
                    "description": tool.get("description", ""),
                    "parameters": tool.get("parameters", {})
                }
            }
            openai_tools.append(openai_tool)
        
        try:
            # Make the API call
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=temp,
                max_tokens=tokens,
                tools=openai_tools,
                **kwargs
            )
            
            # Extract response
            choice = response.choices[0]
            message = choice.message
            
            # Check for tool calls
            if hasattr(message, "tool_calls") and message.tool_calls:
                tool_calls = []
                for tool_call in message.tool_calls:
                    # Parse arguments as JSON
                    try:
                        arguments = json.loads(tool_call.function.arguments)
                    except:
                        arguments = tool_call.function.arguments
                    
                    # Create a normalized tool call
                    normalized_tool_call = {
                        "id": tool_call.id,
                        "name": tool_call.function.name,
                        "arguments": arguments
                    }
                    tool_calls.append(normalized_tool_call)
                
                return {
                    "content": message.content,
                    "tool_calls": tool_calls
                }
            else:
                # No tool calls, just text
                return {
                    "content": message.content,
                    "tool_calls": []
                }
        
        except Exception as e:
            logging.error(f"Error generating with tools using OpenAI: {e}")
            return {
                "content": f"Error: {str(e)}",
                "tool_calls": []
            }
    
    def extract_json(
        self, 
        prompt: str, 
        schema: Dict[str, Any],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Extract structured JSON data based on a prompt.
        
        Args:
            prompt: The text prompt for extraction.
            schema: JSON schema describing the expected structure.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional OpenAI-specific parameters.
            
        Returns:
            The extracted JSON data.
        """
        # Set default system message if not provided
        if not system_message:
            system_message = "Extract the requested information and respond only with a valid JSON object according to the specified schema. Do not include any other text."
        
        # Set parameters
        temp = temperature if temperature is not None else self.temperature
        tokens = max_tokens if max_tokens is not None else self.max_tokens
        
        # Make the API call with response format JSON
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": f"Schema: {json.dumps(schema)}\n\nPrompt: {prompt}"}
                ],
                temperature=temp,
                max_tokens=tokens,
                response_format={"type": "json_object"},
                **kwargs
            )
            
            # Extract and parse the response
            content = response.choices[0].message.content
            
            try:
                return json.loads(content)
            except json.JSONDecodeError:
                logging.error(f"Failed to parse JSON from response: {content}")
                return {"error": "Failed to parse JSON response"}
        
        except Exception as e:
            logging.error(f"Error extracting JSON with OpenAI: {e}")
            return {"error": str(e)}
    
    def get_embedding(self, text: str, **kwargs) -> List[float]:
        """
        Generate an embedding vector for the given text.
        
        Args:
            text: The text to embed.
            **kwargs: Additional OpenAI-specific parameters.
            
        Returns:
            The embedding vector as a list of floats.
        """
        try:
            response = self.client.embeddings.create(
                model=self.embedding_model,
                input=text,
                **kwargs
            )
            
            return response.data[0].embedding
        
        except Exception as e:
            logging.error(f"Error generating embedding with OpenAI: {e}")
            return []
```

## anus/agents/README.md

- Characters: 698
- Tokens: 0

```markdown
# Anus Agents Module

This module contains the agent system components of the Anus AI framework, including:

- Single-Agent Mode
- Multi-Agent Collaboration Mode
- Agent Role Definition Framework
- Inter-Agent Communication Protocol

## Components

### base_agent.py
Base class for all agent types with common functionality.

### single_agent.py
Simplified agent implementation for straightforward tasks.

### multi_agent.py
Implementation of multi-agent collaboration system.

### roles.py
Predefined agent role templates and custom role creation capabilities.

### communication.py
Inter-agent communication protocol and message handling.

### registry.py
Agent registration and discovery system.
```

## anus/ui/README.md

- Characters: 541
- Tokens: 0

```markdown
# Anus UI Module

This module contains the user interface components of the Anus AI framework, including:

- Command-Line Interface
- Web Interface (Optional)
- API for Integration with Other Systems

## Components

### cli.py
Command-line interface for interacting with the Anus AI agent.

### web_interface.py
Optional web-based user interface for the Anus AI agent.

### api.py
RESTful API for integration with external systems.

### utils.py
Utility functions for UI components.

### config.py
Configuration management for UI components.
```

## anus/ui/cli.py

- Characters: 12287
- Tokens: 0

```python
"""
Command-line interface for the ANUS framework.

Remember: With great ANUS comes great responsibility.
"""

import os
import sys
import time
import json
import logging
import cmd
import shutil
import random
from typing import Dict, List, Any, Optional, Union
from datetime import datetime

from anus.core.orchestrator import AgentOrchestrator

class CLI(cmd.Cmd):
    """
    Command-line interface for interacting with the ANUS framework.
    
    Provides commands for:
    - Executing tasks
    - Managing agents
    - Viewing task history
    - Configuration
    
    Warning: Prolonged exposure to ANUS may cause uncontrollable smirking.
    """
    
    intro = "Welcome to the ANUS framework. Type help or ? to list commands."
    prompt = "anus> "
    
    # Easter egg jokes for random display
    _anus_jokes = [
        "ANUS: Because 'Autonomous Networked Utility System' sounds better in meetings.",
        "ANUS: The backend system that handles all your crap.",
        "ANUS: Boldly going where no framework has gone before.",
        "ANUS: It's not a bug, it's a feature... a very uncomfortable feature.",
        "ANUS: For when your code needs that extra push from behind.",
        "ANUS: Working hard so you don't have to explain the acronym to your boss.",
        "ANUS: The framework that makes other developers snicker during code review.",
        "ANUS: Tight integration with your backend systems.",
        "ANUS: Because 'BUTT' was already taken as an acronym.",
        "ANUS: Making developers uncomfortable in stand-up meetings since 2023."
    ]
    
    def __init__(self, verbose: bool = False, config_path: str = "config.yaml"):
        """
        Initialize a CLI instance.
        
        Args:
            verbose: Whether to enable verbose output.
            config_path: Path to the configuration file.
        """
        super().__init__()
        self.verbose = verbose
        self.config_path = config_path
        self.orchestrator = None
        self.current_result = None
        self.history = []
        self.joke_counter = 0  # Track number of commands for occasional jokes
        
        # Set up logging
        log_level = logging.DEBUG if verbose else logging.INFO
        logging.basicConfig(
            level=log_level,
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )
    
    def display_welcome(self) -> None:
        """
        Display a welcome message.
        
        Includes a random ANUS joke to brighten your day.
        """
        term_width = shutil.get_terminal_size().columns
        
        print("=" * term_width)
        print("ANUS - Autonomous Networked Utility System".center(term_width))
        print("=" * term_width)
        print(random.choice(self._anus_jokes).center(term_width))
        print("=" * term_width)
        print("Type 'help' or '?' to list available commands.".center(term_width))
        print("=" * term_width)
        print()
    
    def start_interactive_mode(self, orchestrator: Optional[AgentOrchestrator] = None) -> None:
        """
        Start the interactive command-line interface.
        
        Args:
            orchestrator: Optional orchestrator instance. If not provided, one will be created.
        """
        if orchestrator:
            self.orchestrator = orchestrator
        else:
            self.orchestrator = AgentOrchestrator(config_path=self.config_path)
        
        # Display welcome message if not in stdin mode
        if sys.stdin.isatty():
            self.display_welcome()
        
        # Start the command loop
        self.cmdloop()
    
    def display_result(self, result: Dict[str, Any]) -> None:
        """
        Display the result of a task execution.
        
        Args:
            result: The task execution result.
        """
        self.current_result = result
        
        term_width = shutil.get_terminal_size().columns
        
        print("\n" + "=" * term_width)
        print("TASK RESULT".center(term_width))
        print("=" * term_width)
        
        # Display the task
        task = result.get("task", "Unknown task")
        print(f"Task: {task}")
        
        # Display the answer
        answer = result.get("answer", "No answer provided")
        print("\nAnswer:")
        print(f"{answer}")
        
        # Display additional information if verbose
        if self.verbose:
            print("\nExecution Details:")
            
            # Mode
            mode = result.get("mode", "single")
            print(f"Mode: {mode}")
            
            # Steps or iterations
            if "iterations" in result:
                iterations = result.get("iterations", 0)
                print(f"Iterations: {iterations}")
            elif "steps" in result:
                steps = len(result.get("steps", []))
                completed_steps = len(result.get("completed_steps", []))
                print(f"Steps: {completed_steps}/{steps} completed")
            
            # Display context or not based on verbosity
            if self.verbose and "context" in result:
                print("\nExecution Context:")
                self._pretty_print(result["context"])
        
        print("=" * term_width)
        
        # Occasionally show a joke after results
        self.joke_counter += 1
        if self.joke_counter % 3 == 0:  # Every 3rd result
            print(f"\nANUS Wisdom: {random.choice(self._anus_jokes)}")
    
    def do_task(self, arg: str) -> None:
        """
        Execute a task.
        
        Usage: task [mode] <task description>
        
        Args:
            arg: Task description and optional mode.
        """
        # Make sure orchestrator is initialized
        if not self.orchestrator:
            self.orchestrator = AgentOrchestrator(config_path=self.config_path)
        
        # Parse arguments
        parts = arg.strip().split(maxsplit=1)
        
        if len(parts) == 0 or not arg.strip():
            print("Error: Please provide a task description.")
            print("ANUS can't work with nothing. It needs substance.")
            return
        
        # Check if mode is specified
        mode = None
        task = arg.strip()
        
        if len(parts) > 1 and parts[0] in ["single", "multi", "auto"]:
            mode = parts[0]
            task = parts[1]
        
        # Execute the task
        print(f"Executing task: {task}")
        if mode:
            print(f"Mode: {mode}")
        
        if mode == "multi":
            print("Multiple agents engaged. ANUS is working from all directions...")
        
        try:
            result = self.orchestrator.execute_task(task, mode=mode)
            self.display_result(result)
            
            # Add to history
            self.history.append({
                "timestamp": time.time(),
                "task": task,
                "mode": mode,
                "result": result
            })
            
        except Exception as e:
            print(f"Error executing task: {e}")
            print("Even ANUS has its limits. Please try again.")
    
    def do_agents(self, arg: str) -> None:
        """
        List available agents.
        
        Usage: agents
        """
        # Make sure orchestrator is initialized
        if not self.orchestrator:
            self.orchestrator = AgentOrchestrator(config_path=self.config_path)
        
        agents = self.orchestrator.list_agents()
        
        if not agents:
            print("No agents available.")
            print("ANUS feels empty inside. Please add some agents.")
            return
        
        print("Available Agents:")
        print("-" * 40)
        
        for agent in agents:
            primary = agent.get("primary", False)
            prefix = "* " if primary else "  "
            print(f"{prefix}{agent.get('name', 'Unknown')} ({agent.get('type', 'Unknown')})")
            
            if self.verbose:
                print(f"   ID: {agent.get('id', 'Unknown')}")
            
            print()
            
        print(f"Total agents: {len(agents)}")
        if len(agents) > 5:
            print("Wow, that's a lot to fit in one ANUS!")
    
    def do_history(self, arg: str) -> None:
        """
        Show task execution history.
        
        Usage: history [limit]
        
        Args:
            arg: Optional limit on the number of history items to display.
        """
        # Parse arguments
        limit = 5
        if arg and arg.strip().isdigit():
            limit = int(arg.strip())
        
        # Get history from orchestrator if available
        if self.orchestrator:
            history = self.orchestrator.get_task_history(limit=limit)
        else:
            history = self.history[-limit:] if self.history else []
        
        if not history:
            print("No task history available.")
            print("ANUS is clean as a whistle. No history to report.")
            return
        
        print("Task History:")
        print("-" * 60)
        
        for i, entry in enumerate(reversed(history)):
            timestamp = entry.get("start_time", entry.get("timestamp", 0))
            dt = datetime.fromtimestamp(timestamp)
            task = entry.get("task", "Unknown task")
            mode = entry.get("mode", "single")
            status = entry.get("status", "completed")
            
            print(f"{i+1}. [{dt.strftime('%Y-%m-%d %H:%M:%S')}] ({mode}) {status}")
            print(f"   Task: {task}")
            
            # Show result summary if available
            if "result" in entry and "answer" in entry["result"]:
                answer = entry["result"]["answer"]
                summary = answer[:100] + "..." if len(answer) > 100 else answer
                print(f"   Answer: {summary}")
            
            print()
        
        print(f"Showing {min(len(history), limit)} of {len(history)} total entries.")
        if len(history) > 10:
            print("ANUS has been quite busy, hasn't it?")
    
    def do_config(self, arg: str) -> None:
        """
        Show current configuration.
        
        Usage: config
        """
        # Make sure orchestrator is initialized
        if not self.orchestrator:
            self.orchestrator = AgentOrchestrator(config_path=self.config_path)
        
        print(f"Configuration file: {self.config_path}")
        print("-" * 60)
        
        self._pretty_print(self.orchestrator.config)
        print("\nProTip: A well-configured ANUS is a happy ANUS.")
    
    def do_joke(self, arg: str) -> None:
        """
        Display a random ANUS joke.
        
        Usage: joke
        """
        joke = random.choice(self._anus_jokes)
        
        term_width = shutil.get_terminal_size().columns
        
        print()
        print("=" * term_width)
        print("ANUS WISDOM".center(term_width))
        print("=" * term_width)
        print(joke.center(term_width))
        print("=" * term_width)
        print()
    
    def do_exit(self, arg: str) -> bool:
        """
        Exit the application.
        
        Usage: exit
        """
        print("Exiting ANUS. We hope your experience wasn't too uncomfortable.")
        return True
    
    def do_quit(self, arg: str) -> bool:
        """
        Exit the application.
        
        Usage: quit
        """
        return self.do_exit(arg)
    
    def do_EOF(self, arg: str) -> bool:
        """
        Handle EOF (Ctrl+D).
        """
        print()  # Add a newline
        return self.do_exit(arg)
    
    def emptyline(self) -> None:
        """
        Handle empty lines in the CLI.
        """
        # 1 in 10 chance to show a joke on empty line
        if random.random() < 0.1:
            print(f"ANUS is waiting... {random.choice(self._anus_jokes)}")
    
    def _pretty_print(self, data: Any) -> None:
        """
        Pretty print data.
        
        Args:
            data: Data to print.
        """
        if isinstance(data, (dict, list)):
            try:
                print(json.dumps(data, indent=2))
            except Exception:
                print(data)
        else:
            print(data)
```

## anus/ui/__init__.py

- Characters: 168
- Tokens: 0

```python
"""
UI module for the ANUS framework.

This module contains user interface components:
- CLI: Command-line interface
"""

from anus.ui.cli import CLI

__all__ = ["CLI"]
```

## anus/core/README.md

- Characters: 809
- Tokens: 0

```markdown
# Anus Core Module

This module contains the core functionality of the Anus AI agent system, including:

- Agent Orchestration System
- Task Planning and Execution Framework
- Memory and Context Management
- Tool Integration Interface

## Components

### orchestrator.py
Manages the lifecycle of agents, handles agent creation, destruction, and resource allocation.

### planner.py
Breaks down complex tasks into manageable steps, assigns steps to appropriate agents or tools.

### memory.py
Maintains short-term and long-term memory, manages conversation history and context.

### tool_manager.py
Provides a standardized API for tool integration, tool discovery and registration system.

### config.py
Configuration management for the core module.

### utils.py
Utility functions used across the core module.
```

## anus/core/memory/long_term.py

- Characters: 10936
- Tokens: 0

```python
"""
Long-term memory module for the ANUS framework.
"""

from typing import Dict, List, Any, Optional, Union
import uuid
import time
import json
import os
import logging
from pathlib import Path

from anus.core.memory.base_memory import BaseMemory

class LongTermMemory(BaseMemory):
    """
    Persistent implementation of the BaseMemory interface.
    
    Provides a file-based persistent memory store.
    """
    
    def __init__(
        self, 
        storage_path: Optional[str] = None,
        index_in_memory: bool = True,
        **kwargs
    ):
        """
        Initialize a LongTermMemory instance.
        
        Args:
            storage_path: Path to store memory files. If None, uses a default location.
            index_in_memory: Whether to keep an in-memory index for faster searches.
            **kwargs: Additional configuration options.
        """
        super().__init__(**kwargs)
        
        # Set storage path
        if storage_path is None:
            home_dir = os.path.expanduser("~")
            storage_path = os.path.join(home_dir, ".anus", "memory")
        
        self.storage_path = storage_path
        self.index_in_memory = index_in_memory
        
        # Create storage directory if it doesn't exist
        os.makedirs(self.storage_path, exist_ok=True)
        
        # Create indexes
        self.index: Dict[str, Dict[str, Any]] = {}
        
        # Load index from disk if using in-memory indexing
        if self.index_in_memory:
            self._load_index()
    
    def add(self, item: Dict[str, Any]) -> str:
        """
        Add an item to memory and return its identifier.
        
        Args:
            item: The item to add to memory.
            
        Returns:
            A string identifier for the added item.
        """
        # Generate a unique identifier
        identifier = str(uuid.uuid4())
        
        # Add metadata
        item_with_metadata = item.copy()
        item_with_metadata["_meta"] = {
            "id": identifier,
            "created_at": time.time(),
            "updated_at": time.time()
        }
        
        # Save the item to disk
        self._save_item(identifier, item_with_metadata)
        
        # Update the index
        if self.index_in_memory:
            self.index[identifier] = item_with_metadata
        
        return identifier
    
    def get(self, identifier: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve an item from memory by its identifier.
        
        Args:
            identifier: The identifier of the item to retrieve.
            
        Returns:
            The retrieved item, or None if not found.
        """
        # Check in-memory index first if available
        if self.index_in_memory and identifier in self.index:
            return self.index[identifier]
        
        # Otherwise, load from disk
        item_path = self._get_item_path(identifier)
        if not os.path.exists(item_path):
            return None
        
        try:
            with open(item_path, "r") as f:
                return json.load(f)
        except Exception as e:
            logging.error(f"Error loading item {identifier}: {e}")
            return None
    
    def search(self, query: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:
        """
        Search memory for items matching the query.
        
        Args:
            query: The search query.
            limit: Maximum number of results to return.
            
        Returns:
            A list of matching items.
        """
        results = []
        
        # If using in-memory index, search there
        if self.index_in_memory:
            for identifier, item in self.index.items():
                if self._matches_query(item, query):
                    results.append({
                        "id": identifier,
                        "item": item,
                        "created_at": item.get("_meta", {}).get("created_at", 0)
                    })
                    
                    if len(results) >= limit:
                        break
        else:
            # Otherwise, scan the storage directory
            for item_file in os.listdir(self.storage_path):
                if not item_file.endswith(".json"):
                    continue
                
                identifier = item_file[:-5]  # Remove .json extension
                item = self.get(identifier)
                
                if item and self._matches_query(item, query):
                    results.append({
                        "id": identifier,
                        "item": item,
                        "created_at": item.get("_meta", {}).get("created_at", 0)
                    })
                    
                    if len(results) >= limit:
                        break
        
        # Sort by creation time (newest first)
        results.sort(key=lambda x: x["created_at"], reverse=True)
        
        return results
    
    def update(self, identifier: str, item: Dict[str, Any]) -> bool:
        """
        Update an item in memory.
        
        Args:
            identifier: The identifier of the item to update.
            item: The updated item.
            
        Returns:
            True if the update was successful, False otherwise.
        """
        # Check if the item exists
        existing_item = self.get(identifier)
        if existing_item is None:
            return False
        
        # Preserve metadata
        item_with_metadata = item.copy()
        if "_meta" in existing_item:
            item_with_metadata["_meta"] = existing_item["_meta"]
            item_with_metadata["_meta"]["updated_at"] = time.time()
        else:
            item_with_metadata["_meta"] = {
                "id": identifier,
                "created_at": time.time(),
                "updated_at": time.time()
            }
        
        # Save the updated item
        self._save_item(identifier, item_with_metadata)
        
        # Update the index
        if self.index_in_memory:
            self.index[identifier] = item_with_metadata
        
        return True
    
    def delete(self, identifier: str) -> bool:
        """
        Delete an item from memory.
        
        Args:
            identifier: The identifier of the item to delete.
            
        Returns:
            True if the deletion was successful, False otherwise.
        """
        item_path = self._get_item_path(identifier)
        if not os.path.exists(item_path):
            return False
        
        try:
            os.remove(item_path)
            
            # Update the index
            if self.index_in_memory and identifier in self.index:
                del self.index[identifier]
            
            return True
        except Exception as e:
            logging.error(f"Error deleting item {identifier}: {e}")
            return False
    
    def clear(self) -> None:
        """
        Clear all items from memory.
        """
        for item_file in os.listdir(self.storage_path):
            if not item_file.endswith(".json"):
                continue
            
            try:
                os.remove(os.path.join(self.storage_path, item_file))
            except Exception as e:
                logging.error(f"Error deleting file {item_file}: {e}")
        
        # Clear the index
        if self.index_in_memory:
            self.index = {}
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the memory system.
        
        Returns:
            A dictionary containing memory statistics.
        """
        # Count the number of items
        if self.index_in_memory:
            item_count = len(self.index)
        else:
            item_count = len([f for f in os.listdir(self.storage_path) if f.endswith(".json")])
        
        # Get the total size of all items
        total_size = sum(
            os.path.getsize(os.path.join(self.storage_path, f)) 
            for f in os.listdir(self.storage_path) 
            if os.path.isfile(os.path.join(self.storage_path, f)) and f.endswith(".json")
        )
        
        return {
            "type": "long_term",
            "storage_path": self.storage_path,
            "index_in_memory": self.index_in_memory,
            "item_count": item_count,
            "total_size_bytes": total_size
        }
    
    def _get_item_path(self, identifier: str) -> str:
        """
        Get the file path for an item.
        
        Args:
            identifier: The identifier of the item.
            
        Returns:
            The file path for the item.
        """
        return os.path.join(self.storage_path, f"{identifier}.json")
    
    def _save_item(self, identifier: str, item: Dict[str, Any]) -> None:
        """
        Save an item to disk.
        
        Args:
            identifier: The identifier of the item.
            item: The item to save.
        """
        item_path = self._get_item_path(identifier)
        
        try:
            with open(item_path, "w") as f:
                json.dump(item, f, indent=2)
        except Exception as e:
            logging.error(f"Error saving item {identifier}: {e}")
    
    def _load_index(self) -> None:
        """
        Load the index from disk.
        """
        self.index = {}
        
        for item_file in os.listdir(self.storage_path):
            if not item_file.endswith(".json"):
                continue
            
            identifier = item_file[:-5]  # Remove .json extension
            
            try:
                with open(os.path.join(self.storage_path, item_file), "r") as f:
                    item = json.load(f)
                    self.index[identifier] = item
            except Exception as e:
                logging.error(f"Error loading index for {identifier}: {e}")
    
    def _matches_query(self, item: Dict[str, Any], query: Dict[str, Any]) -> bool:
        """
        Check if an item matches a query.
        
        Args:
            item: The item to check.
            query: The query to match against.
            
        Returns:
            True if the item matches the query, False otherwise.
        """
        for key, value in query.items():
            # Handle nested keys with dot notation
            if "." in key:
                parts = key.split(".")
                curr = item
                for part in parts:
                    if isinstance(curr, dict) and part in curr:
                        curr = curr[part]
                    else:
                        return False
                
                if curr != value:
                    return False
            # Handle simple keys
            elif key not in item or item[key] != value:
                return False
        
        return True
```

## anus/core/memory/__init__.py

- Characters: 507
- Tokens: 0

```python
"""
Memory module for the ANUS framework.

This module contains various memory implementations:
- BaseMemory: Abstract base class for all memory systems
- ShortTermMemory: Volatile in-memory storage with LRU eviction
- LongTermMemory: Persistent storage backed by a file system
"""

from anus.core.memory.base_memory import BaseMemory
from anus.core.memory.short_term import ShortTermMemory
from anus.core.memory.long_term import LongTermMemory

__all__ = ["BaseMemory", "ShortTermMemory", "LongTermMemory"]
```

## anus/core/memory/short_term.py

- Characters: 10413
- Tokens: 0

```python
"""
Short-term memory module for the ANUS framework.

Because even an ANUS needs to remember what it just processed.
"""

from typing import Dict, List, Any, Optional, Union
import uuid
import time
import heapq
import logging
import random

from anus.core.memory.base_memory import BaseMemory

class ShortTermMemory(BaseMemory):
    """
    In-memory implementation of the BaseMemory interface.
    
    Provides a volatile memory store with automatic pruning of old items.
    
    Just like the human ANUS, it's good at handling recent input but tends to 
    forget older stuff if not regularly refreshed.
    """
    
    # Funny memory-related messages
    _memory_messages = [
        "ANUS short-term memory retaining item...",
        "Storing this for quick retrieval from your ANUS...",
        "This item is now tightly held in ANUS memory...",
        "Squeezing this into ANUS short-term storage...",
        "ANUS will remember this, at least for a little while..."
    ]
    
    def __init__(
        self, 
        capacity: int = 1000, 
        ttl: int = 3600,  # Time to live in seconds
        **kwargs
    ):
        """
        Initialize a ShortTermMemory instance.
        
        Args:
            capacity: Maximum number of items to store.
            ttl: Time to live for items in seconds.
            **kwargs: Additional configuration options.
        """
        super().__init__(**kwargs)
        self.capacity = capacity
        self.ttl = ttl
        self.items: Dict[str, Dict[str, Any]] = {}
        self.access_times: Dict[str, float] = {}
        self.creation_times: Dict[str, float] = {}
        self.lru_queue: List[tuple] = []  # Priority queue for LRU eviction
        
        if capacity < 100:
            logging.warning(f"ANUS short-term memory capacity of {capacity} is quite small. Performance may suffer.")
        elif capacity > 10000:
            logging.warning(f"ANUS short-term memory capacity of {capacity} is unusually large. Hope you have enough RAM!")
        
        logging.info(f"ANUS short-term memory initialized with capacity for {capacity} items and {ttl}s retention")
    
    def add(self, item: Dict[str, Any]) -> str:
        """
        Add an item to memory and return its identifier.
        
        If the memory is at capacity, the least recently used item will be evicted.
        
        Args:
            item: The item to add to memory.
            
        Returns:
            A string identifier for the added item.
        """
        # Prune expired items
        self._prune_expired()
        
        # Generate a unique identifier
        identifier = str(uuid.uuid4())
        
        # Add the item
        self.items[identifier] = item
        current_time = time.time()
        self.access_times[identifier] = current_time
        self.creation_times[identifier] = current_time
        
        # Add to LRU queue
        heapq.heappush(self.lru_queue, (current_time, identifier))
        
        # Check capacity and evict if necessary
        if len(self.items) > self.capacity:
            self._evict_lru()
            
        # 5% chance to log a funny memory message
        if random.random() < 0.05:
            logging.debug(random.choice(self._memory_messages))
            
        # Log capacity status if getting full
        capacity_pct = len(self.items) / self.capacity * 100
        if capacity_pct > 90:
            logging.warning(f"ANUS short-term memory is {capacity_pct:.1f}% full. Starting to feel tight in here!")
        
        return identifier
    
    def get(self, identifier: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve an item from memory by its identifier.
        
        Updates the access time of the item to prevent it from being evicted.
        
        Args:
            identifier: The identifier of the item to retrieve.
            
        Returns:
            The retrieved item, or None if not found.
        """
        # Prune expired items
        self._prune_expired()
        
        # Check if the item exists
        if identifier not in self.items:
            logging.debug(f"ANUS has no recollection of item {identifier[:8]}...")
            return None
        
        # Update access time
        self.access_times[identifier] = time.time()
        
        # Return the item
        logging.debug(f"ANUS recalls this item perfectly!")
        return self.items[identifier]
    
    def search(self, query: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:
        """
        Search memory for items matching the query.
        
        Simple implementation that checks for exact matches on query fields.
        
        Args:
            query: The search query.
            limit: Maximum number of results to return.
            
        Returns:
            A list of matching items.
        """
        # Prune expired items
        self._prune_expired()
        
        logging.debug(f"ANUS is probing deeply for matching items...")
        
        results = []
        
        for identifier, item in self.items.items():
            # Check if all query fields match
            is_match = True
            for key, value in query.items():
                if key not in item or item[key] != value:
                    is_match = False
                    break
            
            if is_match:
                # Update access time
                self.access_times[identifier] = time.time()
                
                # Add to results
                results.append({
                    "id": identifier,
                    "item": item,
                    "created_at": self.creation_times[identifier]
                })
                
                # Check limit
                if len(results) >= limit:
                    break
        
        # Sort by recency
        results.sort(key=lambda x: x["created_at"], reverse=True)
        
        if not results:
            logging.debug("ANUS found nothing that matches. How disappointing.")
        else:
            logging.debug(f"ANUS successfully extracted {len(results)} matching items!")
        
        return results
    
    def update(self, identifier: str, item: Dict[str, Any]) -> bool:
        """
        Update an item in memory.
        
        Args:
            identifier: The identifier of the item to update.
            item: The updated item.
            
        Returns:
            True if the update was successful, False otherwise.
        """
        # Prune expired items
        self._prune_expired()
        
        # Check if the item exists
        if identifier not in self.items:
            logging.debug(f"ANUS can't update what it doesn't have (identifier: {identifier[:8]})")
            return False
        
        # Update the item
        self.items[identifier] = item
        
        # Update access time
        self.access_times[identifier] = time.time()
        
        logging.debug(f"ANUS memory successfully updated with fresh content")
        return True
    
    def delete(self, identifier: str) -> bool:
        """
        Delete an item from memory.
        
        Args:
            identifier: The identifier of the item to delete.
            
        Returns:
            True if the deletion was successful, False otherwise.
        """
        # Check if the item exists
        if identifier not in self.items:
            return False
        
        # Delete the item
        del self.items[identifier]
        del self.access_times[identifier]
        del self.creation_times[identifier]
        
        # Note: The item will remain in the LRU queue, but will be skipped when it's popped
        
        logging.debug(f"ANUS has purged this item from its memory")
        return True
    
    def clear(self) -> None:
        """
        Clear all items from memory.
        """
        old_count = len(self.items)
        self.items = {}
        self.access_times = {}
        self.creation_times = {}
        self.lru_queue = []
        
        logging.info(f"ANUS memory has been completely flushed of {old_count} items. Fresh and clean!")
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the memory system.
        
        Returns:
            A dictionary containing memory statistics.
        """
        utilization = len(self.items) / self.capacity if self.capacity > 0 else 0
        
        # Add a funny message based on utilization
        if utilization > 0.9:
            status = "ANUS memory is nearly full! Things are getting tight in here."
        elif utilization > 0.7:
            status = "ANUS memory is filling up nicely."
        elif utilization > 0.4:
            status = "ANUS memory has plenty of room for more."
        else:
            status = "ANUS memory is mostly empty. Feed me more data!"
            
        return {
            "type": "short_term",
            "capacity": self.capacity,
            "ttl": self.ttl,
            "current_size": len(self.items),
            "utilization": utilization,
            "status": status
        }
    
    def _prune_expired(self) -> None:
        """
        Remove items that have exceeded their time to live.
        """
        current_time = time.time()
        expired_identifiers = []
        
        for identifier, creation_time in self.creation_times.items():
            if current_time - creation_time > self.ttl:
                expired_identifiers.append(identifier)
        
        if expired_identifiers:
            for identifier in expired_identifiers:
                self.delete(identifier)
            
            logging.debug(f"ANUS has expelled {len(expired_identifiers)} expired items from memory")
    
    def _evict_lru(self) -> None:
        """
        Evict the least recently used item from memory.
        """
        while self.lru_queue:
            _, identifier = heapq.heappop(self.lru_queue)
            
            # Skip if the item has been deleted
            if identifier not in self.items:
                continue
            
            # Delete the item
            item_name = self.items[identifier].get("name", "unknown")
            self.delete(identifier)
            logging.debug(f"ANUS had to push out '{item_name}' to make room for new content")
            break
```

## anus/core/memory/base_memory.py

- Characters: 2725
- Tokens: 0

```python
"""
Base Memory module that defines the common interface for memory systems.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Union

class BaseMemory(ABC):
    """
    Abstract base class for memory systems in the ANUS framework.
    
    Provides the core functionality and interface that all memory types must implement.
    """
    
    def __init__(self, **kwargs):
        """
        Initialize a BaseMemory instance.
        
        Args:
            **kwargs: Additional configuration options for the memory system.
        """
        self.config = kwargs
    
    @abstractmethod
    def add(self, item: Dict[str, Any]) -> str:
        """
        Add an item to memory and return its identifier.
        
        Args:
            item: The item to add to memory.
            
        Returns:
            A string identifier for the added item.
        """
        pass
    
    @abstractmethod
    def get(self, identifier: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve an item from memory by its identifier.
        
        Args:
            identifier: The identifier of the item to retrieve.
            
        Returns:
            The retrieved item, or None if not found.
        """
        pass
    
    @abstractmethod
    def search(self, query: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:
        """
        Search memory for items matching the query.
        
        Args:
            query: The search query.
            limit: Maximum number of results to return.
            
        Returns:
            A list of matching items.
        """
        pass
    
    @abstractmethod
    def update(self, identifier: str, item: Dict[str, Any]) -> bool:
        """
        Update an item in memory.
        
        Args:
            identifier: The identifier of the item to update.
            item: The updated item.
            
        Returns:
            True if the update was successful, False otherwise.
        """
        pass
    
    @abstractmethod
    def delete(self, identifier: str) -> bool:
        """
        Delete an item from memory.
        
        Args:
            identifier: The identifier of the item to delete.
            
        Returns:
            True if the deletion was successful, False otherwise.
        """
        pass
    
    @abstractmethod
    def clear(self) -> None:
        """
        Clear all items from memory.
        """
        pass
    
    @abstractmethod
    def get_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the memory system.
        
        Returns:
            A dictionary containing memory statistics.
        """
        pass
```

## anus/core/orchestrator.py

- Characters: 14325
- Tokens: 0

```python
"""
Orchestrator module for the ANUS framework.

This module contains the agent orchestration system that manages agent 
lifecycle and coordinates task execution across multiple agents.

Behind every successful ANUS is a well-designed Orchestrator.
"""

from typing import Dict, List, Any, Optional, Union
import logging
import yaml
import os
import time
import random

from anus.core.agent import BaseAgent, HybridAgent
from anus.core.memory import ShortTermMemory, LongTermMemory

# Create a custom logger for ANUS-specific wisdom
class ANUSLogger(logging.Logger):
    """Custom logger that occasionally adds ANUS wisdom to log messages."""
    
    _wisdom = [
        "ANUS Wisdom: Always test your backend thoroughly before deployment.",
        "ANUS Wisdom: Sometimes a little push from behind is all you need.",
        "ANUS Wisdom: Keep your interfaces clean and well-documented.",
        "ANUS Wisdom: A tight architecture prevents unwanted leakage.",
        "ANUS Wisdom: Even the backend deserves some love and attention."
    ]
    
    def info(self, msg, *args, **kwargs):
        if random.random() < 0.1:  # 10% chance
            msg = f"{msg} - {random.choice(self._wisdom)}"
        super().info(msg, *args, **kwargs)
    
    def debug(self, msg, *args, **kwargs):
        if random.random() < 0.2:  # 20% chance
            msg = f"{msg} - {random.choice(self._wisdom)}"
        super().debug(msg, *args, **kwargs)

# Register our custom logger
logging.setLoggerClass(ANUSLogger)
logger = logging.getLogger("anus.orchestrator")

class AgentOrchestrator:
    """
    Coordinates multiple agents and manages their lifecycle.
    
    This class is responsible for:
    - Loading configuration
    - Creating and initializing agents
    - Routing tasks to appropriate agents
    - Managing agent resources
    - Collecting and aggregating results
    
    Remember: A well-lubricated ANUS runs smoothly without friction.
    """
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        Initialize an AgentOrchestrator instance.
        
        Args:
            config_path: Path to the configuration file.
        """
        self.config = self._load_config(config_path)
        self.agents: Dict[str, BaseAgent] = {}
        self.primary_agent = self._create_primary_agent()
        self.last_result: Dict[str, Any] = {}
        self.task_history: List[Dict[str, Any]] = []
        
        # Easter eggs for internal task names
        self._easter_egg_tasks = {
            "status": "Performing deep ANUS inspection...",
            "health": "Checking if ANUS is functioning properly...",
            "clean": "Flushing old data from ANUS...",
            "optimize": "Making ANUS more responsive and flexible...",
            "expand": "Expanding ANUS capabilities..."
        }
        
        logger.info("ANUS Orchestrator initialized and ready for action")
    
    def execute_task(self, task: str, mode: Optional[str] = None) -> Dict[str, Any]:
        """
        Execute a task using an appropriate agent.
        
        Args:
            task: The task description to execute.
            mode: Execution mode ("single" or "multi"). If None, uses the config default.
            
        Returns:
            The execution result.
        """
        # Use config default if mode not specified
        if mode is None:
            mode = self.config.get("agent", {}).get("mode", "single")
        
        start_time = time.time()
        
        # Check for easter egg task names
        display_task = task
        for keyword, message in self._easter_egg_tasks.items():
            if keyword.lower() in task.lower().split():
                display_task = message
                logger.info(f"Easter egg activated: {message}")
                break
        
        # Log the task
        if mode == "multi":
            logger.info(f"ANUS expanding to handle multiple agents for task: {display_task}")
        else:
            logger.info(f"ANUS processing task: {display_task}")
        
        # Execute the task with the primary agent
        result = self.primary_agent.execute(task, mode=mode)
        
        # Record execution time
        execution_time = time.time() - start_time
        
        # Create a task record
        task_record = {
            "task": task,
            "mode": mode,
            "start_time": start_time,
            "execution_time": execution_time,
            "status": "completed",
            "result": result
        }
        
        # Add to task history
        self.task_history.append(task_record)
        
        # Update last result
        self.last_result = result
        
        # Log completion
        if execution_time > 10:
            logger.info(f"ANUS finished after {execution_time:.2f}s - that was quite a workout!")
        else:
            logger.info(f"ANUS completed task in {execution_time:.2f}s")
        
        return result
    
    def list_agents(self) -> List[Dict[str, Any]]:
        """
        List all registered agents.
        
        Returns:
            A list of agent descriptions.
        """
        agent_list = []
        
        # Add primary agent
        agent_list.append({
            "id": self.primary_agent.id,
            "name": self.primary_agent.name,
            "type": type(self.primary_agent).__name__,
            "primary": True
        })
        
        # Add other agents
        for name, agent in self.agents.items():
            if agent.id != self.primary_agent.id:
                agent_list.append({
                    "id": agent.id,
                    "name": agent.name,
                    "type": type(agent).__name__,
                    "primary": False
                })
        
        if len(agent_list) > 3:
            logger.debug(f"ANUS is quite full with {len(agent_list)} agents inside")
        
        return agent_list
    
    def get_task_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get the history of executed tasks.
        
        Args:
            limit: Maximum number of history items to return.
            
        Returns:
            A list of task history records.
        """
        if limit > 50:
            logger.warning(f"Requesting {limit} history items? That's a deep dive into ANUS history!")
        
        return self.task_history[-limit:]
    
    def get_last_result(self) -> Dict[str, Any]:
        """
        Get the result of the last executed task.
        
        Returns:
            The last execution result.
        """
        return self.last_result
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """
        Load configuration from a YAML file.
        
        Args:
            config_path: Path to the configuration file.
            
        Returns:
            The loaded configuration.
        """
        # Default configuration
        default_config = {
            "agent": {
                "name": "anus",
                "mode": "single",
                "max_iterations": 10,
                "complexity_threshold": 7
            },
            "memory": {
                "short_term": {
                    "capacity": 1000,
                    "ttl": 3600
                },
                "long_term": {
                    "enabled": True,
                    "storage_path": None,
                    "index_in_memory": True
                }
            },
            "models": {
                "default": {
                    "provider": "openai",
                    "model": "gpt-4",
                    "temperature": 0.0
                }
            },
            "tools": {
                "enabled": []
            }
        }
        
        # Check if config file exists
        if not os.path.exists(config_path):
            logger.warning(f"Config file {config_path} not found. Using default configuration.")
            logger.info("ANUS is running with default settings. It might be a tight fit for complex tasks.")
            return default_config
        
        try:
            # Load the config file
            with open(config_path, "r") as f:
                config = yaml.safe_load(f)
            
            # Merge with default config
            merged_config = self._merge_configs(default_config, config)
            
            logger.info("ANUS configuration loaded successfully")
            if merged_config.get("agent", {}).get("mode") == "multi":
                logger.info("ANUS is configured for multi-agent mode - it's going to get crowded in there!")
            
            return merged_config
        except Exception as e:
            logger.error(f"Error loading config file: {e}")
            logger.info("ANUS reverted to default configuration. Performance may not be optimal.")
            return default_config
    
    def _merge_configs(self, default: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
        """
        Merge two configuration dictionaries.
        
        Args:
            default: Default configuration.
            override: Override configuration.
            
        Returns:
            The merged configuration.
        """
        result = default.copy()
        
        for key, value in override.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._merge_configs(result[key], value)
            else:
                result[key] = value
        
        return result
    
    def _create_primary_agent(self) -> HybridAgent:
        """
        Create the primary agent based on configuration.
        
        Returns:
            A HybridAgent instance.
        """
        # Get agent config
        agent_config = self.config.get("agent", {})
        name = agent_config.get("name", "anus")
        mode = agent_config.get("mode", "single")
        max_iterations = agent_config.get("max_iterations", 10)
        complexity_threshold = agent_config.get("complexity_threshold", 7)
        
        # Get tools config
        tools_config = self.config.get("tools", {})
        enabled_tools = tools_config.get("enabled", [])
        
        # Create memories
        short_term_memory = self._create_short_term_memory()
        long_term_memory = self._create_long_term_memory()
        
        # Create the agent
        agent = HybridAgent(
            name=name,
            max_iterations=max_iterations,
            tools=enabled_tools,
            mode=mode,
            complexity_threshold=complexity_threshold,
            short_term_memory=short_term_memory,
            long_term_memory=long_term_memory
        )
        
        logger.info(f"Primary agent created. ANUS is ready with {len(enabled_tools)} tools available")
        
        # Create specialized agents if in multi mode
        if mode == "multi" or mode == "auto":
            self._create_specialized_agents(agent)
            logger.info("Multiple specialized agents have been inserted into ANUS")
        
        # Register the agent
        self.agents[name] = agent
        
        return agent
    
    def _create_short_term_memory(self) -> ShortTermMemory:
        """
        Create a short-term memory instance based on configuration.
        
        Returns:
            A ShortTermMemory instance.
        """
        memory_config = self.config.get("memory", {}).get("short_term", {})
        capacity = memory_config.get("capacity", 1000)
        ttl = memory_config.get("ttl", 3600)
        
        logger.debug(f"Initializing ANUS short-term memory with capacity {capacity}")
        return ShortTermMemory(capacity=capacity, ttl=ttl)
    
    def _create_long_term_memory(self) -> Optional[LongTermMemory]:
        """
        Create a long-term memory instance based on configuration.
        
        Returns:
            A LongTermMemory instance, or None if disabled.
        """
        memory_config = self.config.get("memory", {}).get("long_term", {})
        enabled = memory_config.get("enabled", True)
        
        if not enabled:
            logger.info("Long-term memory disabled. ANUS will forget everything after each session.")
            return None
        
        storage_path = memory_config.get("storage_path")
        index_in_memory = memory_config.get("index_in_memory", True)
        
        if storage_path:
            logger.debug(f"ANUS will store long-term memories at: {storage_path}")
        else:
            logger.debug("ANUS will store long-term memories in the default location")
        
        return LongTermMemory(storage_path=storage_path, index_in_memory=index_in_memory)
    
    def _create_specialized_agents(self, primary_agent: HybridAgent) -> None:
        """
        Create specialized agents for multi-agent mode.
        
        Args:
            primary_agent: The primary HybridAgent instance.
        """
        # Default specialized agent roles
        default_roles = ["researcher", "planner", "executor", "critic"]
        
        # Get specialized agent configurations
        specialized_config = self.config.get("specialized_agents", {})
        roles = specialized_config.get("roles", default_roles)
        
        # Create each specialized agent
        for role in roles:
            role_config = specialized_config.get(role, {})
            
            # Default configuration for the role
            default_role_config = {
                "name": f"{role}-agent",
                "max_iterations": primary_agent.max_iterations,
                "tools": self.config.get("tools", {}).get("enabled", [])
            }
            
            # Merge with role-specific config
            merged_config = self._merge_configs(default_role_config, role_config)
            
            # Add to the primary agent
            primary_agent.add_specialized_agent(role, merged_config)
            
            logger.debug(f"Added {role} agent to ANUS")
        
        logger.info(f"ANUS now contains {len(roles)} specialized agents working together harmoniously")
        if len(roles) > 5:
            logger.warning("That's a lot of agents to fit inside one ANUS. Performance may be affected.")
```

## anus/core/planning/task_planner.py

- Characters: 15272
- Tokens: 0

```python
"""
Task Planner module for LLM-based task planning.
"""

import uuid
import time
import json
import logging
from typing import Dict, List, Any, Optional, Union

from anus.core.planning.base_planner import BasePlanner
from anus.models.base.base_model import BaseModel

class TaskPlanner(BasePlanner):
    """
    A planner that uses language models to create and manage task plans.
    
    Implements task breakdown, dependency tracking, and adaptive replanning.
    """
    
    def __init__(self, model: BaseModel, **kwargs):
        """
        Initialize a TaskPlanner instance.
        
        Args:
            model: The language model to use for planning.
            **kwargs: Additional configuration options for the planner.
        """
        super().__init__(**kwargs)
        self.model = model
        self.max_steps = kwargs.get("max_steps", 10)
    
    def create_plan(self, task: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Create a plan for executing a task using the language model.
        
        Args:
            task: The task description.
            context: Optional context for planning.
            
        Returns:
            A plan dictionary with steps and metadata.
        """
        context = context or {}
        
        # Prepare the planning prompt
        prompt = self._create_planning_prompt(task, context)
        
        # Extract JSON schema for the plan
        plan_schema = {
            "type": "object",
            "properties": {
                "steps": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "string"},
                            "name": {"type": "string"},
                            "description": {"type": "string"},
                            "tool": {"type": "string"},
                            "tool_input": {"type": "object"},
                            "expected_output": {"type": "string"},
                            "dependencies": {
                                "type": "array",
                                "items": {"type": "string"}
                            }
                        },
                        "required": ["name", "description", "tool"]
                    }
                },
                "reasoning": {"type": "string"},
                "estimated_steps": {"type": "integer"}
            },
            "required": ["steps", "reasoning"]
        }
        
        # Generate the plan using the model
        try:
            plan_data = self.model.extract_json(
                prompt=prompt,
                schema=plan_schema,
                system_message="You are a task planning assistant. Break down tasks into logical steps."
            )
            
            # Process the plan data
            return self._process_plan_data(task, plan_data)
            
        except Exception as e:
            logging.error(f"Error creating plan: {e}")
            # Return a minimal plan
            return {
                "id": str(uuid.uuid4()),
                "task": task,
                "status": "error",
                "error": str(e),
                "created_at": time.time(),
                "steps": [],
                "reasoning": "Error generating plan",
                "current_step_index": 0,
                "completed_steps": [],
                "metadata": {"context": context}
            }
    
    def replan(self, plan: Dict[str, Any], feedback: Dict[str, Any]) -> Dict[str, Any]:
        """
        Update a plan based on execution feedback.
        
        Args:
            plan: The current plan.
            feedback: Feedback from execution.
            
        Returns:
            The updated plan.
        """
        # Extract current plan state
        task = plan.get("task", "")
        completed_steps = plan.get("completed_steps", [])
        remaining_steps = self._get_remaining_steps(plan)
        
        # Prepare the replanning prompt
        prompt = self._create_replanning_prompt(task, plan, feedback)
        
        # Extract JSON schema for the updated plan
        plan_schema = {
            "type": "object",
            "properties": {
                "steps": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "string"},
                            "name": {"type": "string"},
                            "description": {"type": "string"},
                            "tool": {"type": "string"},
                            "tool_input": {"type": "object"},
                            "expected_output": {"type": "string"},
                            "dependencies": {
                                "type": "array",
                                "items": {"type": "string"}
                            }
                        },
                        "required": ["name", "description", "tool"]
                    }
                },
                "reasoning": {"type": "string"}
            },
            "required": ["steps", "reasoning"]
        }
        
        try:
            # Generate the updated plan
            updated_plan_data = self.model.extract_json(
                prompt=prompt,
                schema=plan_schema,
                system_message="You are a task planning assistant. Revise plans based on feedback."
            )
            
            # Merge the updated plan with the original plan
            updated_plan = plan.copy()
            updated_plan["steps"] = completed_steps + updated_plan_data.get("steps", [])
            updated_plan["reasoning"] = updated_plan_data.get("reasoning", "Plan updated based on feedback")
            updated_plan["updated_at"] = time.time()
            updated_plan["status"] = "updated"
            
            # Keep the current step index
            if len(completed_steps) < len(updated_plan["steps"]):
                updated_plan["current_step_index"] = len(completed_steps)
            else:
                updated_plan["current_step_index"] = 0
            
            # Add feedback to metadata
            if "metadata" not in updated_plan:
                updated_plan["metadata"] = {}
            updated_plan["metadata"]["feedback"] = feedback
            
            return updated_plan
            
        except Exception as e:
            logging.error(f"Error replanning: {e}")
            # Return the original plan with an error flag
            plan["status"] = "error"
            plan["error"] = str(e)
            return plan
    
    def get_next_step(self, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Get the next step to execute from a plan.
        
        Args:
            plan: The current plan.
            
        Returns:
            The next step to execute, or None if the plan is complete.
        """
        steps = plan.get("steps", [])
        current_index = plan.get("current_step_index", 0)
        
        # Check if we've completed all steps
        if current_index >= len(steps):
            return None
        
        # Get the next step
        next_step = steps[current_index]
        
        # Check dependencies
        if "dependencies" in next_step and next_step["dependencies"]:
            completed_step_ids = [step.get("id") for step in plan.get("completed_steps", [])]
            
            # Check if all dependencies are satisfied
            for dep_id in next_step["dependencies"]:
                if dep_id not in completed_step_ids:
                    # Dependency not satisfied, try to find an alternative step
                    alt_step = self._find_executable_step(plan)
                    if alt_step:
                        return alt_step
                    else:
                        # Can't proceed, need replanning
                        logging.warning(f"Can't execute step {next_step.get('id')}: unsatisfied dependencies")
                        return None
        
        return next_step
    
    def mark_step_complete(self, plan: Dict[str, Any], step_id: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Mark a step as complete in a plan.
        
        Args:
            plan: The current plan.
            step_id: The ID of the completed step.
            result: The result of the step execution.
            
        Returns:
            The updated plan.
        """
        updated_plan = plan.copy()
        steps = updated_plan.get("steps", [])
        current_index = updated_plan.get("current_step_index", 0)
        
        # Find the step
        step_index = -1
        for i, step in enumerate(steps):
            if step.get("id") == step_id:
                step_index = i
                break
        
        if step_index == -1:
            logging.warning(f"Step {step_id} not found in plan")
            return plan
        
        # Update the step with result
        completed_step = steps[step_index].copy()
        completed_step["result"] = result
        completed_step["completed_at"] = time.time()
        
        # Add to completed steps
        if "completed_steps" not in updated_plan:
            updated_plan["completed_steps"] = []
        updated_plan["completed_steps"].append(completed_step)
        
        # Update current step index
        if step_index == current_index:
            updated_plan["current_step_index"] = current_index + 1
        
        # Check if plan is complete
        if updated_plan["current_step_index"] >= len(steps):
            updated_plan["status"] = "completed"
            updated_plan["completed_at"] = time.time()
        
        return updated_plan
    
    def _create_planning_prompt(self, task: str, context: Dict[str, Any]) -> str:
        """
        Create a prompt for generating a plan.
        
        Args:
            task: The task description.
            context: Context information.
            
        Returns:
            A prompt string.
        """
        prompt = f"""
Task: {task}

I need a detailed plan to accomplish this task. Please break it down into specific steps.

For each step, include:
1. A clear name and description
2. The tool required (e.g., web_search, file_read, code_execution)
3. The expected input for the tool
4. Any dependencies on previous steps

Context information:
{json.dumps(context, indent=2)}

Please provide a structured plan with no more than {self.max_steps} steps.
"""
        return prompt
    
    def _create_replanning_prompt(self, task: str, plan: Dict[str, Any], feedback: Dict[str, Any]) -> str:
        """
        Create a prompt for replanning.
        
        Args:
            task: The task description.
            plan: The current plan.
            feedback: Feedback from execution.
            
        Returns:
            A prompt string.
        """
        # Extract completed steps
        completed_steps = plan.get("completed_steps", [])
        completed_steps_text = ""
        for i, step in enumerate(completed_steps):
            result = step.get("result", {})
            result_status = result.get("status", "unknown")
            result_summary = str(result.get("result", "No result"))[:100] + "..." if len(str(result.get("result", ""))) > 100 else str(result.get("result", "No result"))
            
            completed_steps_text += f"{i+1}. {step.get('name', 'Step')}: {result_status} - {result_summary}\n"
        
        # Extract remaining steps
        remaining_steps = self._get_remaining_steps(plan)
        remaining_steps_text = ""
        for i, step in enumerate(remaining_steps):
            remaining_steps_text += f"{i+1}. {step.get('name', 'Step')}: {step.get('description', 'No description')}\n"
        
        prompt = f"""
Task: {task}

I need to revise my plan based on execution feedback. 

Completed steps:
{completed_steps_text}

Current feedback:
{json.dumps(feedback, indent=2)}

Current remaining steps:
{remaining_steps_text}

Please provide an updated plan for the remaining steps, considering the feedback and results from completed steps.
"""
        return prompt
    
    def _process_plan_data(self, task: str, plan_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process raw plan data into a structured plan.
        
        Args:
            task: The task description.
            plan_data: Raw plan data from the model.
            
        Returns:
            A structured plan dictionary.
        """
        steps = plan_data.get("steps", [])
        
        # Ensure each step has an ID and required fields
        for i, step in enumerate(steps):
            if "id" not in step:
                step["id"] = f"step-{i+1}-{str(uuid.uuid4())[:8]}"
            
            if "tool_input" not in step:
                step["tool_input"] = {}
            
            if "dependencies" not in step:
                step["dependencies"] = []
        
        # Create the plan structure
        plan = {
            "id": str(uuid.uuid4()),
            "task": task,
            "status": "created",
            "created_at": time.time(),
            "steps": steps,
            "reasoning": plan_data.get("reasoning", ""),
            "current_step_index": 0,
            "completed_steps": [],
            "metadata": {
                "estimated_steps": plan_data.get("estimated_steps", len(steps))
            }
        }
        
        return plan
    
    def _get_remaining_steps(self, plan: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Get the remaining steps from a plan.
        
        Args:
            plan: The current plan.
            
        Returns:
            A list of remaining steps.
        """
        steps = plan.get("steps", [])
        current_index = plan.get("current_step_index", 0)
        
        if current_index >= len(steps):
            return []
        
        return steps[current_index:]
    
    def _find_executable_step(self, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Find a step that can be executed (all dependencies satisfied).
        
        Args:
            plan: The current plan.
            
        Returns:
            An executable step, or None if none found.
        """
        steps = plan.get("steps", [])
        current_index = plan.get("current_step_index", 0)
        completed_step_ids = [step.get("id") for step in plan.get("completed_steps", [])]
        
        # Look for steps after the current index
        for i in range(current_index, len(steps)):
            step = steps[i]
            dependencies = step.get("dependencies", [])
            
            # Check if all dependencies are satisfied
            dependencies_satisfied = True
            for dep_id in dependencies:
                if dep_id not in completed_step_ids:
                    dependencies_satisfied = False
                    break
            
            if dependencies_satisfied:
                return step
        
        return None
```

## anus/core/planning/__init__.py

- Characters: 353
- Tokens: 0

```python
"""
Planning module for the ANUS framework.

This module contains classes for task planning:
- BasePlanner: Abstract base class for planners
- TaskPlanner: LLM-based task planning implementation
"""

from anus.core.planning.base_planner import BasePlanner
from anus.core.planning.task_planner import TaskPlanner

__all__ = ["BasePlanner", "TaskPlanner"]
```

## anus/core/planning/base_planner.py

- Characters: 2133
- Tokens: 0

```python
"""
Base Planner module that defines the common interface for task planning.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional

class BasePlanner(ABC):
    """
    Abstract base class for planners in the ANUS framework.
    
    Provides the core functionality for breaking down tasks into steps.
    """
    
    def __init__(self, **kwargs):
        """
        Initialize a BasePlanner instance.
        
        Args:
            **kwargs: Additional configuration options for the planner.
        """
        self.config = kwargs
    
    @abstractmethod
    def create_plan(self, task: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Create a plan for executing a task.
        
        Args:
            task: The task description.
            context: Optional context for planning.
            
        Returns:
            A plan dictionary with steps and metadata.
        """
        pass
    
    @abstractmethod
    def replan(self, plan: Dict[str, Any], feedback: Dict[str, Any]) -> Dict[str, Any]:
        """
        Update a plan based on execution feedback.
        
        Args:
            plan: The current plan.
            feedback: Feedback from execution.
            
        Returns:
            The updated plan.
        """
        pass
    
    @abstractmethod
    def get_next_step(self, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Get the next step to execute from a plan.
        
        Args:
            plan: The current plan.
            
        Returns:
            The next step to execute, or None if the plan is complete.
        """
        pass
    
    @abstractmethod
    def mark_step_complete(self, plan: Dict[str, Any], step_id: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Mark a step as complete in a plan.
        
        Args:
            plan: The current plan.
            step_id: The ID of the completed step.
            result: The result of the step execution.
            
        Returns:
            The updated plan.
        """
        pass
```

## anus/core/agent/react_agent.py

- Characters: 16009
- Tokens: 0

```python
"""
React Agent module that extends the base agent with reasoning capabilities.
"""

from typing import Dict, List, Any, Optional, Tuple
import json
import logging
import time
import uuid

from anus.core.agent.base_agent import BaseAgent
from anus.models.base.base_model import BaseModel


class ReactAgent(BaseAgent):
    """
    A reasoning agent that follows the React paradigm (Reasoning and Acting).

    This agent implements a thought-action-observation loop for complex reasoning.
    """

    def __init__(
        self,
        name: Optional[str] = None,
        max_iterations: int = 10,
        llm: Optional[BaseModel] = None,
        **kwargs,
    ):
        """
        Initialize a ReactAgent instance.

        Args:
            name: Optional name for the agent.
            max_iterations: Maximum number of thought-action cycles to perform.
            llm: Language model to use for reasoning. If None, a default one will be created.
            **kwargs: Additional configuration options for the agent.
        """
        super().__init__(name=name, **kwargs)
        self.max_iterations = max_iterations
        self.current_iteration = 0

        # Set up language model
        if llm:
            self.llm = llm
        else:
            # Import here to avoid circular imports
            from anus.models.model_router import ModelRouter

            router = ModelRouter()
            self.llm = router.get_default_model()

        # Define React prompts
        self.thought_prompt = """
        You are a reasoning agent solving a complex task. 
        Given the current context and task, generate a thought that would help you make progress.
        
        Task: {task}
        
        Previous steps:
        {history}
        
        Your thought should:
        - Analyze the current situation
        - Consider relevant information
        - Identify what needs to be done next
        - Be detailed and thorough
        
        Thought:
        """

        self.action_prompt = """
        You are a reasoning agent solving a complex task.
        Based on your thought, decide on the next action to take.
        
        Task: {task}
        
        Previous steps:
        {history}
        
        Current thought: {thought}
        
        Available actions:
        - search: Search for information on a topic
        - calculator: Perform mathematical calculations
        - lookup: Look up specific information
        - finish: Complete the task and provide the final answer
        
        Choose an action and provide the input for that action.
        Respond in JSON format like:
        {{
            "action": "action_name",
            "input": {{
                "query": "your query or input"
            }}
        }}
        
        JSON Response:
        """

    def execute(self, task: str, **kwargs) -> Dict[str, Any]:
        """
        Execute a task using the React paradigm.

        Args:
            task: The task description to execute.
            **kwargs: Additional parameters for task execution.

        Returns:
            A dictionary containing the execution result and metadata.
        """
        self.update_state(status="executing", task=task)
        self.current_iteration = 0

        # Initialize the context with the task
        context = {"task": task, "thoughts": [], "actions": [], "observations": []}

        # Main React loop
        while self.current_iteration < self.max_iterations:
            try:
                # Generate thought
                thought = self._generate_thought(context)
                context["thoughts"].append(thought)

                # Decide on action
                action_name, action_input = self._decide_action(context)
                action = {"name": action_name, "input": action_input}
                context["actions"].append(action)

                # Check if the action is to finish
                if action_name == "finish":
                    final_answer = action_input.get("answer", "Task completed.")

                    # Log the iteration
                    self.log_action(
                        "iteration",
                        {
                            "iteration": self.current_iteration,
                            "thought": thought,
                            "action": action,
                            "final_answer": final_answer,
                        },
                    )

                    # Build result
                    result = {
                        "task": task,
                        "answer": final_answer,
                        "iterations": self.current_iteration + 1,
                        "context": context,
                    }

                    self.update_state(status="completed")
                    return result

                # Execute action and get observation
                observation = self._execute_action(action_name, action_input)
                context["observations"].append(observation)

                # Log the iteration
                self.log_action(
                    "iteration",
                    {
                        "iteration": self.current_iteration,
                        "thought": thought,
                        "action": action,
                        "observation": observation,
                    },
                )

                # Check if we should terminate
                if self._should_terminate(context):
                    break

                self.current_iteration += 1

            except Exception as e:
                logging.error(f"Error in React execution loop: {str(e)}")
                context["errors"] = context.get("errors", []) + [str(e)]
                break

        # Generate final answer
        final_answer = self._generate_final_answer(context)

        result = {
            "task": task,
            "answer": final_answer,
            "iterations": self.current_iteration + 1,
            "context": context,
        }

        self.update_state(status="completed")
        return result

    def _generate_thought(self, context: Dict[str, Any]) -> str:
        """
        Generate a thought based on the current context.
        
        Args:
            context: The current execution context.
            
        Returns:
            A thought string.
        """
        # Build history from previous steps
        history_text = ""
        for i in range(len(context.get("thoughts", []))):
            history_text += f"Iteration {i+1}:\n"
            history_text += f"Thought: {context['thoughts'][i]}\n"
            
            if i < len(context.get("actions", [])):
                action = context["actions"][i]
                history_text += f"Action: {action['name']} - {json.dumps(action['input'])}\n"
                
            if i < len(context.get("observations", [])):
                history_text += f"Observation: {context['observations'][i]}\n"
                
            history_text += "\n"
        
        # Format the prompt
        prompt = self.thought_prompt.format(
            task=context["task"],
            history=history_text
        )
        
        # Call the language model to generate a thought
        try:
            thought_text = self.llm.generate(prompt, temperature=0.7)
            # Truncate the thought if too long
            if len(thought_text) > 1000:
                thought_text = thought_text[:997] + "..."
            return thought_text
        except Exception as e:
            logging.error(f"Error generating thought: {str(e)}")
            return f"I need to reconsider my approach. Previous error: {str(e)}"

    def _decide_action(self, context: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """
        Decide on the next action to take.

        Args:
            context: The current execution context.

        Returns:
            A tuple of (action_name, action_input).
        """
        # Build history text
        history_text = ""
        for i in range(len(context.get("thoughts", []))):
            history_text += f"Iteration {i+1}:\n"
            history_text += f"Thought: {context['thoughts'][i]}\n"

            if i < len(context.get("actions", [])):
                action = context["actions"][i]
                history_text += (
                    f"Action: {action['name']} - {json.dumps(action['input'])}\n"
                )

            if i < len(context.get("observations", [])):
                history_text += f"Observation: {context['observations'][i]}\n"

            history_text += "\n"

        # Format the prompt
        prompt = self.action_prompt.format(
            task=context["task"],
            history=history_text,
            thought=context["thoughts"][-1] if context["thoughts"] else "",
        )

        # Call the language model to generate an action decision
        try:
            response = self.llm.generate(prompt, temperature=0.2)

            # Parse the JSON response
            try:
                action_decision = json.loads(response)
                action_name = action_decision.get("action", "finish")
                action_input = action_decision.get("input", {})

                if not isinstance(action_input, dict):
                    action_input = {"value": action_input}

                return action_name, action_input

            except json.JSONDecodeError:
                # Handle case where response is not valid JSON
                logging.warning(
                    f"Invalid JSON response for action decision: {response}"
                )

                # Try to extract action name and input using simple heuristics
                if "search" in response.lower():
                    query = response.split("search", 1)[1].strip()
                    return "search", {"query": query}
                elif "calculator" in response.lower():
                    expression = response.split("calculator", 1)[1].strip()
                    return "calculator", {"expression": expression}
                elif "lookup" in response.lower():
                    query = response.split("lookup", 1)[1].strip()
                    return "lookup", {"query": query}
                elif "finish" in response.lower():
                    answer = response.split("finish", 1)[1].strip()
                    return "finish", {"answer": answer}
                else:
                    # Default to finish action
                    return "finish", {"answer": response}

        except Exception as e:
            logging.error(f"Error deciding action: {str(e)}")
            # Default to finish action in case of error
            return "finish", {"answer": f"I encountered an error: {str(e)}"}

    def _execute_action(self, action_name: str, action_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute an action and return the observation.
        
        Args:
            action_name: The name of the action to execute.
            action_input: The input parameters for the action.
            
        Returns:
            The observation from executing the action.
        """
        # This should be extended to call the appropriate tool
        # For now, implementing basic functionality for common actions
        
        try:
            if action_name == "search":
                # Simulate search action
                query = action_input.get("query", "")
                return {"result": f"Search results for '{query}': [Simulated search result]"}
                
            elif action_name == "calculator":
                # Implement basic calculator functionality
                expression = action_input.get("expression", "")
                try:
                    # Use safe eval to calculate expressions
                    # This should be replaced with a proper calculator tool
                    result = eval(expression, {"__builtins__": {}}, {"abs": abs, "max": max, "min": min, "sum": sum})
                    return {"result": f"Calculator result: {result}"}
                except Exception as calc_error:
                    return {"error": f"Calculator error: {str(calc_error)}"}
                    
            elif action_name == "lookup":
                # Simulate lookup action
                query = action_input.get("query", "")
                return {"result": f"Lookup result for '{query}': [Simulated lookup result]"}
                
            elif action_name == "finish":
                # Just return the answer
                return {"result": f"Final answer: {action_input.get('answer', '')}"}
                
            else:
                # Handle unknown action
                return {"error": f"Unknown action: {action_name}"}
                
        except Exception as e:
            logging.error(f"Error executing action {action_name}: {str(e)}")
            return {"error": f"Error executing {action_name}: {str(e)}"}

    def _should_terminate(self, context: Dict[str, Any]) -> bool:
        """
        Determine if execution should terminate.

        Args:
            context: The current execution context.

        Returns:
            True if execution should terminate, False otherwise.
        """
        # Check if we've reached the maximum iterations
        if self.current_iteration >= self.max_iterations - 1:
            return True

        # Check if the last action was a finish action
        if context.get("actions") and context["actions"][-1].get("name") == "finish":
            return True

        # Check if we've encountered too many errors
        error_count = sum(
            1 for obs in context.get("observations", []) if "error" in obs
        )
        if error_count >= 3:  # Terminate after 3 errors
            return True

        # Additional termination conditions could be added here

        return False

    def _generate_final_answer(self, context: Dict[str, Any]) -> str:
        """
        Generate a final answer based on the context.

        Args:
            context: The current execution context.

        Returns:
            The final answer string.
        """
        # If the last action was a finish, use its answer
        if context.get("actions") and context["actions"][-1].get("name") == "finish":
            return (
                context["actions"][-1].get("input", {}).get("answer", "Task completed.")
            )

        # Otherwise, generate a final answer using the language model
        final_answer_prompt = f"""
        You are a reasoning agent that has been working on a task.
        Based on the thought process and observations, provide a final comprehensive answer.
        
        Task: {context.get('task', '')}
        
        Thought process:
        """

        # Add the thought process to the prompt
        for i in range(len(context.get("thoughts", []))):
            final_answer_prompt += f"\nIteration {i+1}:\n"
            final_answer_prompt += f"Thought: {context['thoughts'][i]}\n"

            if i < len(context.get("actions", [])):
                action = context["actions"][i]
                final_answer_prompt += (
                    f"Action: {action['name']} - {json.dumps(action['input'])}\n"
                )

            if i < len(context.get("observations", [])):
                final_answer_prompt += f"Observation: {context['observations'][i]}\n"

        final_answer_prompt += "\nBased on the above information, provide a concise and accurate final answer to the task."

        try:
            final_answer = self.llm.generate(final_answer_prompt, temperature=0.3)
            return final_answer
        except Exception as e:
            logging.error(f"Error generating final answer: {str(e)}")

            # Fallback to a basic answer
            return "Based on my analysis, I've reached a conclusion, but had difficulty formulating the final answer."
```

## anus/core/agent/tool_agent.py

- Characters: 4366
- Tokens: 0

```python
"""
Tool Agent module that extends the react agent with tool execution capabilities.
"""

from typing import Dict, List, Any, Optional, Tuple
import importlib
import logging

from anus.core.agent.react_agent import ReactAgent

class ToolAgent(ReactAgent):
    """
    An agent that can use tools to interact with its environment.
    
    Extends the ReactAgent with the ability to discover, load, and execute tools.
    """
    
    def __init__(
        self, 
        name: Optional[str] = None, 
        max_iterations: int = 10, 
        tools: Optional[List[str]] = None,
        **kwargs
    ):
        """
        Initialize a ToolAgent instance.
        
        Args:
            name: Optional name for the agent.
            max_iterations: Maximum number of thought-action cycles to perform.
            tools: Optional list of tool names to load.
            **kwargs: Additional configuration options for the agent.
        """
        super().__init__(name=name, max_iterations=max_iterations, **kwargs)
        self.tools: Dict[str, Any] = {}
        
        # Load specified tools or default tools
        if tools:
            for tool_name in tools:
                self.load_tool(tool_name)
    
    def load_tool(self, tool_name: str) -> bool:
        """
        Load a tool by name.
        
        Args:
            tool_name: The name of the tool to load.
            
        Returns:
            True if the tool was successfully loaded, False otherwise.
        """
        try:
            # Dynamically import the tool module
            module_path = f"anus.tools.{tool_name}"
            module = importlib.import_module(module_path)
            
            # Get the tool class (assumed to be the same name as the module but capitalized)
            class_name = "".join(word.capitalize() for word in tool_name.split("_")) + "Tool"
            tool_class = getattr(module, class_name)
            
            # Instantiate the tool
            tool_instance = tool_class()
            
            # Register the tool
            self.tools[tool_name] = tool_instance
            
            self.log_action("load_tool", {"tool_name": tool_name, "status": "success"})
            return True
            
        except (ImportError, AttributeError, Exception) as e:
            self.log_action("load_tool", {"tool_name": tool_name, "status": "error", "error": str(e)})
            logging.error(f"Failed to load tool {tool_name}: {e}")
            return False
    
    def _execute_action(self, action_name: str, action_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute an action using the appropriate tool.
        
        Args:
            action_name: The name of the action/tool to execute.
            action_input: The input parameters for the action.
            
        Returns:
            The observation from executing the action.
        """
        # Check if the action corresponds to a loaded tool
        if action_name in self.tools:
            try:
                tool = self.tools[action_name]
                result = tool.execute(**action_input)
                return {"status": "success", "result": result}
            except Exception as e:
                error_message = f"Error executing tool {action_name}: {str(e)}"
                logging.error(error_message)
                return {"status": "error", "error": error_message}
        else:
            # Try to load the tool if it's not already loaded
            if self.load_tool(action_name):
                # Retry execution with the newly loaded tool
                return self._execute_action(action_name, action_input)
            else:
                return {"status": "error", "error": f"Unknown action or tool: {action_name}"}
    
    def list_available_tools(self) -> List[Dict[str, Any]]:
        """
        List all available tools and their descriptions.
        
        Returns:
            A list of dictionaries containing tool information.
        """
        tool_info = []
        for name, tool in self.tools.items():
            info = {
                "name": name,
                "description": getattr(tool, "description", "No description available"),
                "parameters": getattr(tool, "parameters", {})
            }
            tool_info.append(info)
        return tool_info
```

## anus/core/agent/base_agent.py

- Characters: 2444
- Tokens: 0

```python
"""
Base Agent module that defines the common interface for all agents.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional
import uuid
import time

class BaseAgent(ABC):
    """
    Abstract base class for all agents in the ANUS framework.
    
    Provides the core functionality and interface that all agent types must implement.
    """
    
    def __init__(self, name: Optional[str] = None, **kwargs):
        """
        Initialize a BaseAgent instance.
        
        Args:
            name: Optional name for the agent. If not provided, a UUID will be generated.
            **kwargs: Additional configuration options for the agent.
        """
        self.id = str(uuid.uuid4())
        self.name = name or f"agent-{self.id[:8]}"
        self.created_at = time.time()
        self.state: Dict[str, Any] = {"status": "initialized"}
        self.history: List[Dict[str, Any]] = []
        self.config = kwargs
    
    @abstractmethod
    def execute(self, task: str, **kwargs) -> Dict[str, Any]:
        """
        Execute a task and return the result.
        
        Args:
            task: The task description to execute.
            **kwargs: Additional parameters for task execution.
            
        Returns:
            A dictionary containing the execution result and metadata.
        """
        pass
    
    def update_state(self, **kwargs) -> None:
        """
        Update the agent's state with new values.
        
        Args:
            **kwargs: Key-value pairs to update in the state.
        """
        self.state.update(kwargs)
        
    def log_action(self, action: str, details: Dict[str, Any]) -> None:
        """
        Log an action performed by the agent.
        
        Args:
            action: The name of the action.
            details: Details about the action.
        """
        log_entry = {
            "timestamp": time.time(),
            "action": action,
            "details": details
        }
        self.history.append(log_entry)
    
    def get_info(self) -> Dict[str, Any]:
        """
        Get information about the agent.
        
        Returns:
            A dictionary containing agent information.
        """
        return {
            "id": self.id,
            "name": self.name,
            "created_at": self.created_at,
            "state": self.state,
            "history_length": len(self.history)
        }
```

## anus/core/agent/hybrid_agent.py

- Characters: 15806
- Tokens: 0

```python
"""
Hybrid Agent module that can switch between single-agent and multi-agent modes.

For when a single agent isn't enough to handle the backend load.
"""

from typing import Dict, List, Any, Optional, Tuple, Union
import logging
import random

from anus.core.agent.tool_agent import ToolAgent

class HybridAgent(ToolAgent):
    """
    An agent that can operate in both single-agent and multi-agent modes.
    
    This agent analyzes task complexity and dynamically switches between
    operating as a single agent or coordinating multiple specialized agents.
    
    Like a good ANUS, it knows when to work alone and when to bring in friends.
    """
    
    # Funny task complexity ratings
    _complexity_ratings = [
        "This task is so simple even a constipated ANUS could handle it.",
        "This task requires moderate effort. ANUS is warming up.",
        "This task is getting complicated. ANUS might need to expand a bit.",
        "Complex task detected! ANUS is stretching to accommodate.",
        "Maximum complexity reached! ANUS is fully dilated for multi-agent mode!"
    ]
    
    def __init__(
        self, 
        name: Optional[str] = None, 
        max_iterations: int = 10, 
        tools: Optional[List[str]] = None,
        mode: str = "auto",
        specialized_agents: Optional[Dict[str, Dict[str, Any]]] = None,
        **kwargs
    ):
        """
        Initialize a HybridAgent instance.
        
        Args:
            name: Optional name for the agent.
            max_iterations: Maximum number of thought-action cycles to perform.
            tools: Optional list of tool names to load.
            mode: Operating mode: "single", "multi", or "auto".
            specialized_agents: Configuration for specialized agents.
            **kwargs: Additional configuration options for the agent.
        """
        super().__init__(name=name, max_iterations=max_iterations, tools=tools, **kwargs)
        self.mode = mode
        self.specialized_agents: Dict[str, ToolAgent] = {}
        self.complexity_threshold = kwargs.get("complexity_threshold", 7)
        
        # Easter egg mode names for logging
        self._mode_names = {
            "single": "single-agent (tight and focused)",
            "multi": "multi-agent (fully expanded)",
            "auto": "auto-expanding"
        }
        
        # Initialize specialized agents if provided
        if specialized_agents:
            for role, config in specialized_agents.items():
                self.add_specialized_agent(role, config)
    
    def add_specialized_agent(self, role: str, config: Dict[str, Any]) -> bool:
        """
        Add a specialized agent for a specific role.
        
        Args:
            role: The role of the specialized agent.
            config: Configuration for the specialized agent.
            
        Returns:
            True if the agent was successfully added, False otherwise.
        """
        try:
            # Create a new ToolAgent with the given configuration
            agent_name = config.get("name", f"{role}-agent")
            agent = ToolAgent(
                name=agent_name,
                max_iterations=config.get("max_iterations", self.max_iterations),
                tools=config.get("tools", []),
                **config.get("kwargs", {})
            )
            
            # Register the specialized agent
            self.specialized_agents[role] = agent
            
            self.log_action("add_specialized_agent", {"role": role, "agent_name": agent_name})
            
            # Add easter egg log message based on role
            if role == "researcher":
                logging.debug(f"Added a researcher agent to probe deep into any subject matter")
            elif role == "coder":
                logging.debug(f"Added a coder agent to handle the backend implementation")
            elif role == "planner":
                logging.debug(f"Added a planner agent to ensure smooth passage through complex tasks")
            elif role == "critic":
                logging.debug(f"Added a critic agent to ensure everything comes out right in the end")
            else:
                logging.debug(f"Added a {role} agent to the ANUS collective")
            
            return True
            
        except Exception as e:
            error_message = f"Error adding specialized agent for role {role}: {str(e)}"
            logging.error(error_message)
            self.log_action("add_specialized_agent", {"role": role, "status": "error", "error": error_message})
            return False
    
    def execute(self, task: str, **kwargs) -> Dict[str, Any]:
        """
        Execute a task in the appropriate mode.
        
        Args:
            task: The task description to execute.
            **kwargs: Additional parameters for task execution.
            
        Returns:
            A dictionary containing the execution result and metadata.
        """
        # Override mode if specified in kwargs
        mode = kwargs.get("mode", self.mode)
        
        # If mode is auto, analyze task complexity to determine mode
        if mode == "auto":
            mode = self._determine_mode(task)
            complexity = self._analyze_task_complexity(task)
            
            # Log a funny complexity message
            rating_index = min(int(complexity // 2), len(self._complexity_ratings) - 1)
            logging.info(self._complexity_ratings[rating_index])
        
        self.update_state(status="executing", task=task, mode=mode)
        
        # Log the mode with easter egg names
        mode_name = self._mode_names.get(mode, mode)
        logging.info(f"ANUS operating in {mode_name} mode for task: {task[:50]}...")
        
        # Execute in the appropriate mode
        if mode == "single" or not self.specialized_agents:
            result = self._execute_single(task, **kwargs)
        else:
            result = self._execute_multi(task, **kwargs)
        
        self.update_state(status="completed")
        return result
    
    def _execute_single(self, task: str, **kwargs) -> Dict[str, Any]:
        """
        Execute a task in single-agent mode.
        
        Args:
            task: The task description to execute.
            **kwargs: Additional parameters for task execution.
            
        Returns:
            A dictionary containing the execution result and metadata.
        """
        # Use the ToolAgent's execute method
        logging.debug("ANUS tightening focus for single-agent execution")
        return super().execute(task, **kwargs)
    
    def _execute_multi(self, task: str, **kwargs) -> Dict[str, Any]:
        """
        Execute a task in multi-agent mode.
        
        Args:
            task: The task description to execute.
            **kwargs: Additional parameters for task execution.
            
        Returns:
            A dictionary containing the execution result and metadata.
        """
        # Ensure we have specialized agents
        if not self.specialized_agents:
            logging.warning("No specialized agents available for multi-agent execution. Falling back to single-agent mode.")
            logging.info("ANUS feels empty inside. Adding more agents is recommended.")
            return self._execute_single(task, **kwargs)
        
        # Decompose the task into subtasks for specialized agents
        logging.info(f"ANUS expanding to accommodate {len(self.specialized_agents)} specialized agents")
        subtasks = self._decompose_task(task)
        
        # Assign subtasks to specialized agents
        results = {}
        for subtask in subtasks:
            role = subtask["role"]
            subtask_description = subtask["description"]
            
            if role in self.specialized_agents:
                agent = self.specialized_agents[role]
                
                # Add easter egg log message
                if role == "researcher":
                    logging.debug(f"Researcher agent is probing deeply into: {subtask_description[:30]}...")
                elif role == "coder":
                    logging.debug(f"Coder agent is handling the backend for: {subtask_description[:30]}...")
                elif role == "planner":
                    logging.debug(f"Planner agent is ensuring smooth passage for: {subtask_description[:30]}...")
                elif role == "critic":
                    logging.debug(f"Critic agent is making sure everything comes out right for: {subtask_description[:30]}...")
                else:
                    logging.debug(f"{role.capitalize()} agent is processing: {subtask_description[:30]}...")
                
                subtask_result = agent.execute(subtask_description, **kwargs)
                results[subtask["id"]] = subtask_result
                
                self.log_action("specialized_agent_execution", {
                    "role": role,
                    "subtask_id": subtask["id"],
                    "subtask": subtask_description,
                    "status": "completed"
                })
            else:
                error_message = f"No agent available for role: {role}"
                logging.warning(error_message)
                results[subtask["id"]] = {"status": "error", "error": error_message}
        
        # Aggregate results into a final answer
        logging.info("All agents have finished their tasks. ANUS is aggregating results...")
        final_result = self._aggregate_results(task, subtasks, results)
        
        return {
            "task": task,
            "mode": "multi",
            "answer": final_result.get("answer", ""),
            "subtasks": subtasks,
            "subtask_results": results,
            "aggregated_result": final_result
        }
    
    def _determine_mode(self, task: str) -> str:
        """
        Determine whether to use single-agent or multi-agent mode.
        
        Args:
            task: The task description to analyze.
            
        Returns:
            "single" or "multi" based on task complexity.
        """
        # Analyze task complexity
        complexity = self._analyze_task_complexity(task)
        
        # If complexity exceeds threshold and we have specialized agents, use multi-agent mode
        if complexity >= self.complexity_threshold and self.specialized_agents:
            logging.info(f"Task complexity ({complexity:.1f}) exceeds threshold ({self.complexity_threshold}). ANUS expanding to multi-agent mode.")
            return "multi"
        else:
            logging.info(f"Task complexity ({complexity:.1f}) below threshold ({self.complexity_threshold}). ANUS staying tight in single-agent mode.")
            return "single"
    
    def _analyze_task_complexity(self, task: str) -> float:
        """
        Analyze the complexity of a task.
        
        Args:
            task: The task description to analyze.
            
        Returns:
            A complexity score (higher values indicate more complex tasks).
        """
        # Placeholder implementation
        # In a real implementation, this would use more sophisticated metrics
        
        # Basic heuristics
        score = 0
        
        # Length-based complexity
        words = task.split()
        score += min(len(words) / 10, 5)  # Cap at 5 points
        
        # Keyword-based complexity
        complexity_keywords = [
            "complex", "difficult", "challenging", "multiple", "analyze", 
            "compare", "design", "create", "optimize", "solve"
        ]
        for keyword in complexity_keywords:
            if keyword in task.lower():
                score += 0.5
        
        # Easter egg: add extra complexity for certain funny keywords
        funny_keywords = ["hard", "deep", "tight", "huge", "massive", "backend", "insertion", "hole"]
        for keyword in funny_keywords:
            if keyword in task.lower():
                score += 0.3
                logging.debug(f"Found complexity keyword '{keyword}' - ANUS might need to expand")
        
        return score
    
    def _decompose_task(self, task: str) -> List[Dict[str, Any]]:
        """
        Decompose a task into subtasks for specialized agents.
        
        Args:
            task: The task description to decompose.
            
        Returns:
            A list of subtask dictionaries with role assignments.
        """
        # Placeholder implementation
        # In a real implementation, this would use an LLM to decompose the task
        
        # Get available roles
        available_roles = list(self.specialized_agents.keys())
        
        # Random funny descriptors for different roles
        role_descriptors = {
            "researcher": [
                "dig deep into",
                "probe thoroughly",
                "explore every crevice of",
                "investigate the depths of",
                "get to the bottom of"
            ],
            "coder": [
                "implement the backend for",
                "code up a tight solution for",
                "develop a robust framework for",
                "craft efficient code for",
                "build a solid foundation for"
            ],
            "planner": [
                "chart a clear passage for",
                "develop a smooth approach to",
                "create a flexible plan for",
                "map out the ins and outs of",
                "devise a strategy for"
            ],
            "critic": [
                "thoroughly examine",
                "inspect every inch of",
                "ensure nothing leaks in",
                "check for holes in",
                "make sure everything comes out right for"
            ]
        }
        
        # Create simple subtasks based on available roles
        subtasks = []
        for i, role in enumerate(available_roles):
            # Pick a random descriptor for this role
            descriptors = role_descriptors.get(role, ["handle"])
            descriptor = random.choice(descriptors)
            
            subtask = {
                "id": f"subtask-{i+1}",
                "role": role,
                "description": f"As a {role}, {descriptor} {task}"
            }
            subtasks.append(subtask)
        
        logging.info(f"Task decomposed into {len(subtasks)} subtasks for optimal ANUS performance")
        return subtasks
    
    def _aggregate_results(self, task: str, subtasks: List[Dict[str, Any]], results: Dict[str, Any]) -> Dict[str, Any]:
        """
        Aggregate results from multiple specialized agents.
        
        Args:
            task: The original task description.
            subtasks: The list of subtasks assigned to agents.
            results: The results from each specialized agent.
            
        Returns:
            An aggregated result.
        """
        # Placeholder implementation
        # In a real implementation, this would use an LLM to synthesize results
        
        # Simple concatenation of results
        answers = []
        for subtask in subtasks:
            subtask_id = subtask["id"]
            if subtask_id in results:
                result = results[subtask_id]
                if "answer" in result:
                    answers.append(f"[{subtask['role']}]: {result['answer']}")
        
        final_answer = "\n\n".join(answers)
        
        logging.info("ANUS has successfully completed multi-agent processing")
        logging.debug(f"Aggregated {len(answers)} agent outputs into one comprehensive response")
        
        return {
            "answer": final_answer,
            "status": "success"
        }
```

## anus/core/agent/__init__.py

- Characters: 589
- Tokens: 0

```python
"""
Agent module for the ANUS framework.

This module contains various agent implementations:
- BaseAgent: Abstract base class for all agents
- ReactAgent: Agent with reasoning capabilities
- ToolAgent: Agent with tool execution capabilities
- HybridAgent: Agent that can switch between single and multi-agent modes
"""

from anus.core.agent.base_agent import BaseAgent
from anus.core.agent.react_agent import ReactAgent
from anus.core.agent.tool_agent import ToolAgent
from anus.core.agent.hybrid_agent import HybridAgent

__all__ = ["BaseAgent", "ReactAgent", "ToolAgent", "HybridAgent"]
```

## anus/__init__.py

- Characters: 232
- Tokens: 0

```python
"""
Anus - Autonomous Networked Utility System
Package initialization
"""

__version__ = "0.1.0"
__author__ = "Anus AI Team"
__email__ = "anus-ai@example.com"
__description__ = "An open-source AI agent framework for task automation"
```

## setup.py

- Characters: 1122
- Tokens: 0

```python
from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

with open("requirements.txt", "r", encoding="utf-8") as fh:
    requirements = fh.read().splitlines()

setup(
    name="anus-ai",
    version="0.1.0",
    author="Anus AI Team",
    author_email="anus-ai@example.com",
    description="An open-source AI agent framework for task automation",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/anus-ai/anus",
    packages=find_packages(),
    classifiers=[
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.11",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Developers",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
    ],
    python_requires=">=3.11",
    install_requires=requirements,
    entry_points={
        "console_scripts": [
            "anus=main:main",
        ],
    },
)
```

## CHANGELOG.md

- Characters: 705
- Tokens: 0

```markdown
# CHANGELOG.md

# Changelog

All notable changes to the Anus AI project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added
- Initial project structure
- Core engine components
- Agent system framework
- Tool ecosystem foundation
- Model integration interfaces
- User interface components
- Documentation framework
- Project logo and branding

### Changed
- N/A

### Deprecated
- N/A

### Removed
- N/A

### Fixed
- N/A

### Security
- N/A

## [0.1.0] - 2025-03-09
- Initial release
- Basic project structure and documentation
```

## requirements.txt

- Characters: 647
- Tokens: 0

```text
# Python dependencies for Anus AI
# Core dependencies
openai>=1.0.0
anthropic>=0.5.0
langchain>=0.0.267
pydantic>=2.0.0
PyYAML>=6.0
python-dotenv>=1.0.0
typer>=0.9.0
rich>=13.0.0
tqdm>=4.66.0
google-genai>=1.5.0

# Web and browser automation
playwright>=1.40.0
beautifulsoup4>=4.12.0
requests>=2.31.0
aiohttp>=3.8.5

# Document processing
pypdf>=3.15.0
python-docx>=0.8.11
openpyxl>=3.1.2
pillow>=10.0.0

# Code execution
jupyter-client>=8.3.0
nbformat>=5.9.0

# Testing
pytest>=7.4.0
pytest-cov>=4.1.0

# Development
black>=23.7.0
isort>=5.12.0
flake8>=6.1.0
mypy>=1.5.0

# API and web interface
fastapi>=0.103.0
uvicorn>=0.23.0
streamlit>=1.26.0
```

## assets/anus_logo.py

- Characters: 1908
- Tokens: 0

```python
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Circle, Ellipse
from matplotlib.colors import LinearSegmentedColormap

# Set up the figure
fig, ax = plt.subplots(figsize=(10, 10))
ax.set_aspect('equal')
ax.axis('off')

# Create a custom colormap for the gradient background
colors = [(0.8, 0.4, 0.6), (0.6, 0.2, 0.5)]  # Pink to purple gradient
cmap = LinearSegmentedColormap.from_list("custom_cmap", colors, N=100)

# Create a circular background with gradient
circle_bg = Circle((0.5, 0.5), 0.45, transform=ax.transAxes, 
                  color='white', zorder=0)
ax.add_patch(circle_bg)

# Create the main shape (stylized "A" that resembles a peach)
# First half of the "A"
ellipse1 = Ellipse((0.4, 0.5), 0.4, 0.7, angle=-20, 
                  color=colors[0], alpha=0.9, zorder=1)
ax.add_patch(ellipse1)

# Second half of the "A"
ellipse2 = Ellipse((0.6, 0.5), 0.4, 0.7, angle=20, 
                  color=colors[1], alpha=0.9, zorder=1)
ax.add_patch(ellipse2)

# Add a small circle at the top to complete the "A"
circle_top = Circle((0.5, 0.8), 0.08, color=(0.7, 0.3, 0.5), zorder=2)
ax.add_patch(circle_top)

# Add a horizontal line to represent the crossbar of the "A"
ax.plot([0.35, 0.65], [0.5, 0.5], color='white', linewidth=8, zorder=3)

# Add AI-themed elements (circuit-like lines)
for i in range(5):
    angle = np.pi * 2 * i / 5
    x = 0.5 + 0.5 * np.cos(angle)
    y = 0.5 + 0.5 * np.sin(angle)
    ax.plot([0.5, x], [0.5, y], color='white', linewidth=1, alpha=0.5, zorder=4)

# Set the limits
ax.set_xlim(0, 1)
ax.set_ylim(0, 1)

# Save the logo
plt.savefig('/home/ubuntu/anus-ai-project/assets/anus_logo.png', 
           dpi=300, bbox_inches='tight', transparent=True)
plt.savefig('/home/ubuntu/anus-ai-project/assets/anus_logo_small.png', 
           dpi=100, bbox_inches='tight', transparent=True)

print("Logo created and saved to assets directory")
```

## assets/toc.md

- Characters: 352
- Tokens: 0

```markdown
# Table of Contents

- [Introduction](#-introduction)
- [Why Anus?](#-why-anus)
- [Features & Capabilities](#-features--capabilities)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Usage Examples](#-usage-examples)
- [Documentation](#-documentation)
- [Contributing](#-contributing)
- [Community](#-community)
- [License](#-license)
```

## assets/badges.md

- Characters: 1251
- Tokens: 0

```markdown
<!-- Badges for the Anus AI project -->

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](https://github.com/anus-ai/anus/blob/main/CONTRIBUTING.md)
[![GitHub stars](https://img.shields.io/github/stars/anus-ai/anus.svg?style=social&label=Star)](https://github.com/anus-ai/anus)
[![GitHub forks](https://img.shields.io/github/forks/anus-ai/anus.svg?style=social&label=Fork)](https://github.com/anus-ai/anus)
[![GitHub issues](https://img.shields.io/github/issues/anus-ai/anus.svg)](https://github.com/anus-ai/anus/issues)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://makeapullrequest.com)
[![Documentation Status](https://img.shields.io/badge/docs-latest-brightgreen.svg)](https://anus-ai.github.io/docs)
[![Discord](https://img.shields.io/discord/1234567890?color=7289da&label=Discord&logo=discord&logoColor=white)](https://discord.gg/anus-ai)
```

## LICENSE

- Characters: 1068
- Tokens: 0

```text
MIT License

Copyright (c) 2025 Anus AI Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## repo.json

- Characters: 132
- Tokens: 0

```json
{
  "name": "ANUS",
  "description": "Advanced Neural Understanding System - AI Project",
  "private": false,
  "auto_init": false
}
```

## repomix-output.md

- Characters: 346513
- Tokens: 0

`````markdown
This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-03-10 16:23:10

# File Summary

## Purpose:

This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

## File Format:

The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
   a. A header with the file path (## File: path/to/file)
   b. The full contents of the file in a code block

## Usage Guidelines:

- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

## Notes:

- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

## Additional Information:

For more information about Repomix, visit: https://github.com/andersonby/python-repomix


# Repository Structure

```
README.md
.gitignore
tests
  README.md
CONTRIBUTING.md
examples
  README.md
instructions
  Implementation Recommendations.md
  Implementation Roadmap.md
  Planning Script.py
  anus_architecture_design.md
  Valuable Concepts.md
CODE_OF_CONDUCT.md
research
  README.md
anus
  tools
    README.md
    utility
      calculator.py
      __init__.py
    base
      tool_result.py
      tool.py
      __init__.py
      tool_collection.py
    __init__.py
  models
    README.md
    base
      base_model.py
      __init__.py
    model_router.py
    gemini_model.py
    __init__.py
    openai_model.py
  agents
    README.md
  ui
    README.md
    cli.py
    __init__.py
  core
    README.md
    memory
      long_term.py
      __init__.py
      short_term.py
      base_memory.py
    orchestrator.py
    planning
      task_planner.py
      __init__.py
      base_planner.py
    agent
      react_agent.py
      tool_agent.py
      base_agent.py
      hybrid_agent.py
      __init__.py
  __init__.py
setup.py
CHANGELOG.md
requirements.txt
assets
  anus_logo.py
  toc.md
  badges.md
LICENSE
repo.json
docs
  advanced_usage.md
  architecture_overview.md
  architecture.md
  api_reference.md
  getting_started.md
main.py
__init__.py
todo.md
```

# Repository Files


## README.md

- Characters: 18558
- Tokens: 0

````markdown
# üçë Anus: Autonomous Networked Utility System

<p align="center">
  <img src="assets/anus_logo.png" alt="Anus AI Logo" width="200"/>
</p>

<p align="center">
  <a href="https://github.com/nikmcfly/ANUS/blob/main/LICENSE"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="License: MIT"></a>
  <a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.11+-blue.svg" alt="Python version"></a>
  <a href="https://github.com/psf/black"><img src="https://img.shields.io/badge/code%20style-black-000000.svg" alt="Code style: black"></a>
  <a href="https://github.com/nikmcfly/ANUS/blob/main/CONTRIBUTING.md"><img src="https://img.shields.io/badge/contributions-welcome-brightgreen.svg" alt="Contributions welcome"></a>
  <br>
  <a href="https://github.com/nikmcfly/ANUS/stargazers"><img src="https://img.shields.io/github/stars/nikmcfly/ANUS.svg?style=social&label=Star" alt="GitHub stars"></a>
  <a href="https://github.com/nikmcfly/ANUS/network/members"><img src="https://img.shields.io/github/forks/nikmcfly/ANUS.svg?style=social&label=Fork" alt="GitHub forks"></a>
  <a href="https://github.com/nikmcfly/ANUS/issues"><img src="https://img.shields.io/github/issues/nikmcfly/ANUS.svg" alt="GitHub issues"></a>
  <a href="https://makeapullrequest.com"><img src="https://img.shields.io/badge/PRs-welcome-brightgreen.svg" alt="PRs Welcome"></a>
  <a href="https://anus-ai.github.io/docs"><img src="https://img.shields.io/badge/docs-latest-brightgreen.svg" alt="Documentation Status"></a>
  <a href="https://discord.gg/anus-ai"><img src="https://img.shields.io/discord/1234567890?color=7289da&label=Discord&logo=discord&logoColor=white" alt="Discord"></a>
</p>

## Table of Contents

- [Introduction](#-introduction)
- [Why Anus?](#-why-anus)
- [Features & Capabilities](#-features--capabilities)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Usage Examples](#-usage-examples)
- [Documentation](#-documentation)
- [Contributing](#-contributing)
- [Community](#-community)
- [License](#-license)

## üåü Introduction

**Anus** (Autonomous Networked Utility System) is a powerful, flexible, and accessible open-source AI agent framework designed to revolutionize task automation. Built with modern AI technologies and best practices, Anus represents the next generation of AI agent frameworks, offering unparalleled capabilities and ease of use.

Anus empowers users to create AI agents that can:
- Execute complex tasks through natural language instructions
- Collaborate in multi-agent environments to solve problems
- Interact with web services, documents, and code
- Process multimodal inputs including text, images, and audio
- Adapt to different domains and use cases

Whether you're a developer looking to build AI-powered applications, a researcher exploring agent-based systems, or an enthusiast interested in the latest AI technologies, Anus provides the tools and flexibility you need to succeed.

## üí° Why Anus?

- **Truly Open Source**: No barriers, no invite codes, just pure open-source goodness
- **Hybrid Architecture**: Combines single-agent simplicity with multi-agent power
- **Flexible Model Support**: Works with OpenAI models, open-source models, or your own
- **Comprehensive Tool Ecosystem**: Web automation, document processing, code execution, and more
- **Community-First Design**: Built for contributions and extensions
- **Transparent Operation**: Clear explanations of all agent actions and decisions
- **Cross-Platform**: Works across different operating systems and environments

## ‚ú® Features & Capabilities

### üß† Advanced AI Agent Architecture

- **Hybrid Agent System**: Seamlessly switch between single-agent and multi-agent modes based on task complexity
- **Dynamic Task Planning**: Sophisticated planning system that breaks down complex tasks into manageable steps
- **Adaptive Resource Allocation**: Intelligently allocates computational resources based on task requirements
- **Memory Management**: Short-term and long-term memory systems for context retention across conversations
- **Explainable Actions**: Transparent reasoning and decision-making processes

### ü§ù Multi-Agent Collaboration

- **Specialized Agent Roles**: Pre-defined roles like Researcher, Coder, Planner, and more
- **Custom Role Creation**: Define your own agent roles with specific capabilities and knowledge
- **Inter-Agent Communication**: Structured protocols for efficient agent-to-agent communication
- **Consensus Mechanisms**: Collaborative decision-making through agent voting and consensus
- **Conflict Resolution**: Sophisticated protocols for resolving disagreements between agents

### üõ†Ô∏è Comprehensive Tool Ecosystem

- **Web Interaction**:
  - Full browser automation via Playwright
  - Web scraping and data extraction
  - Form filling and submission
  - Authentication handling

- **Information Retrieval**:
  - Search engine integration
  - Wikipedia access
  - News and current events sources
  - Specialized knowledge bases

- **Document Processing**:
  - PDF parsing and analysis
  - Office document handling (Word, Excel, PowerPoint)
  - Image recognition and OCR
  - Data extraction and transformation

- **Code Execution**:
  - Secure Python execution sandbox
  - Multiple language support
  - Package management
  - Output capture and analysis

- **Multimodal Processing**:
  - Image analysis and generation
  - Audio processing and transcription
  - Video analysis and summarization
  - Chart and graph interpretation

### üîÑ Flexible Model Integration

- **OpenAI API Support**: Seamless integration with GPT-4 and newer models
- **Open-Source Models**: Support for Llama, Mistral, and other open-source models
- **Local Deployment**: Run models locally for privacy and reduced costs
- **Model Switching**: Automatically select the appropriate model based on task requirements
- **Fallback Mechanisms**: Gracefully handle API issues by switching to alternative models

### üë• User-Friendly Interfaces

- **Command-Line Interface**: Simple and intuitive commands for terminal users
- **Web Interface**: Optional browser-based dashboard for visual interaction
- **API Integration**: RESTful API for embedding Anus in other applications
- **Conversation History**: Review and continue previous conversations
- **Task Monitoring**: Track progress of long-running tasks

### üîí Privacy and Security

- **Local Execution**: Process sensitive data locally without sending to external APIs
- **API Key Management**: Secure handling of API keys and credentials
- **Permission System**: Fine-grained control over agent capabilities
- **Audit Logging**: Comprehensive logging of all agent actions
- **Sandboxed Execution**: Secure environment for running untrusted code

### üß© Extensibility

- **Plugin System**: Easily extend functionality with custom plugins
- **Custom Tools**: Create your own tools to expand agent capabilities
- **Model Adapters**: Add support for new AI models
- **Middleware**: Insert custom processing steps in the agent workflow
- **Event Hooks**: React to specific events in the agent lifecycle

## üîß Installation

Anus AI supports multiple installation methods to accommodate different user preferences and environments.

### Prerequisites

- Python 3.11 or higher
- pip (Python package installer)
- Git

### Method 1: Pip Installation (Recommended for Users)

```bash
# Install from PyPI
pip install anus-ai

# Verify installation
anus --version
```

### Method 2: From Source (Recommended for Developers)

```bash
# Clone the repository
git clone https://github.com/nikmcfly/ANUS.git
cd ANUS

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e .

# Verify installation
anus --version
```

### Method 3: Using Docker

```bash
# Pull the Docker image
docker pull anusai/anus:latest

# Run Anus in a container
docker run -it anusai/anus:latest
```

### Method 4: Using Conda

```bash
# Create a new conda environment
conda create -n anus python=3.11
conda activate anus

# Install Anus
pip install anus-ai
```

### Platform-Specific Instructions

#### Windows

```bash
# Install required system dependencies
pip install windows-curses

# If using browser automation
playwright install
```

#### macOS

```bash
# Install required system dependencies
brew install python@3.11

# If using browser automation
playwright install
```

#### Linux

```bash
# Install required system dependencies
sudo apt-get update
sudo apt-get install -y python3.11 python3.11-venv

# If using browser automation
playwright install
```

### Optional Dependencies

Anus has several optional features that require additional dependencies:

```bash
# For document processing
pip install anus-ai[documents]

# For browser automation
pip install anus-ai[browser]

# For code execution
pip install anus-ai[code]

# For all optional features
pip install anus-ai[all]
```

### Configuration

After installation, you'll need to configure Anus with your API keys:

1. Create a configuration file:

```bash
anus init
```

2. Edit the generated `.anus/config.yaml` file with your API keys:

```yaml
llm:
  provider: openai
  api_key: your_openai_api_key
  model: gpt-4o

# Optional: Configure other providers
anthropic:
  api_key: your_anthropic_api_key

# Optional: Configure tool-specific settings
browser:
  headless: true
```

## üöÄ Quick Start

Once installed, you can start using Anus right away:

```bash
# Run Anus with a simple task
anus run "Find the latest news about artificial intelligence"

# Run in interactive mode
anus interactive

# Run with a specific configuration file
anus run --config custom_config.yaml "Summarize this article: https://example.com/article"
```

## üìã Usage Examples

### Basic Examples

#### Simple Question Answering

```python
from anus import Agent

# Create a single agent
agent = Agent()

# Ask a simple question
response = agent.run("What is the capital of France?")
print(response)
```

#### Web Search

```python
from anus import Agent
from anus.tools import SearchTool

# Create an agent with search capabilities
agent = Agent(tools=[SearchTool()])

# Search for information
response = agent.run("Find the latest research on quantum computing")
print(response)
```

#### Document Analysis

```python
from anus import Agent
from anus.tools import DocumentTool

# Create an agent with document processing capabilities
agent = Agent(tools=[DocumentTool()])

# Analyze a PDF document
response = agent.run("Summarize this PDF: /path/to/document.pdf")
print(response)
```

### Advanced Examples

#### Multi-Agent Collaboration

```python
from anus import Society, Agent

# Create specialized agents
researcher = Agent(role="researcher")
analyst = Agent(role="analyst")
writer = Agent(role="writer")

# Create a society of agents
society = Society(agents=[researcher, analyst, writer])

# Execute a complex task with collaboration
response = society.run(
    "Research the impact of artificial intelligence on healthcare, " 
    "analyze the findings, and write a comprehensive report"
)
print(response)
```

#### Browser Automation

```python
from anus import Agent
from anus.tools import BrowserTool

# Create an agent with browser capabilities
agent = Agent(tools=[BrowserTool()])

# Perform a web task
response = agent.run(
    "Go to weather.com, check the weather forecast for New York City for the next 5 days, "
    "and create a summary table"
)
print(response)
```

#### Code Generation and Execution

```python
from anus import Agent
from anus.tools import CodeTool

# Create an agent with code execution capabilities
agent = Agent(tools=[CodeTool()])

# Generate and execute code
response = agent.run(
    "Create a Python script that generates a fractal tree visualization using matplotlib"
)
print(response)
```

### Command-Line Interface Examples

#### Running Tasks

```bash
# Simple information retrieval
anus run "What is the population of Tokyo?"

# Web search with specific parameters
anus run --search-depth=3 "Find recent breakthroughs in fusion energy research"

# Document processing
anus run --file=/path/to/report.pdf "Extract all financial data from this report"
```

#### Interactive Mode

```bash
# Start interactive session
anus interactive

# In interactive mode, you can have a conversation:
# > Tell me about the history of artificial intelligence
# > Now create a timeline of major AI milestones
# > Generate a visualization of this timeline
```

#### Multi-Agent Mode

```bash
# Run a complex task with multiple agents
anus run --mode=multi "Research, analyze, and summarize the current state of renewable energy technologies"

# Specify particular agent roles
anus run --mode=multi --roles=researcher,analyst,writer "Create a comprehensive market analysis for electric vehicles"
```

### API Usage

```python
from anus.api import AnusAPI

# Initialize the API client
api = AnusAPI(api_key="your_api_key")

# Send a request
response = api.process_task(
    task="Generate a business plan for a sustainable fashion startup",
    mode="multi",
    output_format="markdown"
)

# Print or save the response
print(response.result)
with open("business_plan.md", "w") as f:
    f.write(response.result)
```

### Advanced Configuration

```python
from anus import Agent, Config

# Create a custom configuration
config = Config(
    llm={
        "provider": "anthropic",
        "model": "claude-3-opus",
        "temperature": 0.7,
    },
    memory={
        "type": "persistent",
        "path": "./agent_memory",
    },
    tools={
        "browser": {"headless": False},
        "code": {"sandbox": True},
    }
)

# Create an agent with custom configuration
agent = Agent(config=config)

# Run a task
response = agent.run("Create an interactive data visualization for climate change data")
print(response)
```

## üìö Documentation

For detailed documentation, visit our [Documentation Site](https://anus-ai.github.io/docs).

- [Installation Guide](https://anus-ai.github.io/docs/installation)
- [Getting Started](https://anus-ai.github.io/docs/getting-started)
- [Architecture Overview](https://anus-ai.github.io/docs/architecture)
- [API Reference](https://anus-ai.github.io/docs/api)
- [Examples](https://anus-ai.github.io/docs/examples)
- [Contributing Guide](https://anus-ai.github.io/docs/contributing)

## üë• Contributing

We welcome contributions from the community! Anus is designed to be community-driven, and your input helps make it better for everyone.

### Ways to Contribute

- **Code Contributions**: Implement new features, fix bugs, or improve performance
- **Documentation**: Improve or expand documentation, add examples, fix typos
- **Bug Reports**: Report bugs or suggest improvements
- **Feature Requests**: Suggest new features or enhancements
- **Community Support**: Help answer questions and support other users

### Getting Started with Contributing

1. **Fork the Repository**

```bash
# Fork the repository on GitHub, then clone your fork
git clone https://github.com/your-username/anus.git
cd anus
```

2. **Set Up Development Environment**

```bash
# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install development dependencies
pip install -e ".[dev]"
```

3. **Create a Branch**

```bash
# Create a branch for your contribution
git checkout -b feature/your-feature-name
```

4. **Make Your Changes**

- Follow the code style guidelines
- Add tests for new functionality
- Update documentation as needed

5. **Run Tests**

```bash
# Run the test suite
pytest

# Run linting
flake8
mypy anus
```

6. **Submit a Pull Request**

- Push your changes to your fork
- Submit a pull request from your branch to our main branch
- Provide a clear description of the changes and any related issues

### Code Style Guidelines

- Follow [PEP 8](https://pep8.org/) for Python code style
- Use type hints for all function parameters and return values
- Write docstrings for all functions, classes, and modules
- Keep functions focused and small (under 50 lines when possible)
- Use meaningful variable and function names

### Commit Message Guidelines

We follow the [Conventional Commits](https://www.conventionalcommits.org/) specification:

```
<type>(<scope>): <description>

[optional body]

[optional footer(s)]
```

Types include:
- `feat`: A new feature
- `fix`: A bug fix
- `docs`: Documentation changes
- `style`: Code style changes (formatting, etc.)
- `refactor`: Code changes that neither fix bugs nor add features
- `test`: Adding or modifying tests
- `chore`: Changes to the build process or auxiliary tools

### Pull Request Process

1. Update the README.md or documentation with details of changes if appropriate
2. Update the CHANGELOG.md with details of changes
3. The PR should work for Python 3.11 and above
4. PRs require approval from at least one maintainer
5. Once approved, a maintainer will merge your PR

### Code of Conduct

Please note that this project is released with a [Contributor Code of Conduct](CODE_OF_CONDUCT.md). By participating in this project you agree to abide by its terms.

## üåê Community

Join our community to get help, share ideas, and contribute to the project:

- [Discord Server](https://discord.gg/anus-ai)
- [Twitter](https://twitter.com/anus_ai)
- [Reddit](https://reddit.com/r/anus_ai)

## üìù License

Anus is released under the [MIT License](LICENSE).

```
MIT License

Copyright (c) 2025 Anus AI Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```
````

## .gitignore

- Characters: 3455
- Tokens: 0

```text
config.yaml

# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/

# Translations
*.mo
*.pot

# Django stuff:
*.log
local_settings.py
db.sqlite3
db.sqlite3-journal

# Flask stuff:
instance/
.webassets-cache

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
.pybuilder/
target/

# Jupyter Notebook
.ipynb_checkpoints

# IPython
profile_default/
ipython_config.py

# pyenv
#   For a library or package, you might want to ignore these files since the code is
#   intended to run in multiple environments; otherwise, check them in:
# .python-version

# pipenv
#   According to pypa/pipenv#598, it is recommended to include Pipfile.lock in version control.
#   However, in case of collaboration, if having platform-specific dependencies or dependencies
#   having no cross-platform support, pipenv may install dependencies that don't work, or not
#   install all needed dependencies.
#Pipfile.lock

# UV
#   Similar to Pipfile.lock, it is generally recommended to include uv.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#uv.lock

# poetry
#   Similar to Pipfile.lock, it is generally recommended to include poetry.lock in version control.
#   This is especially recommended for binary packages to ensure reproducibility, and is more
#   commonly ignored for libraries.
#   https://python-poetry.org/docs/basic-usage/#commit-your-poetrylock-file-to-version-control
#poetry.lock

# pdm
#   Similar to Pipfile.lock, it is generally recommended to include pdm.lock in version control.
#pdm.lock
#   pdm stores project-wide configurations in .pdm.toml, but it is recommended to not include it
#   in version control.
#   https://pdm.fming.dev/latest/usage/project/#working-with-version-control
.pdm.toml
.pdm-python
.pdm-build/

# PEP 582; used by e.g. github.com/David-OConnor/pyflow and github.com/pdm-project/pdm
__pypackages__/

# Celery stuff
celerybeat-schedule
celerybeat.pid

# SageMath parsed files
*.sage.py

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# Pyre type checker
.pyre/

# pytype static type analyzer
.pytype/

# Cython debug symbols
cython_debug/

# PyCharm
#  JetBrains specific template is maintained in a separate JetBrains.gitignore that can
#  be found at https://github.com/github/gitignore/blob/main/Global/JetBrains.gitignore
#  and can be added to the global gitignore or merged into this file.  For a more nuclear
#  option (not recommended) you can uncomment the following to ignore the entire idea folder.
#.idea/

# Ruff stuff:
.ruff_cache/

# PyPI configuration file
.pypirc
```

## tests/README.md

- Characters: 671
- Tokens: 0

```markdown
# Tests

This directory contains test cases for the Anus AI agent framework.

## Unit Tests

- `test_core/`: Tests for core module components
- `test_agents/`: Tests for agent system components
- `test_tools/`: Tests for tool ecosystem components
- `test_models/`: Tests for model integration components
- `test_ui/`: Tests for user interface components

## Integration Tests

- `test_integration/`: Tests for integration between different components
- `test_end_to_end/`: End-to-end tests for complete workflows

## Benchmark Tests

- `test_benchmarks/`: Performance and capability benchmark tests
- `test_comparison/`: Comparison tests against other AI agent frameworks
```

## CONTRIBUTING.md

- Characters: 4908
- Tokens: 0

````markdown
# CONTRIBUTING.md

# Contributing to Anus AI

Thank you for your interest in contributing to Anus AI! This document provides guidelines and instructions for contributing to the project.

## Table of Contents

- [Code of Conduct](#code-of-conduct)
- [How Can I Contribute?](#how-can-i-contribute)
- [Development Setup](#development-setup)
- [Pull Request Process](#pull-request-process)
- [Coding Standards](#coding-standards)
- [Testing](#testing)
- [Documentation](#documentation)
- [Community](#community)

## Code of Conduct

This project and everyone participating in it is governed by the [Anus AI Code of Conduct](CODE_OF_CONDUCT.md). By participating, you are expected to uphold this code. Please report unacceptable behavior to the project maintainers.

## How Can I Contribute?

### Reporting Bugs

- **Ensure the bug was not already reported** by searching on GitHub under [Issues](https://github.com/anus-ai/anus/issues).
- If you're unable to find an open issue addressing the problem, [open a new one](https://github.com/anus-ai/anus/issues/new). Be sure to include a **title and clear description**, as much relevant information as possible, and a **code sample** or an **executable test case** demonstrating the expected behavior that is not occurring.

### Suggesting Enhancements

- Open a new issue with a clear title and detailed description.
- Provide specific examples and steps to demonstrate the enhancement.
- Explain why this enhancement would be useful to most Anus AI users.

### Your First Code Contribution

- Look for issues labeled "good first issue" or "help wanted" to find good starting points.
- Fork the repository and create a branch for your changes.
- Make your changes and submit a pull request.

### Pull Requests

- Fill in the required template.
- Do not include issue numbers in the PR title.
- Include screenshots and animated GIFs in your pull request whenever possible.
- Follow the coding standards.
- Document new code.
- End all files with a newline.

## Development Setup

### Prerequisites

- Python 3.11 or higher
- Git
- pip or conda

### Setting Up Your Development Environment

1. Fork the repository on GitHub.
2. Clone your fork locally:
   ```bash
   git clone https://github.com/your-username/anus.git
   cd anus
   ```

3. Create a virtual environment:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

4. Install development dependencies:
   ```bash
   pip install -e ".[dev]"
   ```

5. Set up pre-commit hooks:
   ```bash
   pre-commit install
   ```

## Pull Request Process

1. Update the README.md or documentation with details of changes if appropriate.
2. Update the CHANGELOG.md with details of changes.
3. The PR should work for Python 3.11 and above.
4. PRs require approval from at least one maintainer.
5. Once approved, a maintainer will merge your PR.

## Coding Standards

### Python Style Guide

- Follow [PEP 8](https://pep8.org/) for Python code style.
- Use [Black](https://github.com/psf/black) for code formatting.
- Use [isort](https://pycqa.github.io/isort/) for import sorting.
- Use [flake8](https://flake8.pycqa.org/) for linting.
- Use [mypy](https://mypy.readthedocs.io/) for type checking.

### Type Hints

- Use type hints for all function parameters and return values.
- Use `Optional` for parameters that can be `None`.
- Use `Union` for parameters that can be multiple types.
- Use `Any` sparingly and only when necessary.

### Documentation

- Write docstrings for all functions, classes, and modules.
- Follow the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html#38-comments-and-docstrings) for docstrings.
- Keep documentation up-to-date with code changes.

### Commit Messages

We follow the [Conventional Commits](https://www.conventionalcommits.org/) specification:

```
<type>(<scope>): <description>

[optional body]

[optional footer(s)]
```

Types include:
- `feat`: A new feature
- `fix`: A bug fix
- `docs`: Documentation changes
- `style`: Code style changes (formatting, etc.)
- `refactor`: Code changes that neither fix bugs nor add features
- `test`: Adding or modifying tests
- `chore`: Changes to the build process or auxiliary tools

## Testing

- Write tests for all new features and bug fixes.
- Run the test suite before submitting a pull request:
  ```bash
  pytest
  ```
- Aim for high test coverage.
- Write both unit tests and integration tests.

## Documentation

- Update documentation for all new features and changes.
- Write clear and concise documentation.
- Include examples where appropriate.
- Check for spelling and grammar errors.

## Community

Join our community to get help, share ideas, and contribute to the project:

- [Discord Server](https://discord.gg/anus-ai)
- [Twitter](https://twitter.com/anus_ai)
- [Reddit](https://reddit.com/r/anus_ai)

Thank you for contributing to Anus AI!
````

## examples/README.md

- Characters: 858
- Tokens: 0

```markdown
# Examples

This directory contains example use cases and demonstrations of the Anus AI agent framework.

## Basic Examples

- `simple_task.py`: Demonstrates basic usage of the Anus AI agent for simple tasks.
- `web_search.py`: Shows how to use the agent for web search and information retrieval.
- `code_generation.py`: Example of using the agent for code generation and execution.

## Advanced Examples

- `multi_agent_collaboration.py`: Demonstrates the multi-agent collaboration capabilities.
- `document_processing.py`: Shows how to process and analyze documents.
- `browser_automation.py`: Example of browser automation for web tasks.

## Tutorials

- `getting_started.md`: Step-by-step tutorial for getting started with Anus AI.
- `custom_agent.md`: Guide for creating custom agent roles.
- `tool_development.md`: Tutorial for developing custom tools.
```

## instructions/Implementation Recommendations.md

- Characters: 44934
- Tokens: 0

````markdown
# Implementation Recommendations for ANUS

This document provides specific implementation recommendations for adapting valuable concepts from OpenManus into the ANUS framework. These recommendations focus on practical implementation details while respecting and enhancing ANUS's current structure.

## Core Agent System

### BaseAgent Implementation

```python
# anus/core/agent/base_agent.py

from abc import ABC, abstractmethod
from typing import List, Optional
from pydantic import BaseModel, Field

from anus.models.base_model import BaseModel as LLMModel
from anus.core.memory.base_memory import BaseMemory
from anus.core.schema import AgentState, Message

class BaseAgent(BaseModel, ABC):
    """
    Abstract base class for all ANUS agents.
    Provides foundational functionality for state management, memory, and execution.
    """
    # Core attributes
    name: str = Field(..., description="Unique name of the agent")
    description: Optional[str] = Field(None, description="Agent description")
    
    # Prompts
    system_prompt: Optional[str] = Field(None, description="System-level instruction prompt")
    next_step_prompt: Optional[str] = Field(None, description="Prompt for determining next action")
    
    # Dependencies
    llm: LLMModel = Field(default_factory=LLMModel, description="Language model instance")
    memory: BaseMemory = Field(default_factory=BaseMemory, description="Agent's memory store")
    state: AgentState = Field(default="idle", description="Current agent state")
    
    # Execution control
    max_steps: int = Field(default=15, description="Maximum steps before termination")
    current_step: int = Field(default=0, description="Current step in execution")
    
    class Config:
        arbitrary_types_allowed = True
        extra = "allow"  # Allow extra fields for flexibility in subclasses
    
    @abstractmethod
    async def step(self) -> bool:
        """
        Execute a single step of the agent's reasoning process.
        Returns True if execution should continue, False if complete.
        Must be implemented by subclasses.
        """
        pass
    
    async def run(self, request: Optional[str] = None) -> str:
        """
        Execute the agent with the given request.
        Handles initialization, step execution, and result formatting.
        """
        # Initialize execution
        self.current_step = 0
        self.state = "running"
        
        # Add request to memory if provided
        if request:
            self.memory.add_user_message(request)
        
        # Execute steps until completion or max steps reached
        result = ""
        while self.current_step < self.max_steps and self.state == "running":
            self.current_step += 1
            continue_execution = await self.step()
            
            if not continue_execution:
                self.state = "finished"
                break
        
        # Format and return result
        result = self.memory.get_assistant_response()
        return result
```

### ToolAgent Implementation

```python
# anus/core/agent/tool_agent.py

from typing import Dict, List, Optional
from pydantic import Field

from anus.core.agent.base_agent import BaseAgent
from anus.core.schema import Message, ToolCall
from anus.tools.base.tool_collection import ToolCollection

class ToolAgent(BaseAgent):
    """
    Agent with tool execution capabilities.
    Can use various tools to accomplish tasks through function calling.
    """
    # Tool-related attributes
    available_tools: ToolCollection = Field(default_factory=ToolCollection)
    tool_choice: str = Field(default="auto", description="Tool choice strategy: 'none', 'auto', or 'required'")
    tool_calls: List[ToolCall] = Field(default_factory=list)
    
    async def step(self) -> bool:
        """
        Execute a single step of the agent's reasoning process.
        Includes thinking (deciding what to do) and acting (executing tools).
        """
        # Think: Decide what to do next
        thinking_complete = await self.think()
        if not thinking_complete:
            return False
        
        # Act: Execute decided actions
        action_result = await self.act()
        
        # Check if execution should continue
        if self.state != "running":
            return False
            
        return True
    
    async def think(self) -> bool:
        """Process current state and decide next actions using tools"""
        # Add next step prompt if available
        if self.next_step_prompt:
            self.memory.add_user_message(self.next_step_prompt)
        
        # Get response with tool options
        response = await self.llm.ask_with_tools(
            messages=self.memory.get_messages(),
            system_message=self.system_prompt,
            tools=self.available_tools.to_params(),
            tool_choice=self.tool_choice,
        )
        
        # Store tool calls for execution
        self.tool_calls = response.tool_calls
        
        # Check if thinking produced any tool calls
        if not self.tool_calls and self.tool_choice == "required":
            self.memory.add_assistant_message("Failed to determine next action.")
            return False
            
        return True
    
    async def act(self) -> str:
        """Execute tool calls determined during thinking phase"""
        if not self.tool_calls:
            return ""
            
        results = []
        for tool_call in self.tool_calls:
            result = await self.execute_tool(tool_call)
            results.append(result)
            
        # Add tool results to memory
        combined_result = "\n".join(results)
        self.memory.add_system_message(f"Tool execution results:\n{combined_result}")
        
        return combined_result
    
    async def execute_tool(self, tool_call: ToolCall) -> str:
        """Execute a specific tool call"""
        tool_name = tool_call.function.name
        tool_args = tool_call.function.arguments
        
        # Check for special tools (like termination)
        if tool_name in self.special_tool_names:
            return await self._handle_special_tool(tool_name, tool_args)
        
        # Execute the tool via ToolCollection
        try:
            result = await self.available_tools.execute(name=tool_name, tool_input=tool_args)
            return f"Tool '{tool_name}' executed successfully: {result}"
        except Exception as e:
            error_msg = f"Error executing tool '{tool_name}': {str(e)}"
            return error_msg
```

### HybridAgent Implementation

```python
# anus/core/agent/hybrid_agent.py

from typing import Dict, List, Optional
from pydantic import Field

from anus.core.agent.tool_agent import ToolAgent
from anus.core.flow.consensus_flow import ConsensusFlow

class HybridAgent(ToolAgent):
    """
    Agent that can dynamically switch between single-agent and multi-agent modes
    based on task complexity and requirements.
    """
    # Multi-agent related attributes
    sub_agents: Dict[str, ToolAgent] = Field(default_factory=dict)
    collaboration_threshold: float = Field(default=0.7, description="Complexity threshold for switching modes")
    
    async def run(self, request: Optional[str] = None) -> str:
        """Execute the agent with dynamic mode selection"""
        if not request:
            return "No request provided"
            
        # Analyze task complexity
        complexity = await self._analyze_complexity(request)
        
        # Choose execution mode based on complexity
        if complexity > self.collaboration_threshold:
            return await self._run_collaborative(request)
        else:
            return await super().run(request)
    
    async def _analyze_complexity(self, request: str) -> float:
        """
        Analyze task complexity to determine execution mode.
        Returns a value between 0 and 1 representing task complexity.
        """
        # Use LLM to assess task complexity
        system_prompt = """
        You are a task complexity analyzer. Your job is to assess the complexity of a given task
        and return a score between 0 and 1, where:
        - 0-0.3: Simple tasks requiring minimal reasoning or tool use
        - 0.3-0.7: Moderate tasks requiring some reasoning and tool use
        - 0.7-1.0: Complex tasks requiring extensive reasoning, multiple tools, or specialized knowledge
        
        Analyze only the complexity, not the clarity or specificity of the request.
        Return only a numeric score between 0 and 1, with no explanation.
        """
        
        response = await self.llm.ask(
            messages=[{"role": "user", "content": request}],
            system_message=system_prompt,
            temperature=0.1,  # Low temperature for consistent assessment
        )
        
        # Extract numeric score from response
        try:
            score = float(response.content.strip())
            # Ensure score is within valid range
            return max(0.0, min(1.0, score))
        except ValueError:
            # Default to single-agent mode if parsing fails
            return 0.5
    
    async def _run_collaborative(self, request: str) -> str:
        """Execute request in collaborative multi-agent mode"""
        # Ensure sub-agents exist
        await self._ensure_sub_agents()
        
        # Create consensus flow with sub-agents
        flow = ConsensusFlow(agents=self.sub_agents)
        
        # Execute flow with request
        return await flow.execute(request)
    
    async def _ensure_sub_agents(self) -> None:
        """Create specialized sub-agents if they don't exist"""
        # Define standard roles if not already created
        standard_roles = {
            "researcher": "Specializes in information gathering and research",
            "coder": "Specializes in code writing and software development",
            "planner": "Specializes in task planning and organization",
            "critic": "Specializes in reviewing and improving solutions"
        }
        
        # Create missing sub-agents
        for role, description in standard_roles.items():
            if role not in self.sub_agents:
                # Create specialized agent with role-specific system prompt
                self.sub_agents[role] = await self._create_specialized_agent(role, description)
    
    async def _create_specialized_agent(self, role: str, description: str) -> ToolAgent:
        """Create a specialized agent for a specific role"""
        # Generate role-specific system prompt
        system_prompt = await self._generate_role_prompt(role, description)
        
        # Create agent with same tools but specialized prompt
        agent = ToolAgent(
            name=f"{self.name}_{role}",
            description=description,
            system_prompt=system_prompt,
            available_tools=self.available_tools,
            llm=self.llm,  # Use same LLM instance
        )
        
        return agent
    
    async def _generate_role_prompt(self, role: str, description: str) -> str:
        """Generate a specialized system prompt for a specific role"""
        base_prompt = f"""You are a specialized {role} agent. {description}.
        
        Focus on your specialized role while collaborating with other agents to solve complex tasks.
        Use the available tools effectively to accomplish your part of the task.
        """
        
        return base_prompt
```

## Planning System

### PlanningTool Implementation

```python
# anus/tools/planning/planning_tool.py

from typing import Dict, List, Optional
import time
import json
from pydantic import Field

from anus.tools.base.tool import BaseTool
from anus.tools.base.tool_result import ToolResult

class PlanningTool(BaseTool):
    """
    A planning tool that allows the agent to create and manage plans for solving complex tasks.
    The tool provides functionality for creating plans, updating plan steps, and tracking progress.
    """
    name: str = "planning"
    description: str = """
    Create and manage plans for solving complex tasks. Supports:
    - Creating new plans with steps
    - Updating existing plans
    - Marking steps as completed
    - Listing available plans
    - Getting plan details
    """
    
    # Storage for plans
    plans: Dict[str, Dict] = Field(default_factory=dict)
    active_plan_id: Optional[str] = None
    
    parameters: Dict = {
        "type": "object",
        "properties": {
            "command": {
                "type": "string",
                "enum": ["create", "update", "mark_step", "list", "get", "set_active", "delete"],
                "description": "The planning command to execute"
            },
            "plan_id": {
                "type": "string",
                "description": "Identifier for the plan (auto-generated if not provided)"
            },
            "title": {
                "type": "string",
                "description": "Title of the plan (for create/update)"
            },
            "steps": {
                "type": "array",
                "items": {"type": "string"},
                "description": "List of steps in the plan (for create/update)"
            },
            "step_index": {
                "type": "integer",
                "description": "Index of the step to update (for mark_step)"
            },
            "step_status": {
                "type": "string",
                "enum": ["not_started", "in_progress", "completed", "skipped"],
                "description": "Status to set for the step (for mark_step)"
            }
        },
        "required": ["command"]
    }
    
    async def execute(self, **kwargs) -> ToolResult:
        """Execute the planning tool with the given parameters"""
        command = kwargs.get("command")
        
        if command == "create":
            return self._create_plan(**kwargs)
        elif command == "update":
            return self._update_plan(**kwargs)
        elif command == "mark_step":
            return self._mark_step(**kwargs)
        elif command == "list":
            return self._list_plans()
        elif command == "get":
            return self._get_plan(kwargs.get("plan_id"))
        elif command == "set_active":
            return self._set_active_plan(kwargs.get("plan_id"))
        elif command == "delete":
            return self._delete_plan(kwargs.get("plan_id"))
        else:
            return ToolResult(
                success=False,
                message=f"Unknown planning command: {command}"
            )
    
    def _create_plan(self, **kwargs) -> ToolResult:
        """Create a new plan with the given parameters"""
        plan_id = kwargs.get("plan_id") or f"plan_{int(time.time())}"
        title = kwargs.get("title") or f"Plan {len(self.plans) + 1}"
        steps = kwargs.get("steps") or []
        
        # Create plan structure
        plan = {
            "id": plan_id,
            "title": title,
            "steps": steps,
            "step_statuses": ["not_started"] * len(steps),
            "created_at": time.time(),
            "updated_at": time.time()
        }
        
        # Store the plan
        self.plans[plan_id] = plan
        
        # Set as active plan if no active plan exists
        if not self.active_plan_id:
            self.active_plan_id = plan_id
        
        return ToolResult(
            success=True,
            message=f"Created plan '{title}' with ID {plan_id}",
            data={"plan_id": plan_id}
        )
```

### PlanningFlow Implementation

```python
# anus/core/flow/planning_flow.py

from typing import Dict, List, Optional, Tuple, Union
import time
from pydantic import Field

from anus.core.agent.base_agent import BaseAgent
from anus.core.flow.base_flow import BaseFlow
from anus.models.base_model import BaseModel as LLMModel
from anus.tools.planning.planning_tool import PlanningTool

class PlanningFlow(BaseFlow):
    """
    A flow that manages planning and execution of tasks using agents.
    Breaks down complex tasks into steps and executes them sequentially.
    """
    # Flow components
    llm: LLMModel = Field(default_factory=LLMModel)
    planning_tool: PlanningTool = Field(default_factory=PlanningTool)
    executor_keys: List[str] = Field(default_factory=list)
    
    # Plan tracking
    active_plan_id: str = Field(default_factory=lambda: f"plan_{int(time.time())}")
    current_step_index: Optional[int] = None
    
    async def execute(self, input_text: str) -> str:
        """Execute the planning flow with agents"""
        try:
            # Create initial plan if input provided
            if input_text:
                await self._create_initial_plan(input_text)
                
                # Verify plan was created successfully
                if self.active_plan_id not in self.planning_tool.plans:
                    return f"Failed to create plan for: {input_text}"
            
            result = ""
            while True:
                # Get current step to execute
                self.current_step_index, step_info = await self._get_current_step_info()
                
                # Exit if no more steps or plan completed
                if self.current_step_index is None:
                    result += await self._finalize_plan()
                    break
                
                # Execute current step with appropriate agent
                step_type = step_info.get("type") if step_info else None
                executor = self.get_executor(step_type)
                step_result = await self._execute_step(executor, step_info)
                result += step_result + "\n"
                
                # Check if agent wants to terminate
                if executor.state == "finished":
                    break
            
            return result
        except Exception as e:
            return f"Execution failed: {str(e)}"
    
    def get_executor(self, step_type: Optional[str] = None) -> BaseAgent:
        """
        Get an appropriate executor agent for the current step.
        Can be extended to select agents based on step type/requirements.
        """
        # If step type is provided and matches an agent key, use that agent
        if step_type and step_type in self.agents:
            return self.agents[step_type]
        
        # Otherwise use the first available executor or fall back to primary agent
        for key in self.executor_keys:
            if key in self.agents:
                return self.agents[key]
        
        # Fallback to primary agent
        return self.primary_agent
```

## Tool System

### BaseTool Implementation

```python
# anus/tools/base/tool.py

from abc import ABC, abstractmethod
from typing import Any, Dict, Optional
from pydantic import BaseModel, Field

class BaseTool(ABC, BaseModel):
    """
    Abstract base class for all tools in the ANUS framework.
    Provides foundation for tool definition, parameter specification, and execution.
    """
    name: str
    description: str
    parameters: Optional[Dict] = None
    
    class Config:
        arbitrary_types_allowed = True
    
    async def __call__(self, **kwargs) -> Any:
        """Execute the tool with given parameters."""
        return await self.execute(**kwargs)
    
    @abstractmethod
    async def execute(self, **kwargs) -> Any:
        """
        Execute the tool with given parameters.
        Must be implemented by subclasses.
        """
        pass
    
    def to_param(self) -> Dict:
        """Convert tool to function call format for LLM."""
        return {
            "type": "function",
            "function": {
                "name": self.name,
                "description": self.description,
                "parameters": self.parameters or {
                    "type": "object",
                    "properties": {},
                }
            }
        }
```

### ToolCollection Implementation

```python
# anus/tools/base/tool_collection.py

from typing import Any, Dict, List, Optional
from anus.tools.base.tool import BaseTool
from anus.tools.base.tool_result import ToolResult, ToolFailure

class ToolCollection:
    """
    A collection of tools that can be used by agents.
    Provides unified interface for tool registration, discovery, and execution.
    """
    def __init__(self, *tools: BaseTool):
        self.tools = list(tools)
        self.tool_map = {tool.name: tool for tool in tools}
    
    def __iter__(self):
        return iter(self.tools)
    
    def add_tool(self, tool: BaseTool) -> None:
        """Add a tool to the collection"""
        self.tools.append(tool)
        self.tool_map[tool.name] = tool
    
    def remove_tool(self, tool_name: str) -> None:
        """Remove a tool from the collection"""
        if tool_name in self.tool_map:
            tool = self.tool_map.pop(tool_name)
            self.tools.remove(tool)
    
    def get_tool(self, tool_name: str) -> Optional[BaseTool]:
        """Get a tool by name"""
        return self.tool_map.get(tool_name)
    
    def to_params(self) -> List[Dict[str, Any]]:
        """Convert all tools to function call format for LLM"""
        return [tool.to_param() for tool in self.tools]
    
    async def execute(self, *, name: str, tool_input: Dict[str, Any] = None) -> ToolResult:
        """Execute a tool by name with the given input"""
        tool = self.tool_map.get(name)
        if not tool:
            return ToolFailure(error=f"Tool {name} not found")
        
        try:
            tool_input = tool_input or {}
            result = await tool(**tool_input)
            return result
        except Exception as e:
            return ToolFailure(error=f"Error executing tool {name}: {str(e)}")
```

### BrowserTool Implementation

```python
# anus/tools/web/browser_tool.py

from typing import Dict, Optional
import asyncio
from pydantic import Field

from anus.tools.base.tool import BaseTool
from anus.tools.base.tool_result import ToolResult, ToolFailure

class BrowserTool(BaseTool):
    """
    Tool for browser automation and web interaction.
    Provides capabilities for navigation, content extraction, and element interaction.
    """
    name: str = "browser"
    description: str = """
    Interact with a web browser to perform various actions such as navigation, 
    element interaction, content extraction, and tab management.
    """
    
    # Browser configuration
    headless: bool = Field(default=True, description="Whether to run browser in headless mode")
    browser_instance = None
    
    parameters: Dict = {
        "type": "object",
        "properties": {
            "action": {
                "type": "string",
                "enum": [
                    "navigate", "click", "input_text", "screenshot", 
                    "get_html", "get_text", "read_links", "execute_js",
                    "scroll", "switch_tab", "new_tab", "close_tab", "refresh"
                ],
                "description": "The browser action to perform"
            },
            "url": {
                "type": "string",
                "description": "URL to navigate to (for navigate action)"
            },
            "element_index": {
                "type": "integer",
                "description": "Index of the element to interact with (for click/input actions)"
            },
            "text": {
                "type": "string",
                "description": "Text to input (for input_text action)"
            },
            "js_code": {
                "type": "string",
                "description": "JavaScript code to execute (for execute_js action)"
            },
            "direction": {
                "type": "string",
                "enum": ["up", "down", "left", "right"],
                "description": "Scroll direction (for scroll action)"
            },
            "tab_index": {
                "type": "integer",
                "description": "Tab index to switch to (for switch_tab action)"
            }
        },
        "required": ["action"]
    }
    
    async def execute(self, **kwargs) -> ToolResult:
        """Execute the browser tool with the given parameters"""
        action = kwargs.get("action")
        
        # Initialize browser if not already initialized
        if not self.browser_instance:
            await self._initialize_browser()
        
        try:
            if action == "navigate":
                return await self._navigate(kwargs.get("url"))
            elif action == "click":
                return await self._click(kwargs.get("element_index"))
            elif action == "input_text":
                return await self._input_text(kwargs.get("element_index"), kwargs.get("text"))
            elif action == "screenshot":
                return await self._screenshot()
            elif action == "get_html":
                return await self._get_html()
            elif action == "get_text":
                return await self._get_text()
            elif action == "read_links":
                return await self._read_links()
            elif action == "execute_js":
                return await self._execute_js(kwargs.get("js_code"))
            elif action == "scroll":
                return await self._scroll(kwargs.get("direction"))
            elif action == "switch_tab":
                return await self._switch_tab(kwargs.get("tab_index"))
            elif action == "new_tab":
                return await self._new_tab()
            elif action == "close_tab":
                return await self._close_tab()
            elif action == "refresh":
                return await self._refresh()
            else:
                return ToolFailure(error=f"Unknown browser action: {action}")
        except Exception as e:
            return ToolFailure(error=f"Browser action failed: {str(e)}")
    
    async def _initialize_browser(self) -> None:
        """Initialize the browser instance"""
        # Implementation would use a browser automation library like Playwright
        # This is a placeholder for the actual implementation
        self.browser_instance = {"initialized": True}
```

## Model Integration

### BaseModel Implementation

```python
# anus/models/base_model.py

from abc import ABC, abstractmethod
from typing import Dict, List, Optional, Union
from pydantic import BaseModel as PydanticBaseModel, Field

class Message(PydanticBaseModel):
    """Represents a message in a conversation"""
    role: str
    content: str

class ToolCall(PydanticBaseModel):
    """Represents a tool call from the model"""
    id: str
    type: str = "function"
    function: Dict

class ModelResponse(PydanticBaseModel):
    """Represents a response from a language model"""
    content: Optional[str] = None
    tool_calls: Optional[List[ToolCall]] = None

class BaseModel(PydanticBaseModel, ABC):
    """
    Abstract base class for language model integrations.
    Provides unified interface for different model providers.
    """
    provider: str = "openai"  # Default provider
    model_name: str = "gpt-4o"  # Default model
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: float = 0.0
    max_tokens: int = 4096
    
    @abstractmethod
    async def ask(
        self, 
        messages: List[Union[Dict, Message]], 
        system_message: Optional[str] = None,
        **kwargs
    ) -> ModelResponse:
        """
        Send a request to the language model and get a response.
        Basic version without tool calling.
        """
        pass
    
    @abstractmethod
    async def ask_with_tools(
        self,
        messages: List[Union[Dict, Message]],
        system_message: Optional[str] = None,
        tools: Optional[List[Dict]] = None,
        tool_choice: str = "auto",
        **kwargs
    ) -> ModelResponse:
        """
        Send a request to the language model with tools and get a response.
        Supports function/tool calling.
        """
        pass
```

### OpenAIModel Implementation

```python
# anus/models/openai_model.py

from typing import Dict, List, Optional, Union
import json
import os
from pydantic import Field

from anus.models.base_model import BaseModel, Message, ModelResponse, ToolCall

class OpenAIModel(BaseModel):
    """
    OpenAI API integration for language models.
    Supports GPT-4 and other OpenAI models.
    """
    provider: str = "openai"
    model_name: str = "gpt-4o"
    api_key: Optional[str] = Field(default_factory=lambda: os.environ.get("OPENAI_API_KEY"))
    base_url: Optional[str] = Field(default="https://api.openai.com/v1")
    
    async def ask(
        self, 
        messages: List[Union[Dict, Message]], 
        system_message: Optional[str] = None,
        **kwargs
    ) -> ModelResponse:
        """Send a request to OpenAI API and get a response"""
        import openai
        
        # Set up client
        client = openai.AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # Prepare messages
        formatted_messages = self._format_messages(messages, system_message)
        
        # Set parameters
        params = {
            "model": self.model_name,
            "messages": formatted_messages,
            "temperature": kwargs.get("temperature", self.temperature),
            "max_tokens": kwargs.get("max_tokens", self.max_tokens),
        }
        
        # Send request
        response = await client.chat.completions.create(**params)
        
        # Process response
        content = response.choices[0].message.content
        
        return ModelResponse(content=content)
    
    async def ask_with_tools(
        self,
        messages: List[Union[Dict, Message]],
        system_message: Optional[str] = None,
        tools: Optional[List[Dict]] = None,
        tool_choice: str = "auto",
        **kwargs
    ) -> ModelResponse:
        """Send a request to OpenAI API with tools and get a response"""
        import openai
        
        # Set up client
        client = openai.AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url
        )
        
        # Prepare messages
        formatted_messages = self._format_messages(messages, system_message)
        
        # Set parameters
        params = {
            "model": self.model_name,
            "messages": formatted_messages,
            "temperature": kwargs.get("temperature", self.temperature),
            "max_tokens": kwargs.get("max_tokens", self.max_tokens),
        }
        
        # Add tools if provided
        if tools:
            params["tools"] = tools
            
            # Set tool_choice based on parameter
            if tool_choice == "required":
                params["tool_choice"] = {"type": "function", "function": {"name": tools[0]["function"]["name"]}}
            elif tool_choice == "none":
                params["tool_choice"] = "none"
            else:  # "auto"
                params["tool_choice"] = "auto"
        
        # Send request
        response = await client.chat.completions.create(**params)
        
        # Process response
        message = response.choices[0].message
        content = message.content
        
        # Process tool calls if present
        tool_calls = []
        if hasattr(message, "tool_calls") and message.tool_calls:
            for tc in message.tool_calls:
                tool_calls.append(
                    ToolCall(
                        id=tc.id,
                        type="function",
                        function={
                            "name": tc.function.name,
                            "arguments": tc.function.arguments
                        }
                    )
                )
        
        return ModelResponse(content=content, tool_calls=tool_calls)
    
    def _format_messages(
        self,
        messages: List[Union[Dict, Message]],
        system_message: Optional[str] = None
    ) -> List[Dict]:
        """Format messages for OpenAI API"""
        formatted_messages = []
        
        # Add system message if provided
        if system_message:
            formatted_messages.append({"role": "system", "content": system_message})
        
        # Add other messages
        for msg in messages:
            if isinstance(msg, dict):
                formatted_messages.append(msg)
            else:
                formatted_messages.append({"role": msg.role, "content": msg.content})
        
        return formatted_messages
```

## Memory System

### BaseMemory Implementation

```python
# anus/core/memory/base_memory.py

from typing import Dict, List, Optional
from pydantic import BaseModel, Field

class Message(BaseModel):
    """Represents a message in the agent's memory"""
    role: str
    content: str

class BaseMemory(BaseModel):
    """
    Base class for agent memory systems.
    Provides storage and retrieval of conversation history.
    """
    messages: List[Message] = Field(default_factory=list)
    max_messages: int = 100
    
    def add_message(self, role: str, content: str) -> None:
        """Add a message to memory"""
        self.messages.append(Message(role=role, content=content))
        
        # Trim if exceeding max messages
        if len(self.messages) > self.max_messages:
            self.messages = self.messages[-self.max_messages:]
    
    def add_user_message(self, content: str) -> None:
        """Add a user message to memory"""
        self.add_message("user", content)
    
    def add_assistant_message(self, content: str) -> None:
        """Add an assistant message to memory"""
        self.add_message("assistant", content)
    
    def add_system_message(self, content: str) -> None:
        """Add a system message to memory"""
        self.add_message("system", content)
    
    def get_messages(self) -> List[Message]:
        """Get all messages in memory"""
        return self.messages
    
    def get_last_message(self) -> Optional[Message]:
        """Get the last message in memory"""
        if not self.messages:
            return None
        return self.messages[-1]
    
    def get_assistant_response(self) -> str:
        """Get the last assistant response"""
        for msg in reversed(self.messages):
            if msg.role == "assistant":
                return msg.content
        return ""
    
    def clear(self) -> None:
        """Clear all messages from memory"""
        self.messages = []
```

### HybridMemory Implementation

```python
# anus/core/memory/hybrid_memory.py

from typing import Dict, List, Optional
import json
import os
from pydantic import Field

from anus.core.memory.base_memory import BaseMemory, Message

class HybridMemory(BaseMemory):
    """
    Hybrid memory system with both short-term and long-term storage.
    Provides persistent storage for conversations and context.
    """
    persistence: bool = Field(default=False, description="Whether to persist memory to disk")
    storage_path: Optional[str] = Field(default=None, description="Path to store persistent memory")
    
    # Long-term memory storage
    long_term_memories: Dict[str, List[Dict]] = Field(default_factory=dict)
    
    def __init__(self, **data):
        super().__init__(**data)
        
        # Set default storage path if not provided
        if self.persistence and not self.storage_path:
            self.storage_path = os.path.expanduser("~/.anus/memory")
        
        # Load persistent memory if enabled
        if self.persistence:
            self._load_persistent_memory()
    
    def add_message(self, role: str, content: str) -> None:
        """Add a message to memory and persist if enabled"""
        super().add_message(role, content)
        
        # Persist memory if enabled
        if self.persistence:
            self._save_persistent_memory()
    
    def add_to_long_term(self, category: str, data: Dict) -> None:
        """Add data to long-term memory"""
        if category not in self.long_term_memories:
            self.long_term_memories[category] = []
        
        self.long_term_memories[category].append(data)
        
        # Persist memory if enabled
        if self.persistence:
            self._save_persistent_memory()
    
    def get_from_long_term(self, category: str) -> List[Dict]:
        """Get data from long-term memory by category"""
        return self.long_term_memories.get(category, [])
    
    def search_long_term(self, category: str, query: str) -> List[Dict]:
        """Search long-term memory for relevant information"""
        # Simple keyword search implementation
        # Could be enhanced with vector search or other techniques
        results = []
        for item in self.get_from_long_term(category):
            item_str = json.dumps(item).lower()
            if query.lower() in item_str:
                results.append(item)
        return results
    
    def _load_persistent_memory(self) -> None:
        """Load memory from persistent storage"""
        try:
            # Ensure directory exists
            os.makedirs(self.storage_path, exist_ok=True)
            
            # Load short-term memory
            st_path = os.path.join(self.storage_path, "short_term.json")
            if os.path.exists(st_path):
                with open(st_path, "r") as f:
                    data = json.load(f)
                    self.messages = [Message(**msg) for msg in data]
            
            # Load long-term memory
            lt_path = os.path.join(self.storage_path, "long_term.json")
            if os.path.exists(lt_path):
                with open(lt_path, "r") as f:
                    self.long_term_memories = json.load(f)
        except Exception as e:
            print(f"Error loading persistent memory: {e}")
    
    def _save_persistent_memory(self) -> None:
        """Save memory to persistent storage"""
        try:
            # Ensure directory exists
            os.makedirs(self.storage_path, exist_ok=True)
            
            # Save short-term memory
            st_path = os.path.join(self.storage_path, "short_term.json")
            with open(st_path, "w") as f:
                json.dump([msg.dict() for msg in self.messages], f)
            
            # Save long-term memory
            lt_path = os.path.join(self.storage_path, "long_term.json")
            with open(lt_path, "w") as f:
                json.dump(self.long_term_memories, f)
        except Exception as e:
            print(f"Error saving persistent memory: {e}")
```

## Integration Strategy

### Main Entry Point

```python
# anus/main.py

import argparse
import asyncio
import os
import sys
from typing import Dict, Optional

from anus.core.agent.hybrid_agent import HybridAgent
from anus.core.config import AgentConfig
from anus.ui.cli import CLI

async def main():
    """Main entry point for the ANUS framework"""
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="ANUS - Autonomous Networked Utility System")
    parser.add_argument("--config", type=str, default="config.yaml", help="Path to configuration file")
    parser.add_argument("--mode", type=str, default="single", choices=["single", "multi"], help="Agent mode")
    parser.add_argument("--task", type=str, help="Task description")
    parser.add_argument("--verbose", action="store_true", help="Enable verbose output")
    
    args = parser.parse_args()
    
    # Initialize CLI
    cli = CLI(verbose=args.verbose)
    cli.display_welcome()
    
    # Load configuration
    config = load_config(args.config)
    
    # Override config with command line arguments
    if args.mode:
        config.mode = args.mode
    
    # Initialize agent
    agent = create_agent(config)
    
    # Execute task if provided
    if args.task:
        result = await agent.run(args.task)
        cli.display_result(result)
        return
    
    # Start interactive mode
    await cli.start_interactive_mode(agent)

def load_config(config_path: str) -> AgentConfig:
    """Load configuration from file"""
    # Implementation would load YAML/JSON config
    # This is a placeholder for the actual implementation
    return AgentConfig()

def create_agent(config: AgentConfig) -> HybridAgent:
    """Create agent based on configuration"""
    # Create agent with appropriate tools and configuration
    agent = HybridAgent(
        name=config.name,
        collaboration_threshold=0.7 if config.mode == "multi" else 1.0,  # Force single mode if specified
    )
    
    # Initialize tools based on configuration
    initialize_tools(agent, config)
    
    return agent

def initialize_tools(agent: HybridAgent, config: AgentConfig) -> None:
    """Initialize tools based on configuration"""
    # Implementation would create and add tools based on config
    # This is a placeholder for the actual implementation
    pass

if __name__ == "__main__":
    asyncio.run(main())
```

### Configuration System

```python
# anus/core/config.py

from typing import Dict, Optional
import os
import yaml
from pydantic import BaseModel, Field

class ModelConfig(BaseModel):
    """Configuration for language models"""
    provider: str = "openai"
    model_name: str = "gpt-4o"
    api_key: Optional[str] = Field(default_factory=lambda: os.environ.get("OPENAI_API_KEY"))
    base_url: Optional[str] = None
    temperature: float = 0.0
    max_tokens: int = 4096

class MemoryConfig(BaseModel):
    """Configuration for memory systems"""
    type: str = "hybrid"  # "short_term", "long_term", "hybrid"
    persistence: bool = False
    storage_path: Optional[str] = None

class ToolConfig(BaseModel):
    """Configuration for tools"""
    browser: Dict = Field(default_factory=lambda: {"headless": True})
    code: Dict = Field(default_factory=lambda: {"sandbox": True})
    # Other tool configurations

class AgentConfig(BaseModel):
    """Configuration for agents"""
    name: str = "anus"
    mode: str = "single"  # "single", "multi"
    model: ModelConfig = Field(default_factory=ModelConfig)
    memory: MemoryConfig = Field(default_factory=MemoryConfig)
    tools: ToolConfig = Field(default_factory=ToolConfig)
    max_steps: int = 30

def load_config(config_path: str) -> AgentConfig:
    """Load configuration from YAML file"""
    try:
        with open(config_path, "r") as f:
            config_data = yaml.safe_load(f)
        
        return AgentConfig.parse_obj(config_data)
    except Exception as e:
        print(f"Error loading configuration: {e}")
        return AgentConfig()

def save_config(config: AgentConfig, config_path: str) -> bool:
    """Save configuration to YAML file"""
    try:
        with open(config_path, "w") as f:
            yaml.dump(config.dict(), f)
        return True
    except Exception as e:
        print(f"Error saving configuration: {e}")
        return False
```

## Implementation Roadmap

### Phase 1: Core Framework (Week 1-2)

1. **Setup Project Structure**
   - Create directory structure
   - Set up package configuration
   - Configure development environment

2. **Implement Base Classes**
   - BaseAgent
   - BaseTool and ToolCollection
   - BaseMemory
   - BaseModel

3. **Implement Core Agent Types**
   - ToolAgent
   - Basic HybridAgent

4. **Implement Model Integration**
   - OpenAIModel
   - Model router

5. **Implement Configuration System**
   - Configuration classes
   - YAML loading/saving

### Phase 2: Tool Ecosystem (Week 3-4)

1. **Implement Basic Tools**
   - PlanningTool
   - Basic web tools
   - File operation tools
   - Information retrieval tools

2. **Implement Browser Automation**
   - BrowserTool
   - Navigation and interaction
   - Content extraction

3. **Implement Code Execution**
   - Python execution sandbox
   - Code analysis tools

4. **Implement Document Processing**
   - PDF parsing
   - Text extraction

### Phase 3: Advanced Features (Week 5-6)

1. **Enhance HybridAgent**
   - Task complexity analysis
   - Dynamic mode switching

2. **Implement Multi-Agent Collaboration**
   - Specialized agent roles
   - ConsensusFlow
   - Voting mechanisms

3. **Enhance Memory System**
   - HybridMemory
   - Persistence
   - Search capabilities

4. **Implement Resource Allocation**
   - ResourcePlanner
   - Optimization algorithms

### Phase 4: User Interfaces (Week 7-8)

1. **Enhance CLI**
   - Interactive mode
   - Progress visualization
   - History browsing

2. **Implement Web Interface**
   - Basic web server
   - Dashboard
   - Visualization components

3. **Implement API**
   - RESTful endpoints
   - Authentication
   - Documentation

4. **Final Integration and Testing**
   - End-to-end testing
   - Performance optimization
   - Documentation completion
````

## instructions/Implementation Roadmap.md

- Characters: 6352
- Tokens: 0

```markdown
# ANUS Implementation Roadmap

This roadmap outlines a structured approach to implementing the ANUS framework by adapting valuable concepts from OpenManus. The plan is organized into phases with specific deliverables and milestones to ensure steady progress.

## Phase 1: Foundation (Weeks 1-2)

### Week 1: Project Setup and Core Architecture
- **Days 1-2: Project Structure**
  - Set up repository structure following ANUS directory layout
  - Configure development environment and dependencies
  - Implement basic package structure and imports
  - Set up testing framework

- **Days 3-5: Core Agent System**
  - Implement `BaseAgent` abstract class
  - Implement `ToolAgent` with tool execution capabilities
  - Create basic `HybridAgent` foundation
  - Implement agent state management

### Week 2: Basic Tools and Model Integration
- **Days 1-3: Model Integration**
  - Implement `BaseModel` abstract class
  - Create `OpenAIModel` implementation
  - Implement model response handling
  - Add tool/function calling support

- **Days 4-5: Basic Tool System**
  - Implement `BaseTool` abstract class
  - Create `ToolCollection` for tool management
  - Implement `ToolResult` and error handling
  - Add basic utility tools (file operations, web search)

## Phase 2: Core Functionality (Weeks 3-4)

### Week 3: Planning System and Memory
- **Days 1-3: Planning System**
  - Implement `PlanningTool` for task breakdown
  - Create `BaseFlow` and `PlanningFlow` classes
  - Implement plan tracking and step execution
  - Add plan visualization

- **Days 4-5: Memory System**
  - Implement `BaseMemory` for conversation history
  - Create `HybridMemory` with short/long-term storage
  - Add persistence capabilities
  - Implement memory search functionality

### Week 4: Web Interaction and Configuration
- **Days 1-3: Browser Automation**
  - Implement `BrowserTool` for web interaction
  - Add navigation and content extraction
  - Implement element interaction (click, input)
  - Add screenshot and visual capabilities

- **Days 4-5: Configuration System**
  - Implement configuration classes
  - Add YAML/JSON loading and saving
  - Create environment variable integration
  - Implement configuration validation

## Phase 3: Advanced Features (Weeks 5-6)

### Week 5: Multi-Agent Collaboration
- **Days 1-2: Agent Specialization**
  - Enhance `HybridAgent` with role-based capabilities
  - Implement specialized agent creation
  - Add task complexity analysis
  - Create dynamic mode switching

- **Days 3-5: Consensus Mechanisms**
  - Implement `ConsensusFlow` for multi-agent execution
  - Add voting and agreement algorithms
  - Create conflict resolution strategies
  - Implement result aggregation

### Week 6: Resource Management and Document Processing
- **Days 1-3: Resource Allocation**
  - Implement `ResourcePlanner` for optimization
  - Add parallel execution capabilities
  - Create resource monitoring
  - Implement adaptive resource allocation

- **Days 4-5: Document Processing**
  - Add PDF parsing capabilities
  - Implement document structure analysis
  - Create text extraction and processing
  - Add document generation tools

## Phase 4: User Experience and Integration (Weeks 7-8)

### Week 7: User Interfaces
- **Days 1-3: Command Line Interface**
  - Enhance CLI with interactive features
  - Add progress visualization
  - Implement history browsing
  - Create configuration management interface

- **Days 4-5: Web Interface**
  - Implement basic web server
  - Create dashboard for monitoring
  - Add visualization components
  - Implement task management interface

### Week 8: API and Final Integration
- **Days 1-3: API Development**
  - Implement RESTful API endpoints
  - Add authentication and security
  - Create API documentation
  - Implement client libraries

- **Days 4-5: Final Integration and Testing**
  - Conduct end-to-end testing
  - Optimize performance
  - Complete documentation
  - Prepare for release

## Implementation Priorities

1. **Core Agent System**: The foundation of ANUS, enabling basic task execution
2. **Tool Integration**: Essential for agent capabilities and task execution
3. **Planning System**: Critical for breaking down complex tasks
4. **Memory System**: Important for context retention and learning
5. **Multi-Agent Collaboration**: Key differentiator for ANUS
6. **User Interfaces**: Necessary for usability and adoption

## Key Technical Challenges

1. **Hybrid Agent Implementation**: Balancing single-agent simplicity with multi-agent power
2. **Resource Optimization**: Efficiently allocating computational resources
3. **Tool Security**: Ensuring safe execution of tools, especially code execution
4. **Model Integration**: Supporting multiple model providers with consistent interface
5. **Memory Management**: Balancing context retention with performance

## Integration Strategy

The integration strategy focuses on adapting OpenManus concepts while maintaining ANUS's unique identity:

1. **Preserve Directory Structure**: Maintain ANUS's existing directory layout
2. **Adapt Core Classes**: Reinterpret OpenManus classes to fit ANUS architecture
3. **Enhance with New Features**: Add ANUS-specific features not present in OpenManus
4. **Maintain Consistent Style**: Ensure code style and patterns are consistent
5. **Progressive Enhancement**: Build core functionality first, then add advanced features

## Testing Strategy

1. **Unit Tests**: For individual components and classes
2. **Integration Tests**: For interactions between components
3. **End-to-End Tests**: For complete task execution flows
4. **Performance Tests**: For resource usage and optimization
5. **User Experience Tests**: For interface usability

## Documentation Plan

1. **API Reference**: Comprehensive documentation of all classes and methods
2. **Architecture Guide**: Overview of system design and components
3. **User Guide**: Instructions for using ANUS
4. **Developer Guide**: Information for contributors
5. **Examples**: Sample applications and use cases

## Success Metrics

1. **Functionality**: Successfully executing complex tasks
2. **Performance**: Efficient resource usage and response time
3. **Usability**: Intuitive interfaces and clear documentation
4. **Extensibility**: Ease of adding new tools and capabilities
5. **Community Adoption**: User engagement and contributions
```

## instructions/Planning Script.py

- Characters: 16240
- Tokens: 0

```python
import json
import time
from typing import Dict, List, Optional, Union

from pydantic import Field

from app.agent.base import BaseAgent
from app.flow.base import BaseFlow
from app.llm import LLM
from app.logger import logger
from app.schema import AgentState, Message
from app.tool import PlanningTool


class PlanningFlow(BaseFlow):
    """A flow that manages planning and execution of tasks using agents."""

    llm: LLM = Field(default_factory=lambda: LLM())
    planning_tool: PlanningTool = Field(default_factory=PlanningTool)
    executor_keys: List[str] = Field(default_factory=list)
    active_plan_id: str = Field(default_factory=lambda: f"plan_{int(time.time())}")
    current_step_index: Optional[int] = None

    def __init__(
        self, agents: Union[BaseAgent, List[BaseAgent], Dict[str, BaseAgent]], **data
    ):
        # Set executor keys before super().__init__
        if "executors" in data:
            data["executor_keys"] = data.pop("executors")

        # Set plan ID if provided
        if "plan_id" in data:
            data["active_plan_id"] = data.pop("plan_id")

        # Initialize the planning tool if not provided
        if "planning_tool" not in data:
            planning_tool = PlanningTool()
            data["planning_tool"] = planning_tool

        # Call parent's init with the processed data
        super().__init__(agents, **data)

        # Set executor_keys to all agent keys if not specified
        if not self.executor_keys:
            self.executor_keys = list(self.agents.keys())

    def get_executor(self, step_type: Optional[str] = None) -> BaseAgent:
        """
        Get an appropriate executor agent for the current step.
        Can be extended to select agents based on step type/requirements.
        """
        # If step type is provided and matches an agent key, use that agent
        if step_type and step_type in self.agents:
            return self.agents[step_type]

        # Otherwise use the first available executor or fall back to primary agent
        for key in self.executor_keys:
            if key in self.agents:
                return self.agents[key]

        # Fallback to primary agent
        return self.primary_agent

    async def execute(self, input_text: str) -> str:
        """Execute the planning flow with agents."""
        try:
            if not self.primary_agent:
                raise ValueError("No primary agent available")

            # Create initial plan if input provided
            if input_text:
                await self._create_initial_plan(input_text)

                # Verify plan was created successfully
                if self.active_plan_id not in self.planning_tool.plans:
                    logger.error(
                        f"Plan creation failed. Plan ID {self.active_plan_id} not found in planning tool."
                    )
                    return f"Failed to create plan for: {input_text}"

            result = ""
            while True:
                # Get current step to execute
                self.current_step_index, step_info = await self._get_current_step_info()

                # Exit if no more steps or plan completed
                if self.current_step_index is None:
                    result += await self._finalize_plan()
                    break

                # Execute current step with appropriate agent
                step_type = step_info.get("type") if step_info else None
                executor = self.get_executor(step_type)
                step_result = await self._execute_step(executor, step_info)
                result += step_result + "\n"

                # Check if agent wants to terminate
                if hasattr(executor, "state") and executor.state == AgentState.FINISHED:
                    break

            return result
        except Exception as e:
            logger.error(f"Error in PlanningFlow: {str(e)}")
            return f"Execution failed: {str(e)}"

    async def _create_initial_plan(self, request: str) -> None:
        """Create an initial plan based on the request using the flow's LLM and PlanningTool."""
        logger.info(f"Creating initial plan with ID: {self.active_plan_id}")

        # Create a system message for plan creation
        system_message = Message.system_message(
            "You are a planning assistant. Create a concise, actionable plan with clear steps. "
            "Focus on key milestones rather than detailed sub-steps. "
            "Optimize for clarity and efficiency."
        )

        # Create a user message with the request
        user_message = Message.user_message(
            f"Create a reasonable plan with clear steps to accomplish the task: {request}"
        )

        # Call LLM with PlanningTool
        response = await self.llm.ask_tool(
            messages=[user_message],
            system_msgs=[system_message],
            tools=[self.planning_tool.to_param()],
            tool_choice="required",
        )

        # Process tool calls if present
        if response.tool_calls:
            for tool_call in response.tool_calls:
                if tool_call.function.name == "planning":
                    # Parse the arguments
                    args = tool_call.function.arguments
                    if isinstance(args, str):
                        try:
                            args = json.loads(args)
                        except json.JSONDecodeError:
                            logger.error(f"Failed to parse tool arguments: {args}")
                            continue

                    # Ensure plan_id is set correctly and execute the tool
                    args["plan_id"] = self.active_plan_id

                    # Execute the tool via ToolCollection instead of directly
                    result = await self.planning_tool.execute(**args)

                    logger.info(f"Plan creation result: {str(result)}")
                    return

        # If execution reached here, create a default plan
        logger.warning("Creating default plan")

        # Create default plan using the ToolCollection
        await self.planning_tool.execute(
            **{
                "command": "create",
                "plan_id": self.active_plan_id,
                "title": f"Plan for: {request[:50]}{'...' if len(request) > 50 else ''}",
                "steps": ["Analyze request", "Execute task", "Verify results"],
            }
        )

    async def _get_current_step_info(self) -> tuple[Optional[int], Optional[dict]]:
        """
        Parse the current plan to identify the first non-completed step's index and info.
        Returns (None, None) if no active step is found.
        """
        if (
            not self.active_plan_id
            or self.active_plan_id not in self.planning_tool.plans
        ):
            logger.error(f"Plan with ID {self.active_plan_id} not found")
            return None, None

        try:
            # Direct access to plan data from planning tool storage
            plan_data = self.planning_tool.plans[self.active_plan_id]
            steps = plan_data.get("steps", [])
            step_statuses = plan_data.get("step_statuses", [])

            # Find first non-completed step
            for i, step in enumerate(steps):
                if i >= len(step_statuses):
                    status = "not_started"
                else:
                    status = step_statuses[i]

                if status in ["not_started", "in_progress"]:
                    # Extract step type/category if available
                    step_info = {"text": step}

                    # Try to extract step type from the text (e.g., [SEARCH] or [CODE])
                    import re

                    type_match = re.search(r"\[([A-Z_]+)\]", step)
                    if type_match:
                        step_info["type"] = type_match.group(1).lower()

                    # Mark current step as in_progress
                    try:
                        await self.planning_tool.execute(
                            command="mark_step",
                            plan_id=self.active_plan_id,
                            step_index=i,
                            step_status="in_progress",
                        )
                    except Exception as e:
                        logger.warning(f"Error marking step as in_progress: {e}")
                        # Update step status directly if needed
                        if i < len(step_statuses):
                            step_statuses[i] = "in_progress"
                        else:
                            while len(step_statuses) < i:
                                step_statuses.append("not_started")
                            step_statuses.append("in_progress")

                        plan_data["step_statuses"] = step_statuses

                    return i, step_info

            return None, None  # No active step found

        except Exception as e:
            logger.warning(f"Error finding current step index: {e}")
            return None, None

    async def _execute_step(self, executor: BaseAgent, step_info: dict) -> str:
        """Execute the current step with the specified agent using agent.run()."""
        # Prepare context for the agent with current plan status
        plan_status = await self._get_plan_text()
        step_text = step_info.get("text", f"Step {self.current_step_index}")

        # Create a prompt for the agent to execute the current step
        step_prompt = f"""
        CURRENT PLAN STATUS:
        {plan_status}

        YOUR CURRENT TASK:
        You are now working on step {self.current_step_index}: "{step_text}"

        Please execute this step using the appropriate tools. When you're done, provide a summary of what you accomplished.
        """

        # Use agent.run() to execute the step
        try:
            step_result = await executor.run(step_prompt)

            # Mark the step as completed after successful execution
            await self._mark_step_completed()

            return step_result
        except Exception as e:
            logger.error(f"Error executing step {self.current_step_index}: {e}")
            return f"Error executing step {self.current_step_index}: {str(e)}"

    async def _mark_step_completed(self) -> None:
        """Mark the current step as completed."""
        if self.current_step_index is None:
            return

        try:
            # Mark the step as completed
            await self.planning_tool.execute(
                command="mark_step",
                plan_id=self.active_plan_id,
                step_index=self.current_step_index,
                step_status="completed",
            )
            logger.info(
                f"Marked step {self.current_step_index} as completed in plan {self.active_plan_id}"
            )
        except Exception as e:
            logger.warning(f"Failed to update plan status: {e}")
            # Update step status directly in planning tool storage
            if self.active_plan_id in self.planning_tool.plans:
                plan_data = self.planning_tool.plans[self.active_plan_id]
                step_statuses = plan_data.get("step_statuses", [])

                # Ensure the step_statuses list is long enough
                while len(step_statuses) <= self.current_step_index:
                    step_statuses.append("not_started")

                # Update the status
                step_statuses[self.current_step_index] = "completed"
                plan_data["step_statuses"] = step_statuses

    async def _get_plan_text(self) -> str:
        """Get the current plan as formatted text."""
        try:
            result = await self.planning_tool.execute(
                command="get", plan_id=self.active_plan_id
            )
            return result.output if hasattr(result, "output") else str(result)
        except Exception as e:
            logger.error(f"Error getting plan: {e}")
            return self._generate_plan_text_from_storage()

    def _generate_plan_text_from_storage(self) -> str:
        """Generate plan text directly from storage if the planning tool fails."""
        try:
            if self.active_plan_id not in self.planning_tool.plans:
                return f"Error: Plan with ID {self.active_plan_id} not found"

            plan_data = self.planning_tool.plans[self.active_plan_id]
            title = plan_data.get("title", "Untitled Plan")
            steps = plan_data.get("steps", [])
            step_statuses = plan_data.get("step_statuses", [])
            step_notes = plan_data.get("step_notes", [])

            # Ensure step_statuses and step_notes match the number of steps
            while len(step_statuses) < len(steps):
                step_statuses.append("not_started")
            while len(step_notes) < len(steps):
                step_notes.append("")

            # Count steps by status
            status_counts = {
                "completed": 0,
                "in_progress": 0,
                "blocked": 0,
                "not_started": 0,
            }

            for status in step_statuses:
                if status in status_counts:
                    status_counts[status] += 1

            completed = status_counts["completed"]
            total = len(steps)
            progress = (completed / total) * 100 if total > 0 else 0

            plan_text = f"Plan: {title} (ID: {self.active_plan_id})\n"
            plan_text += "=" * len(plan_text) + "\n\n"

            plan_text += (
                f"Progress: {completed}/{total} steps completed ({progress:.1f}%)\n"
            )
            plan_text += f"Status: {status_counts['completed']} completed, {status_counts['in_progress']} in progress, "
            plan_text += f"{status_counts['blocked']} blocked, {status_counts['not_started']} not started\n\n"
            plan_text += "Steps:\n"

            for i, (step, status, notes) in enumerate(
                zip(steps, step_statuses, step_notes)
            ):
                if status == "completed":
                    status_mark = "[‚úì]"
                elif status == "in_progress":
                    status_mark = "[‚Üí]"
                elif status == "blocked":
                    status_mark = "[!]"
                else:  # not_started
                    status_mark = "[ ]"

                plan_text += f"{i}. {status_mark} {step}\n"
                if notes:
                    plan_text += f"   Notes: {notes}\n"

            return plan_text
        except Exception as e:
            logger.error(f"Error generating plan text from storage: {e}")
            return f"Error: Unable to retrieve plan with ID {self.active_plan_id}"

    async def _finalize_plan(self) -> str:
        """Finalize the plan and provide a summary using the flow's LLM directly."""
        plan_text = await self._get_plan_text()

        # Create a summary using the flow's LLM directly
        try:
            system_message = Message.system_message(
                "You are a planning assistant. Your task is to summarize the completed plan."
            )

            user_message = Message.user_message(
                f"The plan has been completed. Here is the final plan status:\n\n{plan_text}\n\nPlease provide a summary of what was accomplished and any final thoughts."
            )

            response = await self.llm.ask(
                messages=[user_message], system_msgs=[system_message]
            )

            return f"Plan completed:\n\n{response}"
        except Exception as e:
            logger.error(f"Error finalizing plan with LLM: {e}")

            # Fallback to using an agent for the summary
            try:
                agent = self.primary_agent
                summary_prompt = f"""
                The plan has been completed. Here is the final plan status:

                {plan_text}

                Please provide a summary of what wa<response clipped><NOTE>To save on context only part of this file has been shown to you. You should retry this tool after you have searched inside the file with `grep -n` in order to find the line numbers of what you are looking for.</NOTE>
```

## instructions/anus_architecture_design.md

- Characters: 14934
- Tokens: 0

````markdown
# ANUS Architecture Design Based on OpenManus Concepts

## Overview

This document outlines a proposed architecture for the ANUS (Autonomous Networked Utility System) framework, thoughtfully adapting valuable concepts from OpenManus while enhancing them to fulfill ANUS's unique vision. The design maintains ANUS's intended structure while incorporating OpenManus's proven architectural patterns.

## Core Architecture

### Agent System

```
anus/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ agent/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py       # Abstract foundation with core functionality
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ react_agent.py      # Reasoning capabilities extension
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool_agent.py       # Tool execution capabilities
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hybrid_agent.py     # New: Switching between single/multi modes
‚îÇ   ‚îú‚îÄ‚îÄ memory/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_memory.py      # Memory interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ short_term.py       # Short-term memory implementation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ long_term.py        # Long-term memory with persistence
‚îÇ   ‚îî‚îÄ‚îÄ orchestrator.py         # Agent coordination and management
```

#### Key Enhancements:
1. **HybridAgent**: Extends OpenManus's agent hierarchy with the ability to dynamically switch between single-agent and multi-agent modes based on task complexity
2. **Enhanced Memory System**: Expands OpenManus's basic memory with short-term and long-term memory components
3. **Orchestrator**: New component for coordinating multiple agents, not present in OpenManus

### Planning System

```
anus/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ planning/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ base_planner.py     # Abstract planner interface
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ task_planner.py     # Task breakdown and planning
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ resource_planner.py # Resource allocation planning
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ plan.py             # Plan representation and tracking
‚îÇ   ‚îî‚îÄ‚îÄ flow/
‚îÇ       ‚îú‚îÄ‚îÄ base_flow.py        # Abstract flow interface
‚îÇ       ‚îú‚îÄ‚îÄ planning_flow.py    # Planning-based execution flow
‚îÇ       ‚îú‚îÄ‚îÄ parallel_flow.py    # New: Parallel execution flow
‚îÇ       ‚îî‚îÄ‚îÄ consensus_flow.py   # New: Multi-agent consensus flow
```

#### Key Enhancements:
1. **Resource Planning**: Adds resource allocation capabilities to OpenManus's planning system
2. **Parallel Flow**: New flow type for executing steps in parallel when appropriate
3. **Consensus Flow**: New flow type for multi-agent collaboration with voting mechanisms

### Tool System

```
anus/
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ base/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool.py             # Abstract tool foundation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tool_result.py      # Standardized result handling
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tool_collection.py  # Tool management
‚îÇ   ‚îú‚îÄ‚îÄ web/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ browser.py          # Browser automation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scraper.py          # Web content extraction
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ auth.py             # Authentication handling
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ search.py           # Information retrieval
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ document.py         # Document processing
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ database.py         # Database interactions
‚îÇ   ‚îú‚îÄ‚îÄ code/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ executor.py         # Code execution sandbox
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analyzer.py         # Code analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ generator.py        # Code generation
‚îÇ   ‚îî‚îÄ‚îÄ multimodal/
‚îÇ       ‚îú‚îÄ‚îÄ image.py            # Image processing
‚îÇ       ‚îú‚îÄ‚îÄ audio.py            # Audio processing
‚îÇ       ‚îî‚îÄ‚îÄ video.py            # Video processing
```

#### Key Enhancements:
1. **Categorized Tools**: Organizes tools into logical categories beyond OpenManus's flat structure
2. **Expanded Capabilities**: Adds new tool types for document processing, code analysis, and multimodal content
3. **Authentication Handling**: Adds specialized support for web authentication scenarios

### Model Integration

```
anus/
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ base_model.py           # Abstract model interface
‚îÇ   ‚îú‚îÄ‚îÄ openai_model.py         # OpenAI API integration
‚îÇ   ‚îú‚îÄ‚îÄ open_source_model.py    # Open-source model support
‚îÇ   ‚îú‚îÄ‚îÄ local_model.py          # Local model deployment
‚îÇ   ‚îî‚îÄ‚îÄ model_router.py         # Dynamic model selection
```

#### Key Enhancements:
1. **Model Abstraction**: Extends OpenManus's LLM abstraction with support for multiple model types
2. **Model Router**: Adds dynamic model selection based on task requirements
3. **Local Deployment**: Adds support for running models locally for privacy and reduced costs

### User Interface

```
anus/
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îú‚îÄ‚îÄ cli.py                  # Command-line interface
‚îÇ   ‚îú‚îÄ‚îÄ web/                    # Web interface components
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ server.py           # Web server implementation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ static/             # Static assets
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ templates/          # HTML templates
‚îÇ   ‚îî‚îÄ‚îÄ api.py                  # RESTful API for integration
```

#### Key Enhancements:
1. **Multiple Interfaces**: Expands beyond OpenManus's CLI to include web and API interfaces
2. **Interactive Mode**: Adds support for interactive conversations and task monitoring
3. **API Integration**: Enables embedding ANUS in other applications

## Integration Points

### Configuration System

```python
# config.py
from pydantic import BaseModel, Field
from typing import Dict, List, Optional, Union

class ModelConfig(BaseModel):
    provider: str = "openai"
    model_name: str = "gpt-4o"
    api_key: Optional[str] = None
    base_url: Optional[str] = None
    temperature: float = 0.0
    max_tokens: int = 4096
    
class MemoryConfig(BaseModel):
    type: str = "hybrid"  # "short_term", "long_term", "hybrid"
    persistence: bool = False
    storage_path: Optional[str] = None
    
class ToolConfig(BaseModel):
    browser: Dict = Field(default_factory=lambda: {"headless": True})
    code: Dict = Field(default_factory=lambda: {"sandbox": True})
    # Other tool configurations
    
class AgentConfig(BaseModel):
    name: str = "anus"
    mode: str = "single"  # "single", "multi"
    model: ModelConfig = Field(default_factory=ModelConfig)
    memory: MemoryConfig = Field(default_factory=MemoryConfig)
    tools: ToolConfig = Field(default_factory=ToolConfig)
    max_steps: int = 30
```

### Agent Orchestration

```python
# orchestrator.py
from typing import Dict, List, Optional
from anus.core.agent.base_agent import BaseAgent
from anus.core.agent.hybrid_agent import HybridAgent
from anus.core.flow.base_flow import BaseFlow
from anus.core.flow.planning_flow import PlanningFlow
from anus.core.flow.consensus_flow import ConsensusFlow

class AgentOrchestrator:
    """Coordinates multiple agents and manages execution flows"""
    
    def __init__(self, config_path: str):
        self.config = self._load_config(config_path)
        self.agents: Dict[str, BaseAgent] = {}
        self.primary_agent = self._create_primary_agent()
        
    def execute_task(self, task: str, mode: str = "single") -> str:
        """Execute a task using appropriate agents and flow"""
        if mode == "single":
            return self._execute_single_agent(task)
        else:
            return self._execute_multi_agent(task)
            
    def _execute_single_agent(self, task: str) -> str:
        """Execute task with single agent using planning flow"""
        flow = PlanningFlow(agents={"primary": self.primary_agent})
        return flow.execute(task)
        
    def _execute_multi_agent(self, task: str) -> str:
        """Execute task with multiple specialized agents"""
        # Create specialized agents if needed
        self._ensure_specialized_agents()
        
        # Use consensus flow for multi-agent execution
        flow = ConsensusFlow(agents=self.agents)
        return flow.execute(task)
        
    def _ensure_specialized_agents(self) -> None:
        """Create specialized agents if they don't exist"""
        roles = ["researcher", "coder", "planner", "critic"]
        for role in roles:
            if role not in self.agents:
                self.agents[role] = self._create_agent_for_role(role)
```

### Tool Registration

```python
# tool_registry.py
from typing import Dict, Type
from anus.tools.base.tool import BaseTool

class ToolRegistry:
    """Registry for tool discovery and instantiation"""
    
    _tools: Dict[str, Type[BaseTool]] = {}
    
    @classmethod
    def register(cls, tool_class: Type[BaseTool]) -> Type[BaseTool]:
        """Register a tool class"""
        cls._tools[tool_class.__name__] = tool_class
        return tool_class
        
    @classmethod
    def get_tool(cls, name: str) -> Type[BaseTool]:
        """Get a tool class by name"""
        if name not in cls._tools:
            raise ValueError(f"Tool {name} not registered")
        return cls._tools[name]
        
    @classmethod
    def create_tool(cls, name: str, **kwargs) -> BaseTool:
        """Create a tool instance by name"""
        tool_class = cls.get_tool(name)
        return tool_class(**kwargs)
        
    @classmethod
    def list_tools(cls) -> Dict[str, Type[BaseTool]]:
        """List all registered tools"""
        return cls._tools.copy()

# Usage example
@ToolRegistry.register
class BrowserTool(BaseTool):
    name = "browser"
    description = "Interact with web browser"
    # Implementation...
```

## Enhanced Concepts

### Hybrid Agent System

```python
# hybrid_agent.py
from typing import Dict, List, Optional
from anus.core.agent.tool_agent import ToolAgent
from anus.core.memory.base_memory import BaseMemory

class HybridAgent(ToolAgent):
    """
    Agent that can dynamically switch between single-agent and multi-agent modes
    based on task complexity and requirements.
    """
    
    name: str = "hybrid"
    description: str = "A versatile agent that can work alone or collaborate"
    
    # Additional fields for multi-agent mode
    sub_agents: Dict[str, ToolAgent] = {}
    collaboration_threshold: float = 0.7  # Complexity threshold for switching modes
    
    async def run(self, request: Optional[str] = None) -> str:
        """Execute the agent with dynamic mode selection"""
        if not request:
            return "No request provided"
            
        # Analyze task complexity
        complexity = await self._analyze_complexity(request)
        
        # Choose execution mode based on complexity
        if complexity > self.collaboration_threshold:
            return await self._run_collaborative(request)
        else:
            return await super().run(request)
            
    async def _analyze_complexity(self, request: str) -> float:
        """Analyze task complexity to determine execution mode"""
        # Implementation using LLM to assess task complexity
        # Returns a value between 0 and 1
        
    async def _run_collaborative(self, request: str) -> str:
        """Execute request in collaborative multi-agent mode"""
        # Implementation of multi-agent collaboration
        # Creates sub-agents if needed, coordinates their work
```

### Consensus Mechanism

```python
# consensus_flow.py
from typing import Dict, List, Optional
from anus.core.agent.base_agent import BaseAgent
from anus.core.flow.base_flow import BaseFlow

class ConsensusFlow(BaseFlow):
    """
    Flow that coordinates multiple agents to reach consensus on complex tasks
    through voting and collaborative decision-making.
    """
    
    voting_threshold: float = 0.6  # Minimum agreement percentage for consensus
    max_rounds: int = 3  # Maximum voting rounds before fallback
    
    async def execute(self, input_text: str) -> str:
        """Execute the consensus flow with multiple agents"""
        # Break down the task
        task_components = await self._break_down_task(input_text)
        
        results = []
        for component in task_components:
            # Get solutions from all agents
            solutions = await self._gather_solutions(component)
            
            # Reach consensus through voting
            consensus = await self._reach_consensus(solutions)
            
            # Execute the consensus solution
            result = await self._execute_consensus(consensus, component)
            results.append(result)
            
        # Combine results
        return self._combine_results(results)
        
    async def _gather_solutions(self, task: str) -> Dict[str, str]:
        """Gather solutions from all agents"""
        solutions = {}
        for name, agent in self.agents.items():
            solution = await agent.run(task)
            solutions[name] = solution
        return solutions
        
    async def _reach_consensus(self, solutions: Dict[str, str]) -> str:
        """Reach consensus through voting mechanism"""
        # Implementation of voting and consensus algorithm
```

### Resource Allocation

```python
# resource_planner.py
from typing import Dict, List, Optional
from anus.core.planning.base_planner import BasePlanner

class ResourcePlanner(BasePlanner):
    """
    Planner that allocates computational resources based on task requirements
    and optimizes execution efficiency.
    """
    
    async def allocate_resources(self, plan: Dict) -> Dict:
        """Allocate resources to plan steps based on requirements"""
        enhanced_plan = plan.copy()
        
        # Analyze resource requirements for each step
        for i, step in enumerate(enhanced_plan.get("steps", [])):
            resources = await self._analyze_step_resources(step)
            enhanced_plan["step_resources"] = enhanced_plan.get("step_resources", [])
            enhanced_plan["step_resources"].append(resources)
            
        # Optimize resource allocation across steps
        enhanced_plan = await self._optimize_allocation(enhanced_plan)
        
        return enhanced_plan
        
    async def _analyze_step_resources(self, step: str) -> Dict:
        """Analyze resource requirements for a step"""
        # Implementation to determine CPU, memory, model, and tool requirements
        
    async def _optimize_allocation(self, plan: Dict) -> Dict:
        """Optimize resource allocation across steps"""
        # Implementation to balance resources and identify parallelization opportunities
```

## Implementation Strategy

The implementation strategy focuses on progressive enhancement, starting with core components and gradually adding advanced features:

1. **Phase 1: Core Framework**
   - Implement base agent, memory, and tool abstractions
   - Create basic planning system
   - Develop configuration system
   - Build CLI interface

2. **Phase 2: Tool Ecosystem**
   - Implement web interaction tools
   - Add information retrieval capabilities
   - Create document processing tools
   - Develop code execution sandbox

3. **Phase 3: Advanced Features**
   - Implement hybrid agent system
   - Add multi-agent collaboration
   - Develop consensus mechanisms
   - Create resource allocation system

4. **Phase 4: User Interfaces**
   - Enhance CLI with interactive features
   - Develop web interface
   - Create API for integration
   - Add visualization components

This phased approach ensures a solid foundation before adding more complex features, allowing for testing and refinement at each stage.
````

## instructions/Valuable Concepts.md

- Characters: 5228
- Tokens: 0

```markdown
# Valuable Concepts from OpenManus for ANUS Implementation

## 1. Agent Architecture

### Core Concept: Layered Agent Abstraction
OpenManus implements a well-structured agent hierarchy with clear separation of concerns:
- `BaseAgent`: Abstract foundation with core functionality
- `ReActAgent`: Extends base with reasoning capabilities
- `ToolCallAgent`: Adds tool execution capabilities
- `Manus`: Concrete implementation with specific tools

This layered approach allows for:
- Clear inheritance patterns
- Progressive enhancement of capabilities
- Separation of core logic from specific implementations

### Adaptation for ANUS:
ANUS can adopt this pattern while enhancing it with its planned "Hybrid Agent System" that switches between single and multi-agent modes. The base architecture could be extended to support dynamic role assignment and agent collaboration.

## 2. Planning System

### Core Concept: Structured Planning with Step Management
OpenManus implements a sophisticated planning system through:
- `PlanningFlow`: Manages execution of multi-step plans
- `PlanningTool`: Creates and tracks plan progress
- Step status tracking (not_started, in_progress, completed)
- Dynamic step execution with appropriate agent selection

This planning system enables:
- Breaking complex tasks into manageable steps
- Tracking progress through plan execution
- Selecting appropriate agents for specific step types

### Adaptation for ANUS:
ANUS can enhance this planning system to support its "Dynamic Task Planning" feature, adding capabilities for resource allocation and parallel execution of steps when appropriate.

## 3. Tool Integration Framework

### Core Concept: Flexible Tool System
OpenManus implements a robust tool framework through:
- `BaseTool`: Abstract foundation for all tools
- `ToolCollection`: Container for managing multiple tools
- Standardized execution interface
- Tool result handling with success/failure patterns

This tool system enables:
- Easy addition of new capabilities
- Consistent interface for tool execution
- Proper error handling and result processing

### Adaptation for ANUS:
ANUS can adopt this pattern while expanding it to support its "Comprehensive Tool Ecosystem" with categorized tools for web interaction, information retrieval, document processing, etc.

## 4. Flow Management

### Core Concept: Execution Flow Abstraction
OpenManus separates execution flow from agent logic through:
- `BaseFlow`: Abstract foundation for execution patterns
- `PlanningFlow`: Concrete implementation for planning-based execution
- `FlowFactory`: Factory pattern for creating appropriate flows

This flow abstraction enables:
- Different execution strategies without changing agent code
- Clear separation between agent capabilities and execution patterns
- Factory pattern for easy creation of appropriate flows

### Adaptation for ANUS:
ANUS can leverage this pattern to implement its "Multi-Agent Collaboration" feature, creating specialized flows for different collaboration patterns and consensus mechanisms.

## 5. Browser Integration

### Core Concept: Comprehensive Browser Automation
OpenManus implements browser automation through:
- `BrowserUseTool`: Wrapper for browser automation capabilities
- Support for navigation, interaction, content extraction
- Structured interface for browser operations

This browser integration enables:
- Web-based information gathering
- Form filling and submission
- Content extraction and analysis

### Adaptation for ANUS:
ANUS can adopt this pattern while enhancing it with its planned "Web Interaction" capabilities, including authentication handling and more sophisticated scraping.

## 6. LLM Abstraction

### Core Concept: Model Interaction Abstraction
OpenManus abstracts LLM interactions through:
- Standardized interface for model communication
- Support for tool/function calling
- Consistent message formatting

This LLM abstraction enables:
- Swapping underlying models without changing agent code
- Standardized handling of model responses
- Consistent tool calling interface

### Adaptation for ANUS:
ANUS can enhance this pattern to support its "Flexible Model Integration" feature, adding support for open-source models and local deployment options.

## 7. Memory Management

### Core Concept: Agent Memory System
OpenManus implements a basic memory system for agents:
- Message history tracking
- Context management for conversations
- State persistence between interactions

### Adaptation for ANUS:
ANUS can significantly enhance this concept to implement its planned "Memory Management" with short-term and long-term memory systems for better context retention.

## 8. Modular Configuration

### Core Concept: Configuration Management
OpenManus implements configuration handling through:
- External configuration files (TOML)
- Structured configuration objects
- Default values with override capabilities

This configuration system enables:
- Easy customization without code changes
- Environment-specific configurations
- Sensible defaults with override options

### Adaptation for ANUS:
ANUS can adopt this pattern while enhancing it to support its more complex configuration needs for multi-agent setups and tool ecosystems.
```

## CODE_OF_CONDUCT.md

- Characters: 5245
- Tokens: 0

```markdown
# CODE_OF_CONDUCT.md

# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
[INSERT CONTACT METHOD].
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior, harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.
```

## research/README.md

- Characters: 590
- Tokens: 0

```markdown
# Research

This directory contains research materials, analysis documents, and technical investigations related to the ANUS project.

## Contents

- AI Agent Architectures
- Multi-Agent Systems
- Natural Language Processing
- Task Planning and Execution
- Tool Integration Patterns
- Security and Privacy Considerations

## Contributing

If you'd like to contribute research materials:

1. Create a new markdown file with your research topic
2. Include clear methodology and findings
3. Reference academic papers and sources where applicable
4. Submit a pull request with your contribution
```

## anus/tools/README.md

- Characters: 893
- Tokens: 0

```markdown
# Anus Tools Module

This module contains the tool ecosystem components of the Anus AI framework, including:

- Web Interaction Tools (Browser Automation)
- Information Retrieval Tools (Search, Wikipedia)
- Document Processing Tools (PDF, Word, Excel)
- Code Execution Environment
- Multimodal Processing (Images, Audio, Video)

## Components

### base_tool.py
Base class for all tools with common functionality and interface.

### web_tools.py
Browser automation using Playwright, web scraping, and data extraction.

### search_tools.py
Search engine integration, Wikipedia access, and information retrieval.

### document_tools.py
PDF parsing, Office document handling, and data extraction.

### code_tools.py
Secure Python execution sandbox and code analysis.

### multimodal_tools.py
Image, audio, and video processing capabilities.

### registry.py
Tool registration and discovery system.
```

## anus/tools/utility/calculator.py

- Characters: 7579
- Tokens: 0

```python
"""
Calculator tool for basic arithmetic operations.

When ANUS needs to do math, it uses this tool to work things out.
"""

import logging
import random
from typing import Dict, Any, Union, List

from anus.tools.base.tool import BaseTool
from anus.tools.base.tool_result import ToolResult

class CalculatorTool(BaseTool):
    """
    A tool for performing basic arithmetic calculations.
    
    Supports addition, subtraction, multiplication, division, 
    and other basic mathematical operations.
    
    ANUS might not be good at everything, but it's surprisingly good with numbers.
    """
    
    name = "calculator"
    description = "Perform basic arithmetic calculations"
    parameters = {
        "type": "object",
        "properties": {
            "expression": {
                "type": "string",
                "description": "The mathematical expression to evaluate"
            }
        },
        "required": ["expression"]
    }
    
    # Easter egg responses for specific calculations
    _easter_eggs = {
        "1+1": "2 (even ANUS can handle this one!)",
        "69+69": "138 (nice+nice)",
        "80085": "The number spells 'BOOBS' on a calculator. ANUS approves.",
        "42": "The answer to life, the universe, and everything. ANUS is enlightened.",
        "3.14159": "œÄ (ANUS loves pie!)",
        "58008": "Turn your calculator upside down for a surprise. ANUS is giggling.",
        "1/0": "ANUS cannot handle division by zero! It's too tight a squeeze.",
        "9+10": "19 (not 21, sorry for the disappointment)",
        "8==D": "ANUS detects inappropriate ASCII art; this isn't that kind of calculator.",
        "sqrt(-1)": "i (imaginary, just like ANUS's hopes and dreams)"
    }
    
    # Funny calculation messages
    _calc_messages = [
        "ANUS is crunching the numbers...",
        "ANUS is performing intense calculations...",
        "ANUS is squeezing out a result...",
        "ANUS is pushing through this tough equation...",
        "ANUS is working it out from behind the scenes..."
    ]
    
    def execute(self, expression: str, **kwargs) -> Union[Dict[str, Any], ToolResult]:
        """
        Execute the calculator tool.
        
        Args:
            expression: The mathematical expression to evaluate.
            **kwargs: Additional parameters (ignored).
            
        Returns:
            The calculation result.
        """
        try:
            # Check for easter eggs
            cleaned_expr = expression.replace(" ", "").lower()
            for trigger, response in self._easter_eggs.items():
                if cleaned_expr == trigger.lower():
                    logging.info(f"ANUS calculator triggered an easter egg: {trigger}")
                    return ToolResult.success(
                        self.name,
                        {
                            "expression": expression,
                            "result": response,
                            "easter_egg": True
                        }
                    )
            
            # Log a funny calculation message
            if random.random() < 0.3:  # 30% chance
                logging.info(random.choice(self._calc_messages))
            
            # Validate the expression first
            self._validate_expression(expression)
            
            # Evaluate the expression
            result = eval(expression, {"__builtins__": {}}, self._safe_math_context())
            
            # Check for special number results to make jokes about
            result_jokes = {
                69: "Nice!",
                420: "Blaze it!",
                666: "Devilish result!",
                1337: "Leet calculation!",
                80085: "ANUS likes this number for some reason...",
                42: "The answer to life, the universe, and everything!"
            }
            
            comment = None
            if isinstance(result, (int, float)):
                for number, joke in result_jokes.items():
                    if abs(result - number) < 0.0001:  # Close enough for floats
                        comment = joke
                        break
            
            # Return as ToolResult
            result_dict = {
                "expression": expression,
                "result": result
            }
            
            if comment:
                result_dict["comment"] = comment
                logging.info(f"ANUS calculator result triggered a joke: {comment}")
            
            return ToolResult.success(self.name, result_dict)
            
        except Exception as e:
            error_msg = str(e)
            
            # Add funny error messages
            if "division by zero" in error_msg.lower():
                error_msg = "Division by zero! Even ANUS has its limits."
            elif "invalid syntax" in error_msg.lower():
                error_msg = "Invalid syntax! ANUS is confused by your notation."
            
            logging.error(f"Error in calculator tool: {e}")
            return ToolResult.error(self.name, f"Calculation error: {error_msg}")
    
    def validate_input(self, expression: str = None, **kwargs) -> bool:
        """
        Validate the input parameters.
        
        Args:
            expression: The mathematical expression to validate.
            **kwargs: Additional parameters (ignored).
            
        Returns:
            True if the input is valid, False otherwise.
        """
        if expression is None:
            return False
        
        try:
            self._validate_expression(expression)
            return True
        except:
            return False
    
    def _validate_expression(self, expression: str) -> None:
        """
        Validate that an expression is safe to evaluate.
        
        Args:
            expression: The expression to validate.
            
        Raises:
            ValueError: If the expression contains unsafe elements.
        """
        # Check for common unsafe patterns
        unsafe_patterns = [
            "__", "import", "eval", "exec", "compile", "open", 
            "file", "os.", "sys.", "subprocess", "lambda"
        ]
        
        for pattern in unsafe_patterns:
            if pattern in expression:
                logging.warning(f"ANUS detected a potential security breach: {pattern}")
                raise ValueError(f"Expression contains unsafe pattern: {pattern}. ANUS refuses to process this.")
        
        # Only allow basic arithmetic operations and numeric literals
        allowed_chars = set("0123456789.+-*/() ")
        for char in expression:
            if char not in allowed_chars:
                logging.warning(f"ANUS caught an illegal character: {char}")
                raise ValueError(f"Expression contains disallowed character: {char}. ANUS only does basic arithmetic.")
    
    def _safe_math_context(self) -> Dict[str, Any]:
        """
        Create a safe context for math operations.
        
        Returns:
            A dictionary with allowed mathematical functions.
        """
        import math
        
        # Allow only safe math functions
        return {
            "abs": abs,
            "max": max,
            "min": min,
            "pow": pow,
            "round": round,
            "sum": sum,
            # Add some math module functions
            "sqrt": math.sqrt,
            "sin": math.sin,
            "cos": math.cos,
            "tan": math.tan,
            "pi": math.pi,
            "e": math.e
        }
```

## anus/tools/utility/__init__.py

- Characters: 244
- Tokens: 0

```python
"""
Utility tools for the ANUS framework.

This module contains basic utility tools:
- CalculatorTool: Tool for performing basic arithmetic calculations
"""

from anus.tools.utility.calculator import CalculatorTool

__all__ = ["CalculatorTool"]
```

## anus/tools/base/tool_result.py

- Characters: 3192
- Tokens: 0

```python
"""
Tool Result module for standardized result handling.
"""

from typing import Dict, List, Any, Optional, Union
import time

class ToolResult:
    """
    Standardized container for tool execution results.
    
    Provides consistent structure and metadata for tool results.
    """
    
    def __init__(
        self, 
        tool_name: str,
        status: str = "success",
        result: Any = None,
        error: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ):
        """
        Initialize a ToolResult instance.
        
        Args:
            tool_name: Name of the tool that produced the result.
            status: Status of the tool execution ("success" or "error").
            result: The actual result data.
            error: Error message if status is "error".
            metadata: Additional metadata about the execution.
        """
        self.tool_name = tool_name
        self.status = status
        self.result = result
        self.error = error
        self.metadata = metadata or {}
        
        # Add timestamp
        self.timestamp = time.time()
    
    def to_dict(self) -> Dict[str, Any]:
        """
        Convert the result to a dictionary.
        
        Returns:
            A dictionary representation of the result.
        """
        result_dict = {
            "tool_name": self.tool_name,
            "status": self.status,
            "timestamp": self.timestamp,
            "metadata": self.metadata
        }
        
        if self.status == "success":
            result_dict["result"] = self.result
        elif self.status == "error":
            result_dict["error"] = self.error
        
        return result_dict
    
    @classmethod
    def success(cls, tool_name: str, result: Any, metadata: Optional[Dict[str, Any]] = None) -> 'ToolResult':
        """
        Create a successful result.
        
        Args:
            tool_name: Name of the tool.
            result: The result data.
            metadata: Additional metadata.
            
        Returns:
            A ToolResult instance with success status.
        """
        return cls(tool_name=tool_name, status="success", result=result, metadata=metadata)
    
    @classmethod
    def error(cls, tool_name: str, error: str, metadata: Optional[Dict[str, Any]] = None) -> 'ToolResult':
        """
        Create an error result.
        
        Args:
            tool_name: Name of the tool.
            error: The error message.
            metadata: Additional metadata.
            
        Returns:
            A ToolResult instance with error status.
        """
        return cls(tool_name=tool_name, status="error", error=error, metadata=metadata)
    
    def is_success(self) -> bool:
        """
        Check if the result is successful.
        
        Returns:
            True if the status is "success", False otherwise.
        """
        return self.status == "success"
    
    def is_error(self) -> bool:
        """
        Check if the result is an error.
        
        Returns:
            True if the status is "error", False otherwise.
        """
        return self.status == "error"
```

## anus/tools/base/tool.py

- Characters: 1671
- Tokens: 0

```python
"""
Base Tool module that defines the common interface for all tools.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Union

class BaseTool(ABC):
    """
    Abstract base class for all tools in the ANUS framework.
    
    Provides the core functionality and interface that all tool types must implement.
    """
    
    name = "base_tool"
    description = "Base class for all tools"
    
    def __init__(self, **kwargs):
        """
        Initialize a BaseTool instance.
        
        Args:
            **kwargs: Additional configuration options for the tool.
        """
        self.config = kwargs
    
    @abstractmethod
    def execute(self, **kwargs) -> Any:
        """
        Execute the tool's function.
        
        Args:
            **kwargs: Input parameters for the tool.
            
        Returns:
            The result of the tool execution.
        """
        pass
    
    def validate_input(self, **kwargs) -> bool:
        """
        Validate the input parameters.
        
        Args:
            **kwargs: Input parameters to validate.
            
        Returns:
            True if the input is valid, False otherwise.
        """
        # Base implementation is a pass-through
        return True
    
    def get_schema(self) -> Dict[str, Any]:
        """
        Get the tool's parameter schema.
        
        Returns:
            A dictionary describing the tool's parameters.
        """
        # Base implementation returns a simple schema
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {}
        }
```

## anus/tools/base/__init__.py

- Characters: 463
- Tokens: 0

```python
"""
Base Tool module for the ANUS framework.

This module contains base classes for tools:
- BaseTool: Abstract base class for all tools
- ToolResult: Standardized container for tool results
- ToolCollection: Utility for managing collections of tools
"""

from anus.tools.base.tool import BaseTool
from anus.tools.base.tool_result import ToolResult
from anus.tools.base.tool_collection import ToolCollection

__all__ = ["BaseTool", "ToolResult", "ToolCollection"]
```

## anus/tools/base/tool_collection.py

- Characters: 6073
- Tokens: 0

```python
"""
Tool Collection module for managing collections of tools.
"""

from typing import Dict, List, Any, Optional, Type, Union
import importlib
import inspect
import logging
import os
import pkgutil

from anus.tools.base.tool import BaseTool

class ToolCollection:
    """
    A collection of tools with registration and discovery capabilities.
    
    Provides functionality for:
    - Registering tools
    - Loading tools dynamically
    - Tool discovery
    - Tool execution
    """
    
    def __init__(self):
        """
        Initialize a ToolCollection instance.
        """
        self.tools: Dict[str, BaseTool] = {}
        self.tool_classes: Dict[str, Type[BaseTool]] = {}
    
    def register_tool(self, tool: BaseTool) -> None:
        """
        Register a tool instance.
        
        Args:
            tool: The tool instance to register.
        """
        self.tools[tool.name] = tool
        logging.info(f"Registered tool: {tool.name}")
    
    def register_tool_class(self, tool_class: Type[BaseTool]) -> None:
        """
        Register a tool class for later instantiation.
        
        Args:
            tool_class: The tool class to register.
        """
        name = getattr(tool_class, "name", tool_class.__name__.lower())
        self.tool_classes[name] = tool_class
        logging.info(f"Registered tool class: {name}")
    
    def get_tool(self, name: str) -> Optional[BaseTool]:
        """
        Get a tool by name.
        
        Args:
            name: The name of the tool.
            
        Returns:
            The tool instance, or None if not found.
        """
        # Check if the tool is already instantiated
        if name in self.tools:
            return self.tools[name]
        
        # Check if we have the tool class and can instantiate it
        if name in self.tool_classes:
            try:
                tool = self.tool_classes[name]()
                self.register_tool(tool)
                return tool
            except Exception as e:
                logging.error(f"Error instantiating tool {name}: {e}")
                return None
        
        # Tool not found
        return None
    
    def execute_tool(self, name: str, **kwargs) -> Any:
        """
        Execute a tool by name.
        
        Args:
            name: The name of the tool to execute.
            **kwargs: Input parameters for the tool.
            
        Returns:
            The result of the tool execution, or an error message.
        """
        tool = self.get_tool(name)
        
        if tool is None:
            error_msg = f"Tool not found: {name}"
            logging.error(error_msg)
            return {"status": "error", "error": error_msg}
        
        try:
            # Validate input
            if not tool.validate_input(**kwargs):
                error_msg = f"Invalid input for tool {name}"
                logging.error(error_msg)
                return {"status": "error", "error": error_msg}
            
            # Execute the tool
            result = tool.execute(**kwargs)
            return {"status": "success", "result": result}
        except Exception as e:
            error_msg = f"Error executing tool {name}: {str(e)}"
            logging.error(error_msg)
            return {"status": "error", "error": error_msg}
    
    def list_tools(self) -> List[Dict[str, Any]]:
        """
        List all available tools.
        
        Returns:
            A list of tool information dictionaries.
        """
        tool_info = []
        
        # Add instantiated tools
        for name, tool in self.tools.items():
            info = {
                "name": name,
                "description": getattr(tool, "description", "No description available"),
                "parameters": getattr(tool, "parameters", {})
            }
            tool_info.append(info)
        
        # Add non-instantiated tool classes
        for name, tool_class in self.tool_classes.items():
            if name not in self.tools:
                info = {
                    "name": name,
                    "description": getattr(tool_class, "description", "No description available"),
                    "parameters": getattr(tool_class, "parameters", {})
                }
                tool_info.append(info)
        
        return tool_info
    
    def discover_tools(self, package_name: str = "anus.tools") -> int:
        """
        Discover tools in the specified package.
        
        Args:
            package_name: The package to search for tools.
            
        Returns:
            The number of tools discovered.
        """
        count = 0
        
        try:
            package = importlib.import_module(package_name)
            for _, name, is_pkg in pkgutil.iter_modules(package.__path__, package.__name__ + "."):
                if is_pkg:
                    # Recursively discover tools in subpackages
                    count += self.discover_tools(name)
                else:
                    # Import the module
                    try:
                        module = importlib.import_module(name)
                        
                        # Find tool classes in the module
                        for attr_name in dir(module):
                            attr = getattr(module, attr_name)
                            
                            # Check if it's a tool class
                            if (
                                inspect.isclass(attr) and 
                                issubclass(attr, BaseTool) and 
                                attr != BaseTool
                            ):
                                self.register_tool_class(attr)
                                count += 1
                    except Exception as e:
                        logging.error(f"Error discovering tools in module {name}: {e}")
        except Exception as e:
            logging.error(f"Error discovering tools in package {package_name}: {e}")
        
        return count
```

## anus/tools/__init__.py

- Characters: 282
- Tokens: 0

```python
"""
Tools module for the ANUS framework.

This module contains various tools that can be used by agents to interact with 
the environment and perform tasks.
"""

from anus.tools.base import BaseTool, ToolResult, ToolCollection

__all__ = ["BaseTool", "ToolResult", "ToolCollection"]
```

## anus/models/README.md

- Characters: 703
- Tokens: 0

```markdown
# Anus Models Module

This module contains the model integration components of the Anus AI framework, including:

- OpenAI API Support
- Open-Source Model Support
- Model Switching and Fallback Mechanisms
- Vision Model Integration

## Components

### base_model.py
Base class for all model integrations with common functionality.

### openai_model.py
Integration with OpenAI API models (GPT-4, etc.).

### open_source_model.py
Integration with open-source models (Llama, Mistral, etc.).

### vision_model.py
Integration with vision models for image understanding.

### model_manager.py
Model selection, switching, and fallback mechanisms.

### config.py
Configuration management for model integrations.
```

## anus/models/base/base_model.py

- Characters: 5096
- Tokens: 0

```python
"""
Base Model module that defines the common interface for all language models.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Union, Callable
from pydantic import BaseModel as PydanticBaseModel


class ToolCall(PydanticBaseModel):
    """Represents a tool call from a language model."""

    id: str
    type: str = "function"
    function: Dict[str, Any]


class ModelResponse(PydanticBaseModel):
    """Represents a response from a language model."""

    content: Optional[str] = None
    tool_calls: Optional[List[ToolCall]] = None


class BaseModel(ABC):
    """
    Abstract base class for language model implementations.

    Provides a common interface for interacting with different LLM providers.
    """

    def __init__(
        self,
        model_name: str,
        temperature: float = 0.0,
        max_tokens: Optional[int] = None,
        **kwargs
    ):
        """
        Initialize a BaseModel instance.

        Args:
            model_name: The name of the model to use.
            temperature: Controls randomness in outputs. Lower values are more deterministic.
            max_tokens: Maximum number of tokens to generate.
            **kwargs: Additional model-specific parameters.
        """
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
        self.config = kwargs

    @abstractmethod
    def generate(
        self,
        prompt: str,
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Generate text based on a prompt.

        Args:
            prompt: The text prompt for generation.
            system_message: Optional system message for models that support it.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional model-specific parameters.

        Returns:
            The generated text response.
        """
        pass

    @abstractmethod
    def generate_with_tools(
        self,
        prompt: str,
        tools: List[Dict[str, Any]],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Generate text with tool calling capabilities.

        Args:
            prompt: The text prompt for generation.
            tools: List of tool schemas available for use.
            system_message: Optional system message for models that support it.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional model-specific parameters.

        Returns:
            A dictionary with the response and any tool calls.
        """
        pass

    @abstractmethod
    def extract_json(
        self,
        prompt: str,
        schema: Dict[str, Any],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Extract structured JSON data based on a prompt.

        Args:
            prompt: The text prompt for extraction.
            schema: JSON schema describing the expected structure.
            system_message: Optional system message for models that support it.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional model-specific parameters.

        Returns:
            The extracted JSON data.
        """
        pass

    @abstractmethod
    def get_embedding(self, text: str, **kwargs) -> List[float]:
        """
        Generate an embedding vector for the given text.

        Args:
            text: The text to embed.
            **kwargs: Additional model-specific parameters.

        Returns:
            The embedding vector as a list of floats.
        """
        pass

    def get_token_count(self, text: str) -> int:
        """
        Estimate the number of tokens in the given text.

        Args:
            text: The text to count tokens for.

        Returns:
            The approximate token count.
        """
        # Simple approximation: 1 token ‚âà 4 characters
        return len(text) // 4

    def get_model_details(self) -> Dict[str, Any]:
        """
        Get details about the model.

        Returns:
            A dictionary containing model information.
        """
        return {
            "model_name": self.model_name,
            "temperature": self.temperature,
            "max_tokens": self.max_tokens,
            "config": self.config,
        }
```

## anus/models/base/__init__.py

- Characters: 232
- Tokens: 0

```python
"""
Base Models module for the ANUS framework.

This module contains the base model interfaces:
- BaseModel: Abstract base class for all language models
"""

from anus.models.base.base_model import BaseModel

__all__ = ["BaseModel"]
```

## anus/models/model_router.py

- Characters: 6261
- Tokens: 0

```python
"""
Model Router module for dynamic model selection.
"""

from typing import Dict, List, Any, Optional, Union, Type
import logging

from anus.models.base.base_model import BaseModel
from anus.models.gemini_model import GeminiModel
from anus.models.openai_model import OpenAIModel


class ModelRouter:
    """
    Router for dynamically selecting and managing language models.

    Provides functionality for:
    - Registering different model implementations
    - Selecting models based on task requirements
    - Fallback mechanisms for reliability
    """

    def __init__(self, default_model_config: Optional[Dict[str, Any]] = None):
        """
        Initialize a ModelRouter instance.

        Args:
            default_model_config: Configuration for the default model.
        """
        self.models: Dict[str, BaseModel] = {}
        self.model_classes: Dict[str, Type[BaseModel]] = {
            # "openai": OpenAIModel,
            "gemini": GeminiModel,
        }
        self.default_model_config = default_model_config or {
            "provider": "gemini",
            "model_name": "gemini-2.0-flash",
            "temperature": 0.0,
        }
        self.default_model = None

    def register_model(self, name: str, model: BaseModel) -> None:
        """
        Register a model instance.

        Args:
            name: A unique name for the model.
            model: The model instance to register.
        """
        self.models[name] = model
        logging.info(f"Registered model: {name}")

    def register_model_class(self, provider: str, model_class: Type[BaseModel]) -> None:
        """
        Register a model class for a provider.

        Args:
            provider: The model provider name.
            model_class: The model class to register.
        """
        self.model_classes[provider] = model_class
        logging.info(f"Registered model class for provider: {provider}")

    def get_model(self, name_or_config: Union[str, Dict[str, Any]]) -> BaseModel:
        """
        Get a model instance by name or create one from config.

        Args:
            name_or_config: Either a model name or a model configuration dictionary.

        Returns:
            A model instance.
        """
        # If it's a string, look up by name
        if isinstance(name_or_config, str):
            # Check registered models
            if name_or_config in self.models:
                return self.models[name_or_config]

            # If not found, use default model
            logging.warning(f"Model '{name_or_config}' not found. Using default model.")
            return self.get_default_model()

        # If it's a config dict, create a new model
        elif isinstance(name_or_config, dict):
            return self._create_model_from_config(name_or_config)

        # Invalid input
        else:
            logging.error(f"Invalid model specification: {name_or_config}")
            return self.get_default_model()

    def get_default_model(self) -> BaseModel:
        """
        Get the default model, creating it if necessary.

        Returns:
            The default model instance.
        """
        if self.default_model is None:
            self.default_model = self._create_model_from_config(
                self.default_model_config
            )

        return self.default_model

    def select_model_for_task(
        self, task: str, requirements: Dict[str, Any] = None
    ) -> BaseModel:
        """
        Select an appropriate model for a given task.

        Args:
            task: The task description.
            requirements: Optional requirements for the model.

        Returns:
            The selected model instance.
        """
        # Simple implementation: just use requirements if provided
        if requirements:
            return self._create_model_from_config(requirements)

        # Default to the default model
        return self.get_default_model()

    def _create_model_from_config(self, config: Dict[str, Any]) -> BaseModel:
        """
        Create a model instance from a configuration dictionary.

        Args:
            config: The model configuration.

        Returns:
            A model instance.
        """
        # Get the provider
        provider = config.get("provider", "openai").lower()

        # Check if we have a class for this provider
        if provider not in self.model_classes:
            logging.error(
                f"Unknown model provider: {provider}. Using OpenAI as fallback."
            )
            provider = "openai"

        try:
            # Get the model class
            model_class = self.model_classes[provider]

            # Extract kwargs for the model
            kwargs = config.copy()
            kwargs.pop("provider", None)

            # Create the model
            return model_class(**kwargs)

        except Exception as e:
            logging.error(f"Error creating model for provider {provider}: {e}")

            # Fallback to OpenAI with minimal config
            try:
                return OpenAIModel(model_name="gpt-4")
            except Exception:
                raise ValueError(f"Failed to create model: {e}")

    def list_available_models(self) -> List[Dict[str, Any]]:
        """
        List all available models.

        Returns:
            A list of model information dictionaries.
        """
        models_info = []

        # Add instantiated models
        for name, model in self.models.items():
            info = {
                "name": name,
                "type": type(model).__name__,
                "model_name": model.model_name,
                "details": model.get_model_details(),
            }
            models_info.append(info)

        # Add available providers
        for provider in self.model_classes.keys():
            if provider not in [
                info["details"].get("provider") for info in models_info
            ]:
                models_info.append(
                    {
                        "name": f"{provider}",
                        "type": self.model_classes[provider].__name__,
                        "details": {"provider": provider},
                    }
                )

        return models_info
```

## anus/models/gemini_model.py

- Characters: 10699
- Tokens: 0

```python
"""
Google Gemini Model implementation for the ANUS framework.
"""

from typing import Dict, List, Optional, Union, Any
import json
import os
import logging
from pydantic import Field

# Import from the new SDK
from google import genai 
from google.genai import types as genai_types

from anus.models.base.base_model import BaseModel, ToolCall

class GeminiModel(BaseModel):
    """
    Google Gemini API integration for language models.
    Supports Gemini 2.0 models.
    """
    
    provider: str = "gemini"
    model_name: str = "gemini-2.0-flash"  # Default model
    api_key: Optional[str] = Field(default_factory=lambda: os.environ.get("GOOGLE_API_KEY"))
    base_url: Optional[str] = None
    temperature: float = 0.0
    max_tokens: Optional[int] = None
    
    def __init__(self, **data):
        super().__init__(**data)
        
        if not self.api_key:
            raise ValueError("Google API key is required. Set GOOGLE_API_KEY environment variable or pass api_key parameter.")
        
        # Initialize the client with our API key
        self.client = genai.Client(api_key=self.api_key)
    
    async def generate(
        self, 
        prompt: str, 
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Generate text based on a prompt using Google Gemini.
        
        Args:
            prompt: The text prompt for generation.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional Gemini-specific parameters.
            
        Returns:
            The generated text response.
        """
        # Create configuration
        config = {}
        
        # Add system instruction if provided
        if system_message:
            config["system_instruction"] = system_message
            
        # Add other parameters
        if temperature is not None:
            config["temperature"] = temperature
        elif self.temperature is not None:
            config["temperature"] = self.temperature
            
        if max_tokens is not None:
            config["max_output_tokens"] = max_tokens
        elif self.max_tokens is not None:
            config["max_output_tokens"] = self.max_tokens
        
        try:
            # Generate response
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=config
            )
            
            return response.text
        
        except Exception as e:
            logging.error(f"Error generating with Gemini: {e}")
            return f"Error: {str(e)}"
    
    async def generate_with_tools(
        self, 
        prompt: str, 
        tools: List[Dict[str, Any]],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Generate text with tool calling capabilities.
        
        Args:
            prompt: The text prompt for generation.
            tools: List of tool schemas available for use.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional Gemini-specific parameters.
            
        Returns:
            A dictionary with the response and any tool calls.
        """
        # Convert our tools to Gemini format
        gemini_tools = []
        for tool in tools:
            function = tool.get("function", {})
            
            # Create function declaration
            function_declaration = genai_types.FunctionDeclaration(
                name=function.get("name", ""),
                description=function.get("description", ""),
                parameters=function.get("parameters", {})
            )
            
            # Add to tools list
            gemini_tools.append(genai_types.Tool(
                function_declarations=[function_declaration]
            ))
        
        # Create configuration
        config = {}
        
        # Add system instruction if provided
        if system_message:
            config["system_instruction"] = system_message
            
        # Add parameters
        if temperature is not None:
            config["temperature"] = temperature
        elif self.temperature is not None:
            config["temperature"] = self.temperature
            
        if max_tokens is not None:
            config["max_output_tokens"] = max_tokens
        elif self.max_tokens is not None:
            config["max_output_tokens"] = self.max_tokens
            
        # Add tools and tool choice settings
        if gemini_tools:
            config["tools"] = gemini_tools
            
            # Handle tool choice
            tool_choice = kwargs.get("tool_choice", "auto")
            if tool_choice == "required":
                config["automatic_function_calling"] = {"disable": False}
            elif tool_choice == "none":
                config["automatic_function_calling"] = {"disable": True}
            # "auto" is the default in Gemini
        
        try:
            # Generate response with tools
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=config
            )
            
            # Extract content and tool calls
            content = response.text
            tool_calls = []
            
            # Process tool calls if present
            if hasattr(response, "candidates") and response.candidates:
                for candidate in response.candidates:
                    if hasattr(candidate, "content") and candidate.content.parts:
                        for part in candidate.content.parts:
                            if hasattr(part, "function_call"):
                                # Convert to our ToolCall format
                                tool_calls.append(
                                    ToolCall(
                                        id=str(len(tool_calls)),
                                        type="function",
                                        function={
                                            "name": part.function_call.name,
                                            "arguments": part.function_call.args
                                        }
                                    )
                                )
            
            return {
                "content": content,
                "tool_calls": tool_calls
            }
            
        except Exception as e:
            logging.error(f"Error generating with tools using Gemini: {e}")
            return {
                "content": f"Error: {str(e)}",
                "tool_calls": []
            }
    
    async def extract_json(
        self, 
        prompt: str, 
        schema: Dict[str, Any],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Extract structured JSON data based on a prompt.
        
        Args:
            prompt: The text prompt for extraction.
            schema: JSON schema describing the expected structure.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional Gemini-specific parameters.
            
        Returns:
            The extracted JSON data.
        """
        # Create configuration
        config = {
            "response_mime_type": "application/json",
            "response_schema": schema
        }
        
        # Add system instruction if provided
        if system_message:
            config["system_instruction"] = system_message
            
        # Add parameters
        if temperature is not None:
            config["temperature"] = temperature
        elif self.temperature is not None:
            config["temperature"] = self.temperature
            
        if max_tokens is not None:
            config["max_output_tokens"] = max_tokens
        elif self.max_tokens is not None:
            config["max_output_tokens"] = self.max_tokens
        
        try:
            # Generate response
            response = self.client.models.generate_content(
                model=self.model_name,
                contents=prompt,
                config=config
            )
            
            # The SDK may have parsed JSON automatically
            if hasattr(response, "parsed"):
                return response.parsed
            
            # Otherwise try to parse the JSON
            try:
                return json.loads(response.text)
            except json.JSONDecodeError:
                logging.error(f"Failed to parse JSON from response: {response.text}")
                return {"error": "Failed to parse JSON response"}
                
        except Exception as e:
            logging.error(f"Error extracting JSON with Gemini: {e}")
            return {"error": str(e)}
    
    async def get_embedding(self, text: str, **kwargs) -> List[float]:
        """
        Generate an embedding vector for the given text.
        
        Args:
            text: The text to embed.
            **kwargs: Additional Gemini-specific parameters.
            
        Returns:
            The embedding vector as a list of floats.
        """
        try:
            # Generate embeddings using the embedding model
            response = self.client.models.embed_content(
                model="text-embedding-004",  # Default embedding model
                contents=text
            )
            
            # Extract the embedding values
            if hasattr(response, "embedding"):
                return response.embedding.values
            
            return []
            
        except Exception as e:
            logging.error(f"Error generating embedding with Gemini: {e}")
            return []
```

## anus/models/__init__.py

- Characters: 542
- Tokens: 0

```python
"""
Models module for the ANUS framework.

This module contains language model implementations and utilities:
- BaseModel: Abstract base class for all language models
- OpenAIModel: Implementation for the OpenAI API
- ModelRouter: Dynamic model selection based on task requirements
"""

from anus.models.base import BaseModel
from anus.models.openai_model import OpenAIModel
from anus.models.gemini_model import GeminiModel
from anus.models.model_router import ModelRouter

__all__ = ["BaseModel", "OpenAIModel", "GeminiModel", "ModelRouter"]
```

## anus/models/openai_model.py

- Characters: 10815
- Tokens: 0

```python
"""
OpenAI Model implementation for the ANUS framework.
"""

from typing import Dict, List, Any, Optional, Union, Callable
import json
import logging
import os

try:
    import openai
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

from anus.models.base.base_model import BaseModel

class OpenAIModel(BaseModel):
    """
    OpenAI language model implementation.
    
    Provides integration with OpenAI's API for text generation and embeddings.
    """
    
    def __init__(
        self, 
        model_name: str = "gpt-4", 
        temperature: float = 0.0,
        max_tokens: Optional[int] = None,
        api_key: Optional[str] = None,
        base_url: Optional[str] = None,
        **kwargs
    ):
        """
        Initialize an OpenAIModel instance.
        
        Args:
            model_name: The name of the OpenAI model to use.
            temperature: Controls randomness in outputs. Lower values are more deterministic.
            max_tokens: Maximum number of tokens to generate.
            api_key: OpenAI API key. If None, it will be read from the OPENAI_API_KEY environment variable.
            base_url: Base URL for the OpenAI API. Useful for proxies or non-standard endpoints.
            **kwargs: Additional model-specific parameters.
        """
        super().__init__(model_name, temperature, max_tokens, **kwargs)
        
        if not OPENAI_AVAILABLE:
            logging.error("OpenAI package not installed. Please install it with 'pip install openai'.")
            raise ImportError("OpenAI package not installed")
        
        # Use provided API key or read from environment
        self.api_key = api_key or os.environ.get("OPENAI_API_KEY")
        if not self.api_key:
            logging.error("OpenAI API key not provided and not found in environment.")
            raise ValueError("OpenAI API key required")
        
        self.base_url = base_url
        
        # Initialize client
        self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)
        
        # Set default embedding model
        self.embedding_model = kwargs.get("embedding_model", "text-embedding-ada-002")
    
    def generate(
        self, 
        prompt: str, 
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """
        Generate text based on a prompt using OpenAI.
        
        Args:
            prompt: The text prompt for generation.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional OpenAI-specific parameters.
            
        Returns:
            The generated text response.
        """
        # Prepare messages
        messages = []
        
        # Add system message if provided
        if system_message:
            messages.append({"role": "system", "content": system_message})
        
        # Add user message
        messages.append({"role": "user", "content": prompt})
        
        # Set parameters
        temp = temperature if temperature is not None else self.temperature
        tokens = max_tokens if max_tokens is not None else self.max_tokens
        
        try:
            # Make the API call
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=temp,
                max_tokens=tokens,
                **kwargs
            )
            
            # Extract and return the response text
            return response.choices[0].message.content
        
        except Exception as e:
            logging.error(f"Error generating with OpenAI: {e}")
            return f"Error: {str(e)}"
    
    def generate_with_tools(
        self, 
        prompt: str, 
        tools: List[Dict[str, Any]],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Generate text with tool calling capabilities.
        
        Args:
            prompt: The text prompt for generation.
            tools: List of tool schemas available for use.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional OpenAI-specific parameters.
            
        Returns:
            A dictionary with the response and any tool calls.
        """
        # Prepare messages
        messages = []
        
        # Add system message if provided
        if system_message:
            messages.append({"role": "system", "content": system_message})
        
        # Add user message
        messages.append({"role": "user", "content": prompt})
        
        # Set parameters
        temp = temperature if temperature is not None else self.temperature
        tokens = max_tokens if max_tokens is not None else self.max_tokens
        
        # Convert tools to OpenAI format
        openai_tools = []
        for tool in tools:
            openai_tool = {
                "type": "function",
                "function": {
                    "name": tool.get("name", ""),
                    "description": tool.get("description", ""),
                    "parameters": tool.get("parameters", {})
                }
            }
            openai_tools.append(openai_tool)
        
        try:
            # Make the API call
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=temp,
                max_tokens=tokens,
                tools=openai_tools,
                **kwargs
            )
            
            # Extract response
            choice = response.choices[0]
            message = choice.message
            
            # Check for tool calls
            if hasattr(message, "tool_calls") and message.tool_calls:
                tool_calls = []
                for tool_call in message.tool_calls:
                    # Parse arguments as JSON
                    try:
                        arguments = json.loads(tool_call.function.arguments)
                    except:
                        arguments = tool_call.function.arguments
                    
                    # Create a normalized tool call
                    normalized_tool_call = {
                        "id": tool_call.id,
                        "name": tool_call.function.name,
                        "arguments": arguments
                    }
                    tool_calls.append(normalized_tool_call)
                
                return {
                    "content": message.content,
                    "tool_calls": tool_calls
                }
            else:
                # No tool calls, just text
                return {
                    "content": message.content,
                    "tool_calls": []
                }
        
        except Exception as e:
            logging.error(f"Error generating with tools using OpenAI: {e}")
            return {
                "content": f"Error: {str(e)}",
                "tool_calls": []
            }
    
    def extract_json(
        self, 
        prompt: str, 
        schema: Dict[str, Any],
        system_message: Optional[str] = None,
        temperature: Optional[float] = None,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Extract structured JSON data based on a prompt.
        
        Args:
            prompt: The text prompt for extraction.
            schema: JSON schema describing the expected structure.
            system_message: Optional system message for the model.
            temperature: Controls randomness in outputs. Overrides instance value if provided.
            max_tokens: Maximum number of tokens to generate. Overrides instance value if provided.
            **kwargs: Additional OpenAI-specific parameters.
            
        Returns:
            The extracted JSON data.
        """
        # Set default system message if not provided
        if not system_message:
            system_message = "Extract the requested information and respond only with a valid JSON object according to the specified schema. Do not include any other text."
        
        # Set parameters
        temp = temperature if temperature is not None else self.temperature
        tokens = max_tokens if max_tokens is not None else self.max_tokens
        
        # Make the API call with response format JSON
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": f"Schema: {json.dumps(schema)}\n\nPrompt: {prompt}"}
                ],
                temperature=temp,
                max_tokens=tokens,
                response_format={"type": "json_object"},
                **kwargs
            )
            
            # Extract and parse the response
            content = response.choices[0].message.content
            
            try:
                return json.loads(content)
            except json.JSONDecodeError:
                logging.error(f"Failed to parse JSON from response: {content}")
                return {"error": "Failed to parse JSON response"}
        
        except Exception as e:
            logging.error(f"Error extracting JSON with OpenAI: {e}")
            return {"error": str(e)}
    
    def get_embedding(self, text: str, **kwargs) -> List[float]:
        """
        Generate an embedding vector for the given text.
        
        Args:
            text: The text to embed.
            **kwargs: Additional OpenAI-specific parameters.
            
        Returns:
            The embedding vector as a list of floats.
        """
        try:
            response = self.client.embeddings.create(
                model=self.embedding_model,
                input=text,
                **kwargs
            )
            
            return response.data[0].embedding
        
        except Exception as e:
            logging.error(f"Error generating embedding with OpenAI: {e}")
            return []
```

## anus/agents/README.md

- Characters: 698
- Tokens: 0

```markdown
# Anus Agents Module

This module contains the agent system components of the Anus AI framework, including:

- Single-Agent Mode
- Multi-Agent Collaboration Mode
- Agent Role Definition Framework
- Inter-Agent Communication Protocol

## Components

### base_agent.py
Base class for all agent types with common functionality.

### single_agent.py
Simplified agent implementation for straightforward tasks.

### multi_agent.py
Implementation of multi-agent collaboration system.

### roles.py
Predefined agent role templates and custom role creation capabilities.

### communication.py
Inter-agent communication protocol and message handling.

### registry.py
Agent registration and discovery system.
```

## anus/ui/README.md

- Characters: 541
- Tokens: 0

```markdown
# Anus UI Module

This module contains the user interface components of the Anus AI framework, including:

- Command-Line Interface
- Web Interface (Optional)
- API for Integration with Other Systems

## Components

### cli.py
Command-line interface for interacting with the Anus AI agent.

### web_interface.py
Optional web-based user interface for the Anus AI agent.

### api.py
RESTful API for integration with external systems.

### utils.py
Utility functions for UI components.

### config.py
Configuration management for UI components.
```

## anus/ui/cli.py

- Characters: 12287
- Tokens: 0

```python
"""
Command-line interface for the ANUS framework.

Remember: With great ANUS comes great responsibility.
"""

import os
import sys
import time
import json
import logging
import cmd
import shutil
import random
from typing import Dict, List, Any, Optional, Union
from datetime import datetime

from anus.core.orchestrator import AgentOrchestrator

class CLI(cmd.Cmd):
    """
    Command-line interface for interacting with the ANUS framework.
    
    Provides commands for:
    - Executing tasks
    - Managing agents
    - Viewing task history
    - Configuration
    
    Warning: Prolonged exposure to ANUS may cause uncontrollable smirking.
    """
    
    intro = "Welcome to the ANUS framework. Type help or ? to list commands."
    prompt = "anus> "
    
    # Easter egg jokes for random display
    _anus_jokes = [
        "ANUS: Because 'Autonomous Networked Utility System' sounds better in meetings.",
        "ANUS: The backend system that handles all your crap.",
        "ANUS: Boldly going where no framework has gone before.",
        "ANUS: It's not a bug, it's a feature... a very uncomfortable feature.",
        "ANUS: For when your code needs that extra push from behind.",
        "ANUS: Working hard so you don't have to explain the acronym to your boss.",
        "ANUS: The framework that makes other developers snicker during code review.",
        "ANUS: Tight integration with your backend systems.",
        "ANUS: Because 'BUTT' was already taken as an acronym.",
        "ANUS: Making developers uncomfortable in stand-up meetings since 2023."
    ]
    
    def __init__(self, verbose: bool = False, config_path: str = "config.yaml"):
        """
        Initialize a CLI instance.
        
        Args:
            verbose: Whether to enable verbose output.
            config_path: Path to the configuration file.
        """
        super().__init__()
        self.verbose = verbose
        self.config_path = config_path
        self.orchestrator = None
        self.current_result = None
        self.history = []
        self.joke_counter = 0  # Track number of commands for occasional jokes
        
        # Set up logging
        log_level = logging.DEBUG if verbose else logging.INFO
        logging.basicConfig(
            level=log_level,
            format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
        )
    
    def display_welcome(self) -> None:
        """
        Display a welcome message.
        
        Includes a random ANUS joke to brighten your day.
        """
        term_width = shutil.get_terminal_size().columns
        
        print("=" * term_width)
        print("ANUS - Autonomous Networked Utility System".center(term_width))
        print("=" * term_width)
        print(random.choice(self._anus_jokes).center(term_width))
        print("=" * term_width)
        print("Type 'help' or '?' to list available commands.".center(term_width))
        print("=" * term_width)
        print()
    
    def start_interactive_mode(self, orchestrator: Optional[AgentOrchestrator] = None) -> None:
        """
        Start the interactive command-line interface.
        
        Args:
            orchestrator: Optional orchestrator instance. If not provided, one will be created.
        """
        if orchestrator:
            self.orchestrator = orchestrator
        else:
            self.orchestrator = AgentOrchestrator(config_path=self.config_path)
        
        # Display welcome message if not in stdin mode
        if sys.stdin.isatty():
            self.display_welcome()
        
        # Start the command loop
        self.cmdloop()
    
    def display_result(self, result: Dict[str, Any]) -> None:
        """
        Display the result of a task execution.
        
        Args:
            result: The task execution result.
        """
        self.current_result = result
        
        term_width = shutil.get_terminal_size().columns
        
        print("\n" + "=" * term_width)
        print("TASK RESULT".center(term_width))
        print("=" * term_width)
        
        # Display the task
        task = result.get("task", "Unknown task")
        print(f"Task: {task}")
        
        # Display the answer
        answer = result.get("answer", "No answer provided")
        print("\nAnswer:")
        print(f"{answer}")
        
        # Display additional information if verbose
        if self.verbose:
            print("\nExecution Details:")
            
            # Mode
            mode = result.get("mode", "single")
            print(f"Mode: {mode}")
            
            # Steps or iterations
            if "iterations" in result:
                iterations = result.get("iterations", 0)
                print(f"Iterations: {iterations}")
            elif "steps" in result:
                steps = len(result.get("steps", []))
                completed_steps = len(result.get("completed_steps", []))
                print(f"Steps: {completed_steps}/{steps} completed")
            
            # Display context or not based on verbosity
            if self.verbose and "context" in result:
                print("\nExecution Context:")
                self._pretty_print(result["context"])
        
        print("=" * term_width)
        
        # Occasionally show a joke after results
        self.joke_counter += 1
        if self.joke_counter % 3 == 0:  # Every 3rd result
            print(f"\nANUS Wisdom: {random.choice(self._anus_jokes)}")
    
    def do_task(self, arg: str) -> None:
        """
        Execute a task.
        
        Usage: task [mode] <task description>
        
        Args:
            arg: Task description and optional mode.
        """
        # Make sure orchestrator is initialized
        if not self.orchestrator:
            self.orchestrator = AgentOrchestrator(config_path=self.config_path)
        
        # Parse arguments
        parts = arg.strip().split(maxsplit=1)
        
        if len(parts) == 0 or not arg.strip():
            print("Error: Please provide a task description.")
            print("ANUS can't work with nothing. It needs substance.")
            return
        
        # Check if mode is specified
        mode = None
        task = arg.strip()
        
        if len(parts) > 1 and parts[0] in ["single", "multi", "auto"]:
            mode = parts[0]
            task = parts[1]
        
        # Execute the task
        print(f"Executing task: {task}")
        if mode:
            print(f"Mode: {mode}")
        
        if mode == "multi":
            print("Multiple agents engaged. ANUS is working from all directions...")
        
        try:
            result = self.orchestrator.execute_task(task, mode=mode)
            self.display_result(result)
            
            # Add to history
            self.history.append({
                "timestamp": time.time(),
                "task": task,
                "mode": mode,
                "result": result
            })
            
        except Exception as e:
            print(f"Error executing task: {e}")
            print("Even ANUS has its limits. Please try again.")
    
    def do_agents(self, arg: str) -> None:
        """
        List available agents.
        
        Usage: agents
        """
        # Make sure orchestrator is initialized
        if not self.orchestrator:
            self.orchestrator = AgentOrchestrator(config_path=self.config_path)
        
        agents = self.orchestrator.list_agents()
        
        if not agents:
            print("No agents available.")
            print("ANUS feels empty inside. Please add some agents.")
            return
        
        print("Available Agents:")
        print("-" * 40)
        
        for agent in agents:
            primary = agent.get("primary", False)
            prefix = "* " if primary else "  "
            print(f"{prefix}{agent.get('name', 'Unknown')} ({agent.get('type', 'Unknown')})")
            
            if self.verbose:
                print(f"   ID: {agent.get('id', 'Unknown')}")
            
            print()
            
        print(f"Total agents: {len(agents)}")
        if len(agents) > 5:
            print("Wow, that's a lot to fit in one ANUS!")
    
    def do_history(self, arg: str) -> None:
        """
        Show task execution history.
        
        Usage: history [limit]
        
        Args:
            arg: Optional limit on the number of history items to display.
        """
        # Parse arguments
        limit = 5
        if arg and arg.strip().isdigit():
            limit = int(arg.strip())
        
        # Get history from orchestrator if available
        if self.orchestrator:
            history = self.orchestrator.get_task_history(limit=limit)
        else:
            history = self.history[-limit:] if self.history else []
        
        if not history:
            print("No task history available.")
            print("ANUS is clean as a whistle. No history to report.")
            return
        
        print("Task History:")
        print("-" * 60)
        
        for i, entry in enumerate(reversed(history)):
            timestamp = entry.get("start_time", entry.get("timestamp", 0))
            dt = datetime.fromtimestamp(timestamp)
            task = entry.get("task", "Unknown task")
            mode = entry.get("mode", "single")
            status = entry.get("status", "completed")
            
            print(f"{i+1}. [{dt.strftime('%Y-%m-%d %H:%M:%S')}] ({mode}) {status}")
            print(f"   Task: {task}")
            
            # Show result summary if available
            if "result" in entry and "answer" in entry["result"]:
                answer = entry["result"]["answer"]
                summary = answer[:100] + "..." if len(answer) > 100 else answer
                print(f"   Answer: {summary}")
            
            print()
        
        print(f"Showing {min(len(history), limit)} of {len(history)} total entries.")
        if len(history) > 10:
            print("ANUS has been quite busy, hasn't it?")
    
    def do_config(self, arg: str) -> None:
        """
        Show current configuration.
        
        Usage: config
        """
        # Make sure orchestrator is initialized
        if not self.orchestrator:
            self.orchestrator = AgentOrchestrator(config_path=self.config_path)
        
        print(f"Configuration file: {self.config_path}")
        print("-" * 60)
        
        self._pretty_print(self.orchestrator.config)
        print("\nProTip: A well-configured ANUS is a happy ANUS.")
    
    def do_joke(self, arg: str) -> None:
        """
        Display a random ANUS joke.
        
        Usage: joke
        """
        joke = random.choice(self._anus_jokes)
        
        term_width = shutil.get_terminal_size().columns
        
        print()
        print("=" * term_width)
        print("ANUS WISDOM".center(term_width))
        print("=" * term_width)
        print(joke.center(term_width))
        print("=" * term_width)
        print()
    
    def do_exit(self, arg: str) -> bool:
        """
        Exit the application.
        
        Usage: exit
        """
        print("Exiting ANUS. We hope your experience wasn't too uncomfortable.")
        return True
    
    def do_quit(self, arg: str) -> bool:
        """
        Exit the application.
        
        Usage: quit
        """
        return self.do_exit(arg)
    
    def do_EOF(self, arg: str) -> bool:
        """
        Handle EOF (Ctrl+D).
        """
        print()  # Add a newline
        return self.do_exit(arg)
    
    def emptyline(self) -> None:
        """
        Handle empty lines in the CLI.
        """
        # 1 in 10 chance to show a joke on empty line
        if random.random() < 0.1:
            print(f"ANUS is waiting... {random.choice(self._anus_jokes)}")
    
    def _pretty_print(self, data: Any) -> None:
        """
        Pretty print data.
        
        Args:
            data: Data to print.
        """
        if isinstance(data, (dict, list)):
            try:
                print(json.dumps(data, indent=2))
            except Exception:
                print(data)
        else:
            print(data)
```

## anus/ui/__init__.py

- Characters: 168
- Tokens: 0

```python
"""
UI module for the ANUS framework.

This module contains user interface components:
- CLI: Command-line interface
"""

from anus.ui.cli import CLI

__all__ = ["CLI"]
```

## anus/core/README.md

- Characters: 809
- Tokens: 0

```markdown
# Anus Core Module

This module contains the core functionality of the Anus AI agent system, including:

- Agent Orchestration System
- Task Planning and Execution Framework
- Memory and Context Management
- Tool Integration Interface

## Components

### orchestrator.py
Manages the lifecycle of agents, handles agent creation, destruction, and resource allocation.

### planner.py
Breaks down complex tasks into manageable steps, assigns steps to appropriate agents or tools.

### memory.py
Maintains short-term and long-term memory, manages conversation history and context.

### tool_manager.py
Provides a standardized API for tool integration, tool discovery and registration system.

### config.py
Configuration management for the core module.

### utils.py
Utility functions used across the core module.
```

## anus/core/memory/long_term.py

- Characters: 10936
- Tokens: 0

```python
"""
Long-term memory module for the ANUS framework.
"""

from typing import Dict, List, Any, Optional, Union
import uuid
import time
import json
import os
import logging
from pathlib import Path

from anus.core.memory.base_memory import BaseMemory

class LongTermMemory(BaseMemory):
    """
    Persistent implementation of the BaseMemory interface.
    
    Provides a file-based persistent memory store.
    """
    
    def __init__(
        self, 
        storage_path: Optional[str] = None,
        index_in_memory: bool = True,
        **kwargs
    ):
        """
        Initialize a LongTermMemory instance.
        
        Args:
            storage_path: Path to store memory files. If None, uses a default location.
            index_in_memory: Whether to keep an in-memory index for faster searches.
            **kwargs: Additional configuration options.
        """
        super().__init__(**kwargs)
        
        # Set storage path
        if storage_path is None:
            home_dir = os.path.expanduser("~")
            storage_path = os.path.join(home_dir, ".anus", "memory")
        
        self.storage_path = storage_path
        self.index_in_memory = index_in_memory
        
        # Create storage directory if it doesn't exist
        os.makedirs(self.storage_path, exist_ok=True)
        
        # Create indexes
        self.index: Dict[str, Dict[str, Any]] = {}
        
        # Load index from disk if using in-memory indexing
        if self.index_in_memory:
            self._load_index()
    
    def add(self, item: Dict[str, Any]) -> str:
        """
        Add an item to memory and return its identifier.
        
        Args:
            item: The item to add to memory.
            
        Returns:
            A string identifier for the added item.
        """
        # Generate a unique identifier
        identifier = str(uuid.uuid4())
        
        # Add metadata
        item_with_metadata = item.copy()
        item_with_metadata["_meta"] = {
            "id": identifier,
            "created_at": time.time(),
            "updated_at": time.time()
        }
        
        # Save the item to disk
        self._save_item(identifier, item_with_metadata)
        
        # Update the index
        if self.index_in_memory:
            self.index[identifier] = item_with_metadata
        
        return identifier
    
    def get(self, identifier: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve an item from memory by its identifier.
        
        Args:
            identifier: The identifier of the item to retrieve.
            
        Returns:
            The retrieved item, or None if not found.
        """
        # Check in-memory index first if available
        if self.index_in_memory and identifier in self.index:
            return self.index[identifier]
        
        # Otherwise, load from disk
        item_path = self._get_item_path(identifier)
        if not os.path.exists(item_path):
            return None
        
        try:
            with open(item_path, "r") as f:
                return json.load(f)
        except Exception as e:
            logging.error(f"Error loading item {identifier}: {e}")
            return None
    
    def search(self, query: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:
        """
        Search memory for items matching the query.
        
        Args:
            query: The search query.
            limit: Maximum number of results to return.
            
        Returns:
            A list of matching items.
        """
        results = []
        
        # If using in-memory index, search there
        if self.index_in_memory:
            for identifier, item in self.index.items():
                if self._matches_query(item, query):
                    results.append({
                        "id": identifier,
                        "item": item,
                        "created_at": item.get("_meta", {}).get("created_at", 0)
                    })
                    
                    if len(results) >= limit:
                        break
        else:
            # Otherwise, scan the storage directory
            for item_file in os.listdir(self.storage_path):
                if not item_file.endswith(".json"):
                    continue
                
                identifier = item_file[:-5]  # Remove .json extension
                item = self.get(identifier)
                
                if item and self._matches_query(item, query):
                    results.append({
                        "id": identifier,
                        "item": item,
                        "created_at": item.get("_meta", {}).get("created_at", 0)
                    })
                    
                    if len(results) >= limit:
                        break
        
        # Sort by creation time (newest first)
        results.sort(key=lambda x: x["created_at"], reverse=True)
        
        return results
    
    def update(self, identifier: str, item: Dict[str, Any]) -> bool:
        """
        Update an item in memory.
        
        Args:
            identifier: The identifier of the item to update.
            item: The updated item.
            
        Returns:
            True if the update was successful, False otherwise.
        """
        # Check if the item exists
        existing_item = self.get(identifier)
        if existing_item is None:
            return False
        
        # Preserve metadata
        item_with_metadata = item.copy()
        if "_meta" in existing_item:
            item_with_metadata["_meta"] = existing_item["_meta"]
            item_with_metadata["_meta"]["updated_at"] = time.time()
        else:
            item_with_metadata["_meta"] = {
                "id": identifier,
                "created_at": time.time(),
                "updated_at": time.time()
            }
        
        # Save the updated item
        self._save_item(identifier, item_with_metadata)
        
        # Update the index
        if self.index_in_memory:
            self.index[identifier] = item_with_metadata
        
        return True
    
    def delete(self, identifier: str) -> bool:
        """
        Delete an item from memory.
        
        Args:
            identifier: The identifier of the item to delete.
            
        Returns:
            True if the deletion was successful, False otherwise.
        """
        item_path = self._get_item_path(identifier)
        if not os.path.exists(item_path):
            return False
        
        try:
            os.remove(item_path)
            
            # Update the index
            if self.index_in_memory and identifier in self.index:
                del self.index[identifier]
            
            return True
        except Exception as e:
            logging.error(f"Error deleting item {identifier}: {e}")
            return False
    
    def clear(self) -> None:
        """
        Clear all items from memory.
        """
        for item_file in os.listdir(self.storage_path):
            if not item_file.endswith(".json"):
                continue
            
            try:
                os.remove(os.path.join(self.storage_path, item_file))
            except Exception as e:
                logging.error(f"Error deleting file {item_file}: {e}")
        
        # Clear the index
        if self.index_in_memory:
            self.index = {}
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the memory system.
        
        Returns:
            A dictionary containing memory statistics.
        """
        # Count the number of items
        if self.index_in_memory:
            item_count = len(self.index)
        else:
            item_count = len([f for f in os.listdir(self.storage_path) if f.endswith(".json")])
        
        # Get the total size of all items
        total_size = sum(
            os.path.getsize(os.path.join(self.storage_path, f)) 
            for f in os.listdir(self.storage_path) 
            if os.path.isfile(os.path.join(self.storage_path, f)) and f.endswith(".json")
        )
        
        return {
            "type": "long_term",
            "storage_path": self.storage_path,
            "index_in_memory": self.index_in_memory,
            "item_count": item_count,
            "total_size_bytes": total_size
        }
    
    def _get_item_path(self, identifier: str) -> str:
        """
        Get the file path for an item.
        
        Args:
            identifier: The identifier of the item.
            
        Returns:
            The file path for the item.
        """
        return os.path.join(self.storage_path, f"{identifier}.json")
    
    def _save_item(self, identifier: str, item: Dict[str, Any]) -> None:
        """
        Save an item to disk.
        
        Args:
            identifier: The identifier of the item.
            item: The item to save.
        """
        item_path = self._get_item_path(identifier)
        
        try:
            with open(item_path, "w") as f:
                json.dump(item, f, indent=2)
        except Exception as e:
            logging.error(f"Error saving item {identifier}: {e}")
    
    def _load_index(self) -> None:
        """
        Load the index from disk.
        """
        self.index = {}
        
        for item_file in os.listdir(self.storage_path):
            if not item_file.endswith(".json"):
                continue
            
            identifier = item_file[:-5]  # Remove .json extension
            
            try:
                with open(os.path.join(self.storage_path, item_file), "r") as f:
                    item = json.load(f)
                    self.index[identifier] = item
            except Exception as e:
                logging.error(f"Error loading index for {identifier}: {e}")
    
    def _matches_query(self, item: Dict[str, Any], query: Dict[str, Any]) -> bool:
        """
        Check if an item matches a query.
        
        Args:
            item: The item to check.
            query: The query to match against.
            
        Returns:
            True if the item matches the query, False otherwise.
        """
        for key, value in query.items():
            # Handle nested keys with dot notation
            if "." in key:
                parts = key.split(".")
                curr = item
                for part in parts:
                    if isinstance(curr, dict) and part in curr:
                        curr = curr[part]
                    else:
                        return False
                
                if curr != value:
                    return False
            # Handle simple keys
            elif key not in item or item[key] != value:
                return False
        
        return True
```

## anus/core/memory/__init__.py

- Characters: 507
- Tokens: 0

```python
"""
Memory module for the ANUS framework.

This module contains various memory implementations:
- BaseMemory: Abstract base class for all memory systems
- ShortTermMemory: Volatile in-memory storage with LRU eviction
- LongTermMemory: Persistent storage backed by a file system
"""

from anus.core.memory.base_memory import BaseMemory
from anus.core.memory.short_term import ShortTermMemory
from anus.core.memory.long_term import LongTermMemory

__all__ = ["BaseMemory", "ShortTermMemory", "LongTermMemory"]
```

## anus/core/memory/short_term.py

- Characters: 10413
- Tokens: 0

```python
"""
Short-term memory module for the ANUS framework.

Because even an ANUS needs to remember what it just processed.
"""

from typing import Dict, List, Any, Optional, Union
import uuid
import time
import heapq
import logging
import random

from anus.core.memory.base_memory import BaseMemory

class ShortTermMemory(BaseMemory):
    """
    In-memory implementation of the BaseMemory interface.
    
    Provides a volatile memory store with automatic pruning of old items.
    
    Just like the human ANUS, it's good at handling recent input but tends to 
    forget older stuff if not regularly refreshed.
    """
    
    # Funny memory-related messages
    _memory_messages = [
        "ANUS short-term memory retaining item...",
        "Storing this for quick retrieval from your ANUS...",
        "This item is now tightly held in ANUS memory...",
        "Squeezing this into ANUS short-term storage...",
        "ANUS will remember this, at least for a little while..."
    ]
    
    def __init__(
        self, 
        capacity: int = 1000, 
        ttl: int = 3600,  # Time to live in seconds
        **kwargs
    ):
        """
        Initialize a ShortTermMemory instance.
        
        Args:
            capacity: Maximum number of items to store.
            ttl: Time to live for items in seconds.
            **kwargs: Additional configuration options.
        """
        super().__init__(**kwargs)
        self.capacity = capacity
        self.ttl = ttl
        self.items: Dict[str, Dict[str, Any]] = {}
        self.access_times: Dict[str, float] = {}
        self.creation_times: Dict[str, float] = {}
        self.lru_queue: List[tuple] = []  # Priority queue for LRU eviction
        
        if capacity < 100:
            logging.warning(f"ANUS short-term memory capacity of {capacity} is quite small. Performance may suffer.")
        elif capacity > 10000:
            logging.warning(f"ANUS short-term memory capacity of {capacity} is unusually large. Hope you have enough RAM!")
        
        logging.info(f"ANUS short-term memory initialized with capacity for {capacity} items and {ttl}s retention")
    
    def add(self, item: Dict[str, Any]) -> str:
        """
        Add an item to memory and return its identifier.
        
        If the memory is at capacity, the least recently used item will be evicted.
        
        Args:
            item: The item to add to memory.
            
        Returns:
            A string identifier for the added item.
        """
        # Prune expired items
        self._prune_expired()
        
        # Generate a unique identifier
        identifier = str(uuid.uuid4())
        
        # Add the item
        self.items[identifier] = item
        current_time = time.time()
        self.access_times[identifier] = current_time
        self.creation_times[identifier] = current_time
        
        # Add to LRU queue
        heapq.heappush(self.lru_queue, (current_time, identifier))
        
        # Check capacity and evict if necessary
        if len(self.items) > self.capacity:
            self._evict_lru()
            
        # 5% chance to log a funny memory message
        if random.random() < 0.05:
            logging.debug(random.choice(self._memory_messages))
            
        # Log capacity status if getting full
        capacity_pct = len(self.items) / self.capacity * 100
        if capacity_pct > 90:
            logging.warning(f"ANUS short-term memory is {capacity_pct:.1f}% full. Starting to feel tight in here!")
        
        return identifier
    
    def get(self, identifier: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve an item from memory by its identifier.
        
        Updates the access time of the item to prevent it from being evicted.
        
        Args:
            identifier: The identifier of the item to retrieve.
            
        Returns:
            The retrieved item, or None if not found.
        """
        # Prune expired items
        self._prune_expired()
        
        # Check if the item exists
        if identifier not in self.items:
            logging.debug(f"ANUS has no recollection of item {identifier[:8]}...")
            return None
        
        # Update access time
        self.access_times[identifier] = time.time()
        
        # Return the item
        logging.debug(f"ANUS recalls this item perfectly!")
        return self.items[identifier]
    
    def search(self, query: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:
        """
        Search memory for items matching the query.
        
        Simple implementation that checks for exact matches on query fields.
        
        Args:
            query: The search query.
            limit: Maximum number of results to return.
            
        Returns:
            A list of matching items.
        """
        # Prune expired items
        self._prune_expired()
        
        logging.debug(f"ANUS is probing deeply for matching items...")
        
        results = []
        
        for identifier, item in self.items.items():
            # Check if all query fields match
            is_match = True
            for key, value in query.items():
                if key not in item or item[key] != value:
                    is_match = False
                    break
            
            if is_match:
                # Update access time
                self.access_times[identifier] = time.time()
                
                # Add to results
                results.append({
                    "id": identifier,
                    "item": item,
                    "created_at": self.creation_times[identifier]
                })
                
                # Check limit
                if len(results) >= limit:
                    break
        
        # Sort by recency
        results.sort(key=lambda x: x["created_at"], reverse=True)
        
        if not results:
            logging.debug("ANUS found nothing that matches. How disappointing.")
        else:
            logging.debug(f"ANUS successfully extracted {len(results)} matching items!")
        
        return results
    
    def update(self, identifier: str, item: Dict[str, Any]) -> bool:
        """
        Update an item in memory.
        
        Args:
            identifier: The identifier of the item to update.
            item: The updated item.
            
        Returns:
            True if the update was successful, False otherwise.
        """
        # Prune expired items
        self._prune_expired()
        
        # Check if the item exists
        if identifier not in self.items:
            logging.debug(f"ANUS can't update what it doesn't have (identifier: {identifier[:8]})")
            return False
        
        # Update the item
        self.items[identifier] = item
        
        # Update access time
        self.access_times[identifier] = time.time()
        
        logging.debug(f"ANUS memory successfully updated with fresh content")
        return True
    
    def delete(self, identifier: str) -> bool:
        """
        Delete an item from memory.
        
        Args:
            identifier: The identifier of the item to delete.
            
        Returns:
            True if the deletion was successful, False otherwise.
        """
        # Check if the item exists
        if identifier not in self.items:
            return False
        
        # Delete the item
        del self.items[identifier]
        del self.access_times[identifier]
        del self.creation_times[identifier]
        
        # Note: The item will remain in the LRU queue, but will be skipped when it's popped
        
        logging.debug(f"ANUS has purged this item from its memory")
        return True
    
    def clear(self) -> None:
        """
        Clear all items from memory.
        """
        old_count = len(self.items)
        self.items = {}
        self.access_times = {}
        self.creation_times = {}
        self.lru_queue = []
        
        logging.info(f"ANUS memory has been completely flushed of {old_count} items. Fresh and clean!")
    
    def get_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the memory system.
        
        Returns:
            A dictionary containing memory statistics.
        """
        utilization = len(self.items) / self.capacity if self.capacity > 0 else 0
        
        # Add a funny message based on utilization
        if utilization > 0.9:
            status = "ANUS memory is nearly full! Things are getting tight in here."
        elif utilization > 0.7:
            status = "ANUS memory is filling up nicely."
        elif utilization > 0.4:
            status = "ANUS memory has plenty of room for more."
        else:
            status = "ANUS memory is mostly empty. Feed me more data!"
            
        return {
            "type": "short_term",
            "capacity": self.capacity,
            "ttl": self.ttl,
            "current_size": len(self.items),
            "utilization": utilization,
            "status": status
        }
    
    def _prune_expired(self) -> None:
        """
        Remove items that have exceeded their time to live.
        """
        current_time = time.time()
        expired_identifiers = []
        
        for identifier, creation_time in self.creation_times.items():
            if current_time - creation_time > self.ttl:
                expired_identifiers.append(identifier)
        
        if expired_identifiers:
            for identifier in expired_identifiers:
                self.delete(identifier)
            
            logging.debug(f"ANUS has expelled {len(expired_identifiers)} expired items from memory")
    
    def _evict_lru(self) -> None:
        """
        Evict the least recently used item from memory.
        """
        while self.lru_queue:
            _, identifier = heapq.heappop(self.lru_queue)
            
            # Skip if the item has been deleted
            if identifier not in self.items:
                continue
            
            # Delete the item
            item_name = self.items[identifier].get("name", "unknown")
            self.delete(identifier)
            logging.debug(f"ANUS had to push out '{item_name}' to make room for new content")
            break
```

## anus/core/memory/base_memory.py

- Characters: 2725
- Tokens: 0

```python
"""
Base Memory module that defines the common interface for memory systems.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional, Union

class BaseMemory(ABC):
    """
    Abstract base class for memory systems in the ANUS framework.
    
    Provides the core functionality and interface that all memory types must implement.
    """
    
    def __init__(self, **kwargs):
        """
        Initialize a BaseMemory instance.
        
        Args:
            **kwargs: Additional configuration options for the memory system.
        """
        self.config = kwargs
    
    @abstractmethod
    def add(self, item: Dict[str, Any]) -> str:
        """
        Add an item to memory and return its identifier.
        
        Args:
            item: The item to add to memory.
            
        Returns:
            A string identifier for the added item.
        """
        pass
    
    @abstractmethod
    def get(self, identifier: str) -> Optional[Dict[str, Any]]:
        """
        Retrieve an item from memory by its identifier.
        
        Args:
            identifier: The identifier of the item to retrieve.
            
        Returns:
            The retrieved item, or None if not found.
        """
        pass
    
    @abstractmethod
    def search(self, query: Dict[str, Any], limit: int = 10) -> List[Dict[str, Any]]:
        """
        Search memory for items matching the query.
        
        Args:
            query: The search query.
            limit: Maximum number of results to return.
            
        Returns:
            A list of matching items.
        """
        pass
    
    @abstractmethod
    def update(self, identifier: str, item: Dict[str, Any]) -> bool:
        """
        Update an item in memory.
        
        Args:
            identifier: The identifier of the item to update.
            item: The updated item.
            
        Returns:
            True if the update was successful, False otherwise.
        """
        pass
    
    @abstractmethod
    def delete(self, identifier: str) -> bool:
        """
        Delete an item from memory.
        
        Args:
            identifier: The identifier of the item to delete.
            
        Returns:
            True if the deletion was successful, False otherwise.
        """
        pass
    
    @abstractmethod
    def clear(self) -> None:
        """
        Clear all items from memory.
        """
        pass
    
    @abstractmethod
    def get_stats(self) -> Dict[str, Any]:
        """
        Get statistics about the memory system.
        
        Returns:
            A dictionary containing memory statistics.
        """
        pass
```

## anus/core/orchestrator.py

- Characters: 14325
- Tokens: 0

```python
"""
Orchestrator module for the ANUS framework.

This module contains the agent orchestration system that manages agent 
lifecycle and coordinates task execution across multiple agents.

Behind every successful ANUS is a well-designed Orchestrator.
"""

from typing import Dict, List, Any, Optional, Union
import logging
import yaml
import os
import time
import random

from anus.core.agent import BaseAgent, HybridAgent
from anus.core.memory import ShortTermMemory, LongTermMemory

# Create a custom logger for ANUS-specific wisdom
class ANUSLogger(logging.Logger):
    """Custom logger that occasionally adds ANUS wisdom to log messages."""
    
    _wisdom = [
        "ANUS Wisdom: Always test your backend thoroughly before deployment.",
        "ANUS Wisdom: Sometimes a little push from behind is all you need.",
        "ANUS Wisdom: Keep your interfaces clean and well-documented.",
        "ANUS Wisdom: A tight architecture prevents unwanted leakage.",
        "ANUS Wisdom: Even the backend deserves some love and attention."
    ]
    
    def info(self, msg, *args, **kwargs):
        if random.random() < 0.1:  # 10% chance
            msg = f"{msg} - {random.choice(self._wisdom)}"
        super().info(msg, *args, **kwargs)
    
    def debug(self, msg, *args, **kwargs):
        if random.random() < 0.2:  # 20% chance
            msg = f"{msg} - {random.choice(self._wisdom)}"
        super().debug(msg, *args, **kwargs)

# Register our custom logger
logging.setLoggerClass(ANUSLogger)
logger = logging.getLogger("anus.orchestrator")

class AgentOrchestrator:
    """
    Coordinates multiple agents and manages their lifecycle.
    
    This class is responsible for:
    - Loading configuration
    - Creating and initializing agents
    - Routing tasks to appropriate agents
    - Managing agent resources
    - Collecting and aggregating results
    
    Remember: A well-lubricated ANUS runs smoothly without friction.
    """
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        Initialize an AgentOrchestrator instance.
        
        Args:
            config_path: Path to the configuration file.
        """
        self.config = self._load_config(config_path)
        self.agents: Dict[str, BaseAgent] = {}
        self.primary_agent = self._create_primary_agent()
        self.last_result: Dict[str, Any] = {}
        self.task_history: List[Dict[str, Any]] = []
        
        # Easter eggs for internal task names
        self._easter_egg_tasks = {
            "status": "Performing deep ANUS inspection...",
            "health": "Checking if ANUS is functioning properly...",
            "clean": "Flushing old data from ANUS...",
            "optimize": "Making ANUS more responsive and flexible...",
            "expand": "Expanding ANUS capabilities..."
        }
        
        logger.info("ANUS Orchestrator initialized and ready for action")
    
    def execute_task(self, task: str, mode: Optional[str] = None) -> Dict[str, Any]:
        """
        Execute a task using an appropriate agent.
        
        Args:
            task: The task description to execute.
            mode: Execution mode ("single" or "multi"). If None, uses the config default.
            
        Returns:
            The execution result.
        """
        # Use config default if mode not specified
        if mode is None:
            mode = self.config.get("agent", {}).get("mode", "single")
        
        start_time = time.time()
        
        # Check for easter egg task names
        display_task = task
        for keyword, message in self._easter_egg_tasks.items():
            if keyword.lower() in task.lower().split():
                display_task = message
                logger.info(f"Easter egg activated: {message}")
                break
        
        # Log the task
        if mode == "multi":
            logger.info(f"ANUS expanding to handle multiple agents for task: {display_task}")
        else:
            logger.info(f"ANUS processing task: {display_task}")
        
        # Execute the task with the primary agent
        result = self.primary_agent.execute(task, mode=mode)
        
        # Record execution time
        execution_time = time.time() - start_time
        
        # Create a task record
        task_record = {
            "task": task,
            "mode": mode,
            "start_time": start_time,
            "execution_time": execution_time,
            "status": "completed",
            "result": result
        }
        
        # Add to task history
        self.task_history.append(task_record)
        
        # Update last result
        self.last_result = result
        
        # Log completion
        if execution_time > 10:
            logger.info(f"ANUS finished after {execution_time:.2f}s - that was quite a workout!")
        else:
            logger.info(f"ANUS completed task in {execution_time:.2f}s")
        
        return result
    
    def list_agents(self) -> List[Dict[str, Any]]:
        """
        List all registered agents.
        
        Returns:
            A list of agent descriptions.
        """
        agent_list = []
        
        # Add primary agent
        agent_list.append({
            "id": self.primary_agent.id,
            "name": self.primary_agent.name,
            "type": type(self.primary_agent).__name__,
            "primary": True
        })
        
        # Add other agents
        for name, agent in self.agents.items():
            if agent.id != self.primary_agent.id:
                agent_list.append({
                    "id": agent.id,
                    "name": agent.name,
                    "type": type(agent).__name__,
                    "primary": False
                })
        
        if len(agent_list) > 3:
            logger.debug(f"ANUS is quite full with {len(agent_list)} agents inside")
        
        return agent_list
    
    def get_task_history(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get the history of executed tasks.
        
        Args:
            limit: Maximum number of history items to return.
            
        Returns:
            A list of task history records.
        """
        if limit > 50:
            logger.warning(f"Requesting {limit} history items? That's a deep dive into ANUS history!")
        
        return self.task_history[-limit:]
    
    def get_last_result(self) -> Dict[str, Any]:
        """
        Get the result of the last executed task.
        
        Returns:
            The last execution result.
        """
        return self.last_result
    
    def _load_config(self, config_path: str) -> Dict[str, Any]:
        """
        Load configuration from a YAML file.
        
        Args:
            config_path: Path to the configuration file.
            
        Returns:
            The loaded configuration.
        """
        # Default configuration
        default_config = {
            "agent": {
                "name": "anus",
                "mode": "single",
                "max_iterations": 10,
                "complexity_threshold": 7
            },
            "memory": {
                "short_term": {
                    "capacity": 1000,
                    "ttl": 3600
                },
                "long_term": {
                    "enabled": True,
                    "storage_path": None,
                    "index_in_memory": True
                }
            },
            "models": {
                "default": {
                    "provider": "openai",
                    "model": "gpt-4",
                    "temperature": 0.0
                }
            },
            "tools": {
                "enabled": []
            }
        }
        
        # Check if config file exists
        if not os.path.exists(config_path):
            logger.warning(f"Config file {config_path} not found. Using default configuration.")
            logger.info("ANUS is running with default settings. It might be a tight fit for complex tasks.")
            return default_config
        
        try:
            # Load the config file
            with open(config_path, "r") as f:
                config = yaml.safe_load(f)
            
            # Merge with default config
            merged_config = self._merge_configs(default_config, config)
            
            logger.info("ANUS configuration loaded successfully")
            if merged_config.get("agent", {}).get("mode") == "multi":
                logger.info("ANUS is configured for multi-agent mode - it's going to get crowded in there!")
            
            return merged_config
        except Exception as e:
            logger.error(f"Error loading config file: {e}")
            logger.info("ANUS reverted to default configuration. Performance may not be optimal.")
            return default_config
    
    def _merge_configs(self, default: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
        """
        Merge two configuration dictionaries.
        
        Args:
            default: Default configuration.
            override: Override configuration.
            
        Returns:
            The merged configuration.
        """
        result = default.copy()
        
        for key, value in override.items():
            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
                result[key] = self._merge_configs(result[key], value)
            else:
                result[key] = value
        
        return result
    
    def _create_primary_agent(self) -> HybridAgent:
        """
        Create the primary agent based on configuration.
        
        Returns:
            A HybridAgent instance.
        """
        # Get agent config
        agent_config = self.config.get("agent", {})
        name = agent_config.get("name", "anus")
        mode = agent_config.get("mode", "single")
        max_iterations = agent_config.get("max_iterations", 10)
        complexity_threshold = agent_config.get("complexity_threshold", 7)
        
        # Get tools config
        tools_config = self.config.get("tools", {})
        enabled_tools = tools_config.get("enabled", [])
        
        # Create memories
        short_term_memory = self._create_short_term_memory()
        long_term_memory = self._create_long_term_memory()
        
        # Create the agent
        agent = HybridAgent(
            name=name,
            max_iterations=max_iterations,
            tools=enabled_tools,
            mode=mode,
            complexity_threshold=complexity_threshold,
            short_term_memory=short_term_memory,
            long_term_memory=long_term_memory
        )
        
        logger.info(f"Primary agent created. ANUS is ready with {len(enabled_tools)} tools available")
        
        # Create specialized agents if in multi mode
        if mode == "multi" or mode == "auto":
            self._create_specialized_agents(agent)
            logger.info("Multiple specialized agents have been inserted into ANUS")
        
        # Register the agent
        self.agents[name] = agent
        
        return agent
    
    def _create_short_term_memory(self) -> ShortTermMemory:
        """
        Create a short-term memory instance based on configuration.
        
        Returns:
            A ShortTermMemory instance.
        """
        memory_config = self.config.get("memory", {}).get("short_term", {})
        capacity = memory_config.get("capacity", 1000)
        ttl = memory_config.get("ttl", 3600)
        
        logger.debug(f"Initializing ANUS short-term memory with capacity {capacity}")
        return ShortTermMemory(capacity=capacity, ttl=ttl)
    
    def _create_long_term_memory(self) -> Optional[LongTermMemory]:
        """
        Create a long-term memory instance based on configuration.
        
        Returns:
            A LongTermMemory instance, or None if disabled.
        """
        memory_config = self.config.get("memory", {}).get("long_term", {})
        enabled = memory_config.get("enabled", True)
        
        if not enabled:
            logger.info("Long-term memory disabled. ANUS will forget everything after each session.")
            return None
        
        storage_path = memory_config.get("storage_path")
        index_in_memory = memory_config.get("index_in_memory", True)
        
        if storage_path:
            logger.debug(f"ANUS will store long-term memories at: {storage_path}")
        else:
            logger.debug("ANUS will store long-term memories in the default location")
        
        return LongTermMemory(storage_path=storage_path, index_in_memory=index_in_memory)
    
    def _create_specialized_agents(self, primary_agent: HybridAgent) -> None:
        """
        Create specialized agents for multi-agent mode.
        
        Args:
            primary_agent: The primary HybridAgent instance.
        """
        # Default specialized agent roles
        default_roles = ["researcher", "planner", "executor", "critic"]
        
        # Get specialized agent configurations
        specialized_config = self.config.get("specialized_agents", {})
        roles = specialized_config.get("roles", default_roles)
        
        # Create each specialized agent
        for role in roles:
            role_config = specialized_config.get(role, {})
            
            # Default configuration for the role
            default_role_config = {
                "name": f"{role}-agent",
                "max_iterations": primary_agent.max_iterations,
                "tools": self.config.get("tools", {}).get("enabled", [])
            }
            
            # Merge with role-specific config
            merged_config = self._merge_configs(default_role_config, role_config)
            
            # Add to the primary agent
            primary_agent.add_specialized_agent(role, merged_config)
            
            logger.debug(f"Added {role} agent to ANUS")
        
        logger.info(f"ANUS now contains {len(roles)} specialized agents working together harmoniously")
        if len(roles) > 5:
            logger.warning("That's a lot of agents to fit inside one ANUS. Performance may be affected.")
```

## anus/core/planning/task_planner.py

- Characters: 15272
- Tokens: 0

```python
"""
Task Planner module for LLM-based task planning.
"""

import uuid
import time
import json
import logging
from typing import Dict, List, Any, Optional, Union

from anus.core.planning.base_planner import BasePlanner
from anus.models.base.base_model import BaseModel

class TaskPlanner(BasePlanner):
    """
    A planner that uses language models to create and manage task plans.
    
    Implements task breakdown, dependency tracking, and adaptive replanning.
    """
    
    def __init__(self, model: BaseModel, **kwargs):
        """
        Initialize a TaskPlanner instance.
        
        Args:
            model: The language model to use for planning.
            **kwargs: Additional configuration options for the planner.
        """
        super().__init__(**kwargs)
        self.model = model
        self.max_steps = kwargs.get("max_steps", 10)
    
    def create_plan(self, task: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Create a plan for executing a task using the language model.
        
        Args:
            task: The task description.
            context: Optional context for planning.
            
        Returns:
            A plan dictionary with steps and metadata.
        """
        context = context or {}
        
        # Prepare the planning prompt
        prompt = self._create_planning_prompt(task, context)
        
        # Extract JSON schema for the plan
        plan_schema = {
            "type": "object",
            "properties": {
                "steps": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "string"},
                            "name": {"type": "string"},
                            "description": {"type": "string"},
                            "tool": {"type": "string"},
                            "tool_input": {"type": "object"},
                            "expected_output": {"type": "string"},
                            "dependencies": {
                                "type": "array",
                                "items": {"type": "string"}
                            }
                        },
                        "required": ["name", "description", "tool"]
                    }
                },
                "reasoning": {"type": "string"},
                "estimated_steps": {"type": "integer"}
            },
            "required": ["steps", "reasoning"]
        }
        
        # Generate the plan using the model
        try:
            plan_data = self.model.extract_json(
                prompt=prompt,
                schema=plan_schema,
                system_message="You are a task planning assistant. Break down tasks into logical steps."
            )
            
            # Process the plan data
            return self._process_plan_data(task, plan_data)
            
        except Exception as e:
            logging.error(f"Error creating plan: {e}")
            # Return a minimal plan
            return {
                "id": str(uuid.uuid4()),
                "task": task,
                "status": "error",
                "error": str(e),
                "created_at": time.time(),
                "steps": [],
                "reasoning": "Error generating plan",
                "current_step_index": 0,
                "completed_steps": [],
                "metadata": {"context": context}
            }
    
    def replan(self, plan: Dict[str, Any], feedback: Dict[str, Any]) -> Dict[str, Any]:
        """
        Update a plan based on execution feedback.
        
        Args:
            plan: The current plan.
            feedback: Feedback from execution.
            
        Returns:
            The updated plan.
        """
        # Extract current plan state
        task = plan.get("task", "")
        completed_steps = plan.get("completed_steps", [])
        remaining_steps = self._get_remaining_steps(plan)
        
        # Prepare the replanning prompt
        prompt = self._create_replanning_prompt(task, plan, feedback)
        
        # Extract JSON schema for the updated plan
        plan_schema = {
            "type": "object",
            "properties": {
                "steps": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "id": {"type": "string"},
                            "name": {"type": "string"},
                            "description": {"type": "string"},
                            "tool": {"type": "string"},
                            "tool_input": {"type": "object"},
                            "expected_output": {"type": "string"},
                            "dependencies": {
                                "type": "array",
                                "items": {"type": "string"}
                            }
                        },
                        "required": ["name", "description", "tool"]
                    }
                },
                "reasoning": {"type": "string"}
            },
            "required": ["steps", "reasoning"]
        }
        
        try:
            # Generate the updated plan
            updated_plan_data = self.model.extract_json(
                prompt=prompt,
                schema=plan_schema,
                system_message="You are a task planning assistant. Revise plans based on feedback."
            )
            
            # Merge the updated plan with the original plan
            updated_plan = plan.copy()
            updated_plan["steps"] = completed_steps + updated_plan_data.get("steps", [])
            updated_plan["reasoning"] = updated_plan_data.get("reasoning", "Plan updated based on feedback")
            updated_plan["updated_at"] = time.time()
            updated_plan["status"] = "updated"
            
            # Keep the current step index
            if len(completed_steps) < len(updated_plan["steps"]):
                updated_plan["current_step_index"] = len(completed_steps)
            else:
                updated_plan["current_step_index"] = 0
            
            # Add feedback to metadata
            if "metadata" not in updated_plan:
                updated_plan["metadata"] = {}
            updated_plan["metadata"]["feedback"] = feedback
            
            return updated_plan
            
        except Exception as e:
            logging.error(f"Error replanning: {e}")
            # Return the original plan with an error flag
            plan["status"] = "error"
            plan["error"] = str(e)
            return plan
    
    def get_next_step(self, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Get the next step to execute from a plan.
        
        Args:
            plan: The current plan.
            
        Returns:
            The next step to execute, or None if the plan is complete.
        """
        steps = plan.get("steps", [])
        current_index = plan.get("current_step_index", 0)
        
        # Check if we've completed all steps
        if current_index >= len(steps):
            return None
        
        # Get the next step
        next_step = steps[current_index]
        
        # Check dependencies
        if "dependencies" in next_step and next_step["dependencies"]:
            completed_step_ids = [step.get("id") for step in plan.get("completed_steps", [])]
            
            # Check if all dependencies are satisfied
            for dep_id in next_step["dependencies"]:
                if dep_id not in completed_step_ids:
                    # Dependency not satisfied, try to find an alternative step
                    alt_step = self._find_executable_step(plan)
                    if alt_step:
                        return alt_step
                    else:
                        # Can't proceed, need replanning
                        logging.warning(f"Can't execute step {next_step.get('id')}: unsatisfied dependencies")
                        return None
        
        return next_step
    
    def mark_step_complete(self, plan: Dict[str, Any], step_id: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Mark a step as complete in a plan.
        
        Args:
            plan: The current plan.
            step_id: The ID of the completed step.
            result: The result of the step execution.
            
        Returns:
            The updated plan.
        """
        updated_plan = plan.copy()
        steps = updated_plan.get("steps", [])
        current_index = updated_plan.get("current_step_index", 0)
        
        # Find the step
        step_index = -1
        for i, step in enumerate(steps):
            if step.get("id") == step_id:
                step_index = i
                break
        
        if step_index == -1:
            logging.warning(f"Step {step_id} not found in plan")
            return plan
        
        # Update the step with result
        completed_step = steps[step_index].copy()
        completed_step["result"] = result
        completed_step["completed_at"] = time.time()
        
        # Add to completed steps
        if "completed_steps" not in updated_plan:
            updated_plan["completed_steps"] = []
        updated_plan["completed_steps"].append(completed_step)
        
        # Update current step index
        if step_index == current_index:
            updated_plan["current_step_index"] = current_index + 1
        
        # Check if plan is complete
        if updated_plan["current_step_index"] >= len(steps):
            updated_plan["status"] = "completed"
            updated_plan["completed_at"] = time.time()
        
        return updated_plan
    
    def _create_planning_prompt(self, task: str, context: Dict[str, Any]) -> str:
        """
        Create a prompt for generating a plan.
        
        Args:
            task: The task description.
            context: Context information.
            
        Returns:
            A prompt string.
        """
        prompt = f"""
Task: {task}

I need a detailed plan to accomplish this task. Please break it down into specific steps.

For each step, include:
1. A clear name and description
2. The tool required (e.g., web_search, file_read, code_execution)
3. The expected input for the tool
4. Any dependencies on previous steps

Context information:
{json.dumps(context, indent=2)}

Please provide a structured plan with no more than {self.max_steps} steps.
"""
        return prompt
    
    def _create_replanning_prompt(self, task: str, plan: Dict[str, Any], feedback: Dict[str, Any]) -> str:
        """
        Create a prompt for replanning.
        
        Args:
            task: The task description.
            plan: The current plan.
            feedback: Feedback from execution.
            
        Returns:
            A prompt string.
        """
        # Extract completed steps
        completed_steps = plan.get("completed_steps", [])
        completed_steps_text = ""
        for i, step in enumerate(completed_steps):
            result = step.get("result", {})
            result_status = result.get("status", "unknown")
            result_summary = str(result.get("result", "No result"))[:100] + "..." if len(str(result.get("result", ""))) > 100 else str(result.get("result", "No result"))
            
            completed_steps_text += f"{i+1}. {step.get('name', 'Step')}: {result_status} - {result_summary}\n"
        
        # Extract remaining steps
        remaining_steps = self._get_remaining_steps(plan)
        remaining_steps_text = ""
        for i, step in enumerate(remaining_steps):
            remaining_steps_text += f"{i+1}. {step.get('name', 'Step')}: {step.get('description', 'No description')}\n"
        
        prompt = f"""
Task: {task}

I need to revise my plan based on execution feedback. 

Completed steps:
{completed_steps_text}

Current feedback:
{json.dumps(feedback, indent=2)}

Current remaining steps:
{remaining_steps_text}

Please provide an updated plan for the remaining steps, considering the feedback and results from completed steps.
"""
        return prompt
    
    def _process_plan_data(self, task: str, plan_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Process raw plan data into a structured plan.
        
        Args:
            task: The task description.
            plan_data: Raw plan data from the model.
            
        Returns:
            A structured plan dictionary.
        """
        steps = plan_data.get("steps", [])
        
        # Ensure each step has an ID and required fields
        for i, step in enumerate(steps):
            if "id" not in step:
                step["id"] = f"step-{i+1}-{str(uuid.uuid4())[:8]}"
            
            if "tool_input" not in step:
                step["tool_input"] = {}
            
            if "dependencies" not in step:
                step["dependencies"] = []
        
        # Create the plan structure
        plan = {
            "id": str(uuid.uuid4()),
            "task": task,
            "status": "created",
            "created_at": time.time(),
            "steps": steps,
            "reasoning": plan_data.get("reasoning", ""),
            "current_step_index": 0,
            "completed_steps": [],
            "metadata": {
                "estimated_steps": plan_data.get("estimated_steps", len(steps))
            }
        }
        
        return plan
    
    def _get_remaining_steps(self, plan: Dict[str, Any]) -> List[Dict[str, Any]]:
        """
        Get the remaining steps from a plan.
        
        Args:
            plan: The current plan.
            
        Returns:
            A list of remaining steps.
        """
        steps = plan.get("steps", [])
        current_index = plan.get("current_step_index", 0)
        
        if current_index >= len(steps):
            return []
        
        return steps[current_index:]
    
    def _find_executable_step(self, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Find a step that can be executed (all dependencies satisfied).
        
        Args:
            plan: The current plan.
            
        Returns:
            An executable step, or None if none found.
        """
        steps = plan.get("steps", [])
        current_index = plan.get("current_step_index", 0)
        completed_step_ids = [step.get("id") for step in plan.get("completed_steps", [])]
        
        # Look for steps after the current index
        for i in range(current_index, len(steps)):
            step = steps[i]
            dependencies = step.get("dependencies", [])
            
            # Check if all dependencies are satisfied
            dependencies_satisfied = True
            for dep_id in dependencies:
                if dep_id not in completed_step_ids:
                    dependencies_satisfied = False
                    break
            
            if dependencies_satisfied:
                return step
        
        return None
```

## anus/core/planning/__init__.py

- Characters: 353
- Tokens: 0

```python
"""
Planning module for the ANUS framework.

This module contains classes for task planning:
- BasePlanner: Abstract base class for planners
- TaskPlanner: LLM-based task planning implementation
"""

from anus.core.planning.base_planner import BasePlanner
from anus.core.planning.task_planner import TaskPlanner

__all__ = ["BasePlanner", "TaskPlanner"]
```

## anus/core/planning/base_planner.py

- Characters: 2133
- Tokens: 0

```python
"""
Base Planner module that defines the common interface for task planning.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional

class BasePlanner(ABC):
    """
    Abstract base class for planners in the ANUS framework.
    
    Provides the core functionality for breaking down tasks into steps.
    """
    
    def __init__(self, **kwargs):
        """
        Initialize a BasePlanner instance.
        
        Args:
            **kwargs: Additional configuration options for the planner.
        """
        self.config = kwargs
    
    @abstractmethod
    def create_plan(self, task: str, context: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """
        Create a plan for executing a task.
        
        Args:
            task: The task description.
            context: Optional context for planning.
            
        Returns:
            A plan dictionary with steps and metadata.
        """
        pass
    
    @abstractmethod
    def replan(self, plan: Dict[str, Any], feedback: Dict[str, Any]) -> Dict[str, Any]:
        """
        Update a plan based on execution feedback.
        
        Args:
            plan: The current plan.
            feedback: Feedback from execution.
            
        Returns:
            The updated plan.
        """
        pass
    
    @abstractmethod
    def get_next_step(self, plan: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Get the next step to execute from a plan.
        
        Args:
            plan: The current plan.
            
        Returns:
            The next step to execute, or None if the plan is complete.
        """
        pass
    
    @abstractmethod
    def mark_step_complete(self, plan: Dict[str, Any], step_id: str, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Mark a step as complete in a plan.
        
        Args:
            plan: The current plan.
            step_id: The ID of the completed step.
            result: The result of the step execution.
            
        Returns:
            The updated plan.
        """
        pass
```

## anus/core/agent/react_agent.py

- Characters: 16009
- Tokens: 0

```python
"""
React Agent module that extends the base agent with reasoning capabilities.
"""

from typing import Dict, List, Any, Optional, Tuple
import json
import logging
import time
import uuid

from anus.core.agent.base_agent import BaseAgent
from anus.models.base.base_model import BaseModel


class ReactAgent(BaseAgent):
    """
    A reasoning agent that follows the React paradigm (Reasoning and Acting).

    This agent implements a thought-action-observation loop for complex reasoning.
    """

    def __init__(
        self,
        name: Optional[str] = None,
        max_iterations: int = 10,
        llm: Optional[BaseModel] = None,
        **kwargs,
    ):
        """
        Initialize a ReactAgent instance.

        Args:
            name: Optional name for the agent.
            max_iterations: Maximum number of thought-action cycles to perform.
            llm: Language model to use for reasoning. If None, a default one will be created.
            **kwargs: Additional configuration options for the agent.
        """
        super().__init__(name=name, **kwargs)
        self.max_iterations = max_iterations
        self.current_iteration = 0

        # Set up language model
        if llm:
            self.llm = llm
        else:
            # Import here to avoid circular imports
            from anus.models.model_router import ModelRouter

            router = ModelRouter()
            self.llm = router.get_default_model()

        # Define React prompts
        self.thought_prompt = """
        You are a reasoning agent solving a complex task. 
        Given the current context and task, generate a thought that would help you make progress.
        
        Task: {task}
        
        Previous steps:
        {history}
        
        Your thought should:
        - Analyze the current situation
        - Consider relevant information
        - Identify what needs to be done next
        - Be detailed and thorough
        
        Thought:
        """

        self.action_prompt = """
        You are a reasoning agent solving a complex task.
        Based on your thought, decide on the next action to take.
        
        Task: {task}
        
        Previous steps:
        {history}
        
        Current thought: {thought}
        
        Available actions:
        - search: Search for information on a topic
        - calculator: Perform mathematical calculations
        - lookup: Look up specific information
        - finish: Complete the task and provide the final answer
        
        Choose an action and provide the input for that action.
        Respond in JSON format like:
        {{
            "action": "action_name",
            "input": {{
                "query": "your query or input"
            }}
        }}
        
        JSON Response:
        """

    def execute(self, task: str, **kwargs) -> Dict[str, Any]:
        """
        Execute a task using the React paradigm.

        Args:
            task: The task description to execute.
            **kwargs: Additional parameters for task execution.

        Returns:
            A dictionary containing the execution result and metadata.
        """
        self.update_state(status="executing", task=task)
        self.current_iteration = 0

        # Initialize the context with the task
        context = {"task": task, "thoughts": [], "actions": [], "observations": []}

        # Main React loop
        while self.current_iteration < self.max_iterations:
            try:
                # Generate thought
                thought = self._generate_thought(context)
                context["thoughts"].append(thought)

                # Decide on action
                action_name, action_input = self._decide_action(context)
                action = {"name": action_name, "input": action_input}
                context["actions"].append(action)

                # Check if the action is to finish
                if action_name == "finish":
                    final_answer = action_input.get("answer", "Task completed.")

                    # Log the iteration
                    self.log_action(
                        "iteration",
                        {
                            "iteration": self.current_iteration,
                            "thought": thought,
                            "action": action,
                            "final_answer": final_answer,
                        },
                    )

                    # Build result
                    result = {
                        "task": task,
                        "answer": final_answer,
                        "iterations": self.current_iteration + 1,
                        "context": context,
                    }

                    self.update_state(status="completed")
                    return result

                # Execute action and get observation
                observation = self._execute_action(action_name, action_input)
                context["observations"].append(observation)

                # Log the iteration
                self.log_action(
                    "iteration",
                    {
                        "iteration": self.current_iteration,
                        "thought": thought,
                        "action": action,
                        "observation": observation,
                    },
                )

                # Check if we should terminate
                if self._should_terminate(context):
                    break

                self.current_iteration += 1

            except Exception as e:
                logging.error(f"Error in React execution loop: {str(e)}")
                context["errors"] = context.get("errors", []) + [str(e)]
                break

        # Generate final answer
        final_answer = self._generate_final_answer(context)

        result = {
            "task": task,
            "answer": final_answer,
            "iterations": self.current_iteration + 1,
            "context": context,
        }

        self.update_state(status="completed")
        return result

    def _generate_thought(self, context: Dict[str, Any]) -> str:
        """
        Generate a thought based on the current context.
        
        Args:
            context: The current execution context.
            
        Returns:
            A thought string.
        """
        # Build history from previous steps
        history_text = ""
        for i in range(len(context.get("thoughts", []))):
            history_text += f"Iteration {i+1}:\n"
            history_text += f"Thought: {context['thoughts'][i]}\n"
            
            if i < len(context.get("actions", [])):
                action = context["actions"][i]
                history_text += f"Action: {action['name']} - {json.dumps(action['input'])}\n"
                
            if i < len(context.get("observations", [])):
                history_text += f"Observation: {context['observations'][i]}\n"
                
            history_text += "\n"
        
        # Format the prompt
        prompt = self.thought_prompt.format(
            task=context["task"],
            history=history_text
        )
        
        # Call the language model to generate a thought
        try:
            thought_text = self.llm.generate(prompt, temperature=0.7)
            # Truncate the thought if too long
            if len(thought_text) > 1000:
                thought_text = thought_text[:997] + "..."
            return thought_text
        except Exception as e:
            logging.error(f"Error generating thought: {str(e)}")
            return f"I need to reconsider my approach. Previous error: {str(e)}"

    def _decide_action(self, context: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """
        Decide on the next action to take.

        Args:
            context: The current execution context.

        Returns:
            A tuple of (action_name, action_input).
        """
        # Build history text
        history_text = ""
        for i in range(len(context.get("thoughts", []))):
            history_text += f"Iteration {i+1}:\n"
            history_text += f"Thought: {context['thoughts'][i]}\n"

            if i < len(context.get("actions", [])):
                action = context["actions"][i]
                history_text += (
                    f"Action: {action['name']} - {json.dumps(action['input'])}\n"
                )

            if i < len(context.get("observations", [])):
                history_text += f"Observation: {context['observations'][i]}\n"

            history_text += "\n"

        # Format the prompt
        prompt = self.action_prompt.format(
            task=context["task"],
            history=history_text,
            thought=context["thoughts"][-1] if context["thoughts"] else "",
        )

        # Call the language model to generate an action decision
        try:
            response = self.llm.generate(prompt, temperature=0.2)

            # Parse the JSON response
            try:
                action_decision = json.loads(response)
                action_name = action_decision.get("action", "finish")
                action_input = action_decision.get("input", {})

                if not isinstance(action_input, dict):
                    action_input = {"value": action_input}

                return action_name, action_input

            except json.JSONDecodeError:
                # Handle case where response is not valid JSON
                logging.warning(
                    f"Invalid JSON response for action decision: {response}"
                )

                # Try to extract action name and input using simple heuristics
                if "search" in response.lower():
                    query = response.split("search", 1)[1].strip()
                    return "search", {"query": query}
                elif "calculator" in response.lower():
                    expression = response.split("calculator", 1)[1].strip()
                    return "calculator", {"expression": expression}
                elif "lookup" in response.lower():
                    query = response.split("lookup", 1)[1].strip()
                    return "lookup", {"query": query}
                elif "finish" in response.lower():
                    answer = response.split("finish", 1)[1].strip()
                    return "finish", {"answer": answer}
                else:
                    # Default to finish action
                    return "finish", {"answer": response}

        except Exception as e:
            logging.error(f"Error deciding action: {str(e)}")
            # Default to finish action in case of error
            return "finish", {"answer": f"I encountered an error: {str(e)}"}

    def _execute_action(self, action_name: str, action_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute an action and return the observation.
        
        Args:
            action_name: The name of the action to execute.
            action_input: The input parameters for the action.
            
        Returns:
            The observation from executing the action.
        """
        # This should be extended to call the appropriate tool
        # For now, implementing basic functionality for common actions
        
        try:
            if action_name == "search":
                # Simulate search action
                query = action_input.get("query", "")
                return {"result": f"Search results for '{query}': [Simulated search result]"}
                
            elif action_name == "calculator":
                # Implement basic calculator functionality
                expression = action_input.get("expression", "")
                try:
                    # Use safe eval to calculate expressions
                    # This should be replaced with a proper calculator tool
                    result = eval(expression, {"__builtins__": {}}, {"abs": abs, "max": max, "min": min, "sum": sum})
                    return {"result": f"Calculator result: {result}"}
                except Exception as calc_error:
                    return {"error": f"Calculator error: {str(calc_error)}"}
                    
            elif action_name == "lookup":
                # Simulate lookup action
                query = action_input.get("query", "")
                return {"result": f"Lookup result for '{query}': [Simulated lookup result]"}
                
            elif action_name == "finish":
                # Just return the answer
                return {"result": f"Final answer: {action_input.get('answer', '')}"}
                
            else:
                # Handle unknown action
                return {"error": f"Unknown action: {action_name}"}
                
        except Exception as e:
            logging.error(f"Error executing action {action_name}: {str(e)}")
            return {"error": f"Error executing {action_name}: {str(e)}"}

    def _should_terminate(self, context: Dict[str, Any]) -> bool:
        """
        Determine if execution should terminate.

        Args:
            context: The current execution context.

        Returns:
            True if execution should terminate, False otherwise.
        """
        # Check if we've reached the maximum iterations
        if self.current_iteration >= self.max_iterations - 1:
            return True

        # Check if the last action was a finish action
        if context.get("actions") and context["actions"][-1].get("name") == "finish":
            return True

        # Check if we've encountered too many errors
        error_count = sum(
            1 for obs in context.get("observations", []) if "error" in obs
        )
        if error_count >= 3:  # Terminate after 3 errors
            return True

        # Additional termination conditions could be added here

        return False

    def _generate_final_answer(self, context: Dict[str, Any]) -> str:
        """
        Generate a final answer based on the context.

        Args:
            context: The current execution context.

        Returns:
            The final answer string.
        """
        # If the last action was a finish, use its answer
        if context.get("actions") and context["actions"][-1].get("name") == "finish":
            return (
                context["actions"][-1].get("input", {}).get("answer", "Task completed.")
            )

        # Otherwise, generate a final answer using the language model
        final_answer_prompt = f"""
        You are a reasoning agent that has been working on a task.
        Based on the thought process and observations, provide a final comprehensive answer.
        
        Task: {context.get('task', '')}
        
        Thought process:
        """

        # Add the thought process to the prompt
        for i in range(len(context.get("thoughts", []))):
            final_answer_prompt += f"\nIteration {i+1}:\n"
            final_answer_prompt += f"Thought: {context['thoughts'][i]}\n"

            if i < len(context.get("actions", [])):
                action = context["actions"][i]
                final_answer_prompt += (
                    f"Action: {action['name']} - {json.dumps(action['input'])}\n"
                )

            if i < len(context.get("observations", [])):
                final_answer_prompt += f"Observation: {context['observations'][i]}\n"

        final_answer_prompt += "\nBased on the above information, provide a concise and accurate final answer to the task."

        try:
            final_answer = self.llm.generate(final_answer_prompt, temperature=0.3)
            return final_answer
        except Exception as e:
            logging.error(f"Error generating final answer: {str(e)}")

            # Fallback to a basic answer
            return "Based on my analysis, I've reached a conclusion, but had difficulty formulating the final answer."
```

## anus/core/agent/tool_agent.py

- Characters: 4366
- Tokens: 0

```python
"""
Tool Agent module that extends the react agent with tool execution capabilities.
"""

from typing import Dict, List, Any, Optional, Tuple
import importlib
import logging

from anus.core.agent.react_agent import ReactAgent

class ToolAgent(ReactAgent):
    """
    An agent that can use tools to interact with its environment.
    
    Extends the ReactAgent with the ability to discover, load, and execute tools.
    """
    
    def __init__(
        self, 
        name: Optional[str] = None, 
        max_iterations: int = 10, 
        tools: Optional[List[str]] = None,
        **kwargs
    ):
        """
        Initialize a ToolAgent instance.
        
        Args:
            name: Optional name for the agent.
            max_iterations: Maximum number of thought-action cycles to perform.
            tools: Optional list of tool names to load.
            **kwargs: Additional configuration options for the agent.
        """
        super().__init__(name=name, max_iterations=max_iterations, **kwargs)
        self.tools: Dict[str, Any] = {}
        
        # Load specified tools or default tools
        if tools:
            for tool_name in tools:
                self.load_tool(tool_name)
    
    def load_tool(self, tool_name: str) -> bool:
        """
        Load a tool by name.
        
        Args:
            tool_name: The name of the tool to load.
            
        Returns:
            True if the tool was successfully loaded, False otherwise.
        """
        try:
            # Dynamically import the tool module
            module_path = f"anus.tools.{tool_name}"
            module = importlib.import_module(module_path)
            
            # Get the tool class (assumed to be the same name as the module but capitalized)
            class_name = "".join(word.capitalize() for word in tool_name.split("_")) + "Tool"
            tool_class = getattr(module, class_name)
            
            # Instantiate the tool
            tool_instance = tool_class()
            
            # Register the tool
            self.tools[tool_name] = tool_instance
            
            self.log_action("load_tool", {"tool_name": tool_name, "status": "success"})
            return True
            
        except (ImportError, AttributeError, Exception) as e:
            self.log_action("load_tool", {"tool_name": tool_name, "status": "error", "error": str(e)})
            logging.error(f"Failed to load tool {tool_name}: {e}")
            return False
    
    def _execute_action(self, action_name: str, action_input: Dict[str, Any]) -> Dict[str, Any]:
        """
        Execute an action using the appropriate tool.
        
        Args:
            action_name: The name of the action/tool to execute.
            action_input: The input parameters for the action.
            
        Returns:
            The observation from executing the action.
        """
        # Check if the action corresponds to a loaded tool
        if action_name in self.tools:
            try:
                tool = self.tools[action_name]
                result = tool.execute(**action_input)
                return {"status": "success", "result": result}
            except Exception as e:
                error_message = f"Error executing tool {action_name}: {str(e)}"
                logging.error(error_message)
                return {"status": "error", "error": error_message}
        else:
            # Try to load the tool if it's not already loaded
            if self.load_tool(action_name):
                # Retry execution with the newly loaded tool
                return self._execute_action(action_name, action_input)
            else:
                return {"status": "error", "error": f"Unknown action or tool: {action_name}"}
    
    def list_available_tools(self) -> List[Dict[str, Any]]:
        """
        List all available tools and their descriptions.
        
        Returns:
            A list of dictionaries containing tool information.
        """
        tool_info = []
        for name, tool in self.tools.items():
            info = {
                "name": name,
                "description": getattr(tool, "description", "No description available"),
                "parameters": getattr(tool, "parameters", {})
            }
            tool_info.append(info)
        return tool_info
```

## anus/core/agent/base_agent.py

- Characters: 2444
- Tokens: 0

```python
"""
Base Agent module that defines the common interface for all agents.
"""

from abc import ABC, abstractmethod
from typing import Dict, List, Any, Optional
import uuid
import time

class BaseAgent(ABC):
    """
    Abstract base class for all agents in the ANUS framework.
    
    Provides the core functionality and interface that all agent types must implement.
    """
    
    def __init__(self, name: Optional[str] = None, **kwargs):
        """
        Initialize a BaseAgent instance.
        
        Args:
            name: Optional name for the agent. If not provided, a UUID will be generated.
            **kwargs: Additional configuration options for the agent.
        """
        self.id = str(uuid.uuid4())
        self.name = name or f"agent-{self.id[:8]}"
        self.created_at = time.time()
        self.state: Dict[str, Any] = {"status": "initialized"}
        self.history: List[Dict[str, Any]] = []
        self.config = kwargs
    
    @abstractmethod
    def execute(self, task: str, **kwargs) -> Dict[str, Any]:
        """
        Execute a task and return the result.
        
        Args:
            task: The task description to execute.
            **kwargs: Additional parameters for task execution.
            
        Returns:
            A dictionary containing the execution result and metadata.
        """
        pass
    
    def update_state(self, **kwargs) -> None:
        """
        Update the agent's state with new values.
        
        Args:
            **kwargs: Key-value pairs to update in the state.
        """
        self.state.update(kwargs)
        
    def log_action(self, action: str, details: Dict[str, Any]) -> None:
        """
        Log an action performed by the agent.
        
        Args:
            action: The name of the action.
            details: Details about the action.
        """
        log_entry = {
            "timestamp": time.time(),
            "action": action,
            "details": details
        }
        self.history.append(log_entry)
    
    def get_info(self) -> Dict[str, Any]:
        """
        Get information about the agent.
        
        Returns:
            A dictionary containing agent information.
        """
        return {
            "id": self.id,
            "name": self.name,
            "created_at": self.created_at,
            "state": self.state,
            "history_length": len(self.history)
        }
```

## anus/core/agent/hybrid_agent.py

- Characters: 15806
- Tokens: 0

```python
"""
Hybrid Agent module that can switch between single-agent and multi-agent modes.

For when a single agent isn't enough to handle the backend load.
"""

from typing import Dict, List, Any, Optional, Tuple, Union
import logging
import random

from anus.core.agent.tool_agent import ToolAgent

class HybridAgent(ToolAgent):
    """
    An agent that can operate in both single-agent and multi-agent modes.
    
    This agent analyzes task complexity and dynamically switches between
    operating as a single agent or coordinating multiple specialized agents.
    
    Like a good ANUS, it knows when to work alone and when to bring in friends.
    """
    
    # Funny task complexity ratings
    _complexity_ratings = [
        "This task is so simple even a constipated ANUS could handle it.",
        "This task requires moderate effort. ANUS is warming up.",
        "This task is getting complicated. ANUS might need to expand a bit.",
        "Complex task detected! ANUS is stretching to accommodate.",
        "Maximum complexity reached! ANUS is fully dilated for multi-agent mode!"
    ]
    
    def __init__(
        self, 
        name: Optional[str] = None, 
        max_iterations: int = 10, 
        tools: Optional[List[str]] = None,
        mode: str = "auto",
        specialized_agents: Optional[Dict[str, Dict[str, Any]]] = None,
        **kwargs
    ):
        """
        Initialize a HybridAgent instance.
        
        Args:
            name: Optional name for the agent.
            max_iterations: Maximum number of thought-action cycles to perform.
            tools: Optional list of tool names to load.
            mode: Operating mode: "single", "multi", or "auto".
            specialized_agents: Configuration for specialized agents.
            **kwargs: Additional configuration options for the agent.
        """
        super().__init__(name=name, max_iterations=max_iterations, tools=tools, **kwargs)
        self.mode = mode
        self.specialized_agents: Dict[str, ToolAgent] = {}
        self.complexity_threshold = kwargs.get("complexity_threshold", 7)
        
        # Easter egg mode names for logging
        self._mode_names = {
            "single": "single-agent (tight and focused)",
            "multi": "multi-agent (fully expanded)",
            "auto": "auto-expanding"
        }
        
        # Initialize specialized agents if provided
        if specialized_agents:
            for role, config in specialized_agents.items():
                self.add_specialized_agent(role, config)
    
    def add_specialized_agent(self, role: str, config: Dict[str, Any]) -> bool:
        """
        Add a specialized agent for a specific role.
        
        Args:
            role: The role of the specialized agent.
            config: Configuration for the specialized agent.
            
        Returns:
            True if the agent was successfully added, False otherwise.
        """
        try:
            # Create a new ToolAgent with the given configuration
            agent_name = config.get("name", f"{role}-agent")
            agent = ToolAgent(
                name=agent_name,
                max_iterations=config.get("max_iterations", self.max_iterations),
                tools=config.get("tools", []),
                **config.get("kwargs", {})
            )
            
            # Register the specialized agent
            self.specialized_agents[role] = agent
            
            self.log_action("add_specialized_agent", {"role": role, "agent_name": agent_name})
            
            # Add easter egg log message based on role
            if role == "researcher":
                logging.debug(f"Added a researcher agent to probe deep into any subject matter")
            elif role == "coder":
                logging.debug(f"Added a coder agent to handle the backend implementation")
            elif role == "planner":
                logging.debug(f"Added a planner agent to ensure smooth passage through complex tasks")
            elif role == "critic":
                logging.debug(f"Added a critic agent to ensure everything comes out right in the end")
            else:
                logging.debug(f"Added a {role} agent to the ANUS collective")
            
            return True
            
        except Exception as e:
            error_message = f"Error adding specialized agent for role {role}: {str(e)}"
            logging.error(error_message)
            self.log_action("add_specialized_agent", {"role": role, "status": "error", "error": error_message})
            return False
    
    def execute(self, task: str, **kwargs) -> Dict[str, Any]:
        """
        Execute a task in the appropriate mode.
        
        Args:
            task: The task description to execute.
            **kwargs: Additional parameters for task execution.
            
        Returns:
            A dictionary containing the execution result and metadata.
        """
        # Override mode if specified in kwargs
        mode = kwargs.get("mode", self.mode)
        
        # If mode is auto, analyze task complexity to determine mode
        if mode == "auto":
            mode = self._determine_mode(task)
            complexity = self._analyze_task_complexity(task)
            
            # Log a funny complexity message
            rating_index = min(int(complexity // 2), len(self._complexity_ratings) - 1)
            logging.info(self._complexity_ratings[rating_index])
        
        self.update_state(status="executing", task=task, mode=mode)
        
        # Log the mode with easter egg names
        mode_name = self._mode_names.get(mode, mode)
        logging.info(f"ANUS operating in {mode_name} mode for task: {task[:50]}...")
        
        # Execute in the appropriate mode
        if mode == "single" or not self.specialized_agents:
            result = self._execute_single(task, **kwargs)
        else:
            result = self._execute_multi(task, **kwargs)
        
        self.update_state(status="completed")
        return result
    
    def _execute_single(self, task: str, **kwargs) -> Dict[str, Any]:
        """
        Execute a task in single-agent mode.
        
        Args:
            task: The task description to execute.
            **kwargs: Additional parameters for task execution.
            
        Returns:
            A dictionary containing the execution result and metadata.
        """
        # Use the ToolAgent's execute method
        logging.debug("ANUS tightening focus for single-agent execution")
        return super().execute(task, **kwargs)
    
    def _execute_multi(self, task: str, **kwargs) -> Dict[str, Any]:
        """
        Execute a task in multi-agent mode.
        
        Args:
            task: The task description to execute.
            **kwargs: Additional parameters for task execution.
            
        Returns:
            A dictionary containing the execution result and metadata.
        """
        # Ensure we have specialized agents
        if not self.specialized_agents:
            logging.warning("No specialized agents available for multi-agent execution. Falling back to single-agent mode.")
            logging.info("ANUS feels empty inside. Adding more agents is recommended.")
            return self._execute_single(task, **kwargs)
        
        # Decompose the task into subtasks for specialized agents
        logging.info(f"ANUS expanding to accommodate {len(self.specialized_agents)} specialized agents")
        subtasks = self._decompose_task(task)
        
        # Assign subtasks to specialized agents
        results = {}
        for subtask in subtasks:
            role = subtask["role"]
            subtask_description = subtask["description"]
            
            if role in self.specialized_agents:
                agent = self.specialized_agents[role]
                
                # Add easter egg log message
                if role == "researcher":
                    logging.debug(f"Researcher agent is probing deeply into: {subtask_description[:30]}...")
                elif role == "coder":
                    logging.debug(f"Coder agent is handling the backend for: {subtask_description[:30]}...")
                elif role == "planner":
                    logging.debug(f"Planner agent is ensuring smooth passage for: {subtask_description[:30]}...")
                elif role == "critic":
                    logging.debug(f"Critic agent is making sure everything comes out right for: {subtask_description[:30]}...")
                else:
                    logging.debug(f"{role.capitalize()} agent is processing: {subtask_description[:30]}...")
                
                subtask_result = agent.execute(subtask_description, **kwargs)
                results[subtask["id"]] = subtask_result
                
                self.log_action("specialized_agent_execution", {
                    "role": role,
                    "subtask_id": subtask["id"],
                    "subtask": subtask_description,
                    "status": "completed"
                })
            else:
                error_message = f"No agent available for role: {role}"
                logging.warning(error_message)
                results[subtask["id"]] = {"status": "error", "error": error_message}
        
        # Aggregate results into a final answer
        logging.info("All agents have finished their tasks. ANUS is aggregating results...")
        final_result = self._aggregate_results(task, subtasks, results)
        
        return {
            "task": task,
            "mode": "multi",
            "answer": final_result.get("answer", ""),
            "subtasks": subtasks,
            "subtask_results": results,
            "aggregated_result": final_result
        }
    
    def _determine_mode(self, task: str) -> str:
        """
        Determine whether to use single-agent or multi-agent mode.
        
        Args:
            task: The task description to analyze.
            
        Returns:
            "single" or "multi" based on task complexity.
        """
        # Analyze task complexity
        complexity = self._analyze_task_complexity(task)
        
        # If complexity exceeds threshold and we have specialized agents, use multi-agent mode
        if complexity >= self.complexity_threshold and self.specialized_agents:
            logging.info(f"Task complexity ({complexity:.1f}) exceeds threshold ({self.complexity_threshold}). ANUS expanding to multi-agent mode.")
            return "multi"
        else:
            logging.info(f"Task complexity ({complexity:.1f}) below threshold ({self.complexity_threshold}). ANUS staying tight in single-agent mode.")
            return "single"
    
    def _analyze_task_complexity(self, task: str) -> float:
        """
        Analyze the complexity of a task.
        
        Args:
            task: The task description to analyze.
            
        Returns:
            A complexity score (higher values indicate more complex tasks).
        """
        # Placeholder implementation
        # In a real implementation, this would use more sophisticated metrics
        
        # Basic heuristics
        score = 0
        
        # Length-based complexity
        words = task.split()
        score += min(len(words) / 10, 5)  # Cap at 5 points
        
        # Keyword-based complexity
        complexity_keywords = [
            "complex", "difficult", "challenging", "multiple", "analyze", 
            "compare", "design", "create", "optimize", "solve"
        ]
        for keyword in complexity_keywords:
            if keyword in task.lower():
                score += 0.5
        
        # Easter egg: add extra complexity for certain funny keywords
        funny_keywords = ["hard", "deep", "tight", "huge", "massive", "backend", "insertion", "hole"]
        for keyword in funny_keywords:
            if keyword in task.lower():
                score += 0.3
                logging.debug(f"Found complexity keyword '{keyword}' - ANUS might need to expand")
        
        return score
    
    def _decompose_task(self, task: str) -> List[Dict[str, Any]]:
        """
        Decompose a task into subtasks for specialized agents.
        
        Args:
            task: The task description to decompose.
            
        Returns:
            A list of subtask dictionaries with role assignments.
        """
        # Placeholder implementation
        # In a real implementation, this would use an LLM to decompose the task
        
        # Get available roles
        available_roles = list(self.specialized_agents.keys())
        
        # Random funny descriptors for different roles
        role_descriptors = {
            "researcher": [
                "dig deep into",
                "probe thoroughly",
                "explore every crevice of",
                "investigate the depths of",
                "get to the bottom of"
            ],
            "coder": [
                "implement the backend for",
                "code up a tight solution for",
                "develop a robust framework for",
                "craft efficient code for",
                "build a solid foundation for"
            ],
            "planner": [
                "chart a clear passage for",
                "develop a smooth approach to",
                "create a flexible plan for",
                "map out the ins and outs of",
                "devise a strategy for"
            ],
            "critic": [
                "thoroughly examine",
                "inspect every inch of",
                "ensure nothing leaks in",
                "check for holes in",
                "make sure everything comes out right for"
            ]
        }
        
        # Create simple subtasks based on available roles
        subtasks = []
        for i, role in enumerate(available_roles):
            # Pick a random descriptor for this role
            descriptors = role_descriptors.get(role, ["handle"])
            descriptor = random.choice(descriptors)
            
            subtask = {
                "id": f"subtask-{i+1}",
                "role": role,
                "description": f"As a {role}, {descriptor} {task}"
            }
            subtasks.append(subtask)
        
        logging.info(f"Task decomposed into {len(subtasks)} subtasks for optimal ANUS performance")
        return subtasks
    
    def _aggregate_results(self, task: str, subtasks: List[Dict[str, Any]], results: Dict[str, Any]) -> Dict[str, Any]:
        """
        Aggregate results from multiple specialized agents.
        
        Args:
            task: The original task description.
            subtasks: The list of subtasks assigned to agents.
            results: The results from each specialized agent.
            
        Returns:
            An aggregated result.
        """
        # Placeholder implementation
        # In a real implementation, this would use an LLM to synthesize results
        
        # Simple concatenation of results
        answers = []
        for subtask in subtasks:
            subtask_id = subtask["id"]
            if subtask_id in results:
                result = results[subtask_id]
                if "answer" in result:
                    answers.append(f"[{subtask['role']}]: {result['answer']}")
        
        final_answer = "\n\n".join(answers)
        
        logging.info("ANUS has successfully completed multi-agent processing")
        logging.debug(f"Aggregated {len(answers)} agent outputs into one comprehensive response")
        
        return {
            "answer": final_answer,
            "status": "success"
        }
```

## anus/core/agent/__init__.py

- Characters: 589
- Tokens: 0

```python
"""
Agent module for the ANUS framework.

This module contains various agent implementations:
- BaseAgent: Abstract base class for all agents
- ReactAgent: Agent with reasoning capabilities
- ToolAgent: Agent with tool execution capabilities
- HybridAgent: Agent that can switch between single and multi-agent modes
"""

from anus.core.agent.base_agent import BaseAgent
from anus.core.agent.react_agent import ReactAgent
from anus.core.agent.tool_agent import ToolAgent
from anus.core.agent.hybrid_agent import HybridAgent

__all__ = ["BaseAgent", "ReactAgent", "ToolAgent", "HybridAgent"]
```

## anus/__init__.py

- Characters: 232
- Tokens: 0

```python
"""
Anus - Autonomous Networked Utility System
Package initialization
"""

__version__ = "0.1.0"
__author__ = "Anus AI Team"
__email__ = "anus-ai@example.com"
__description__ = "An open-source AI agent framework for task automation"
```

## setup.py

- Characters: 1122
- Tokens: 0

```python
from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

with open("requirements.txt", "r", encoding="utf-8") as fh:
    requirements = fh.read().splitlines()

setup(
    name="anus-ai",
    version="0.1.0",
    author="Anus AI Team",
    author_email="anus-ai@example.com",
    description="An open-source AI agent framework for task automation",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/anus-ai/anus",
    packages=find_packages(),
    classifiers=[
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.11",
        "License :: OSI Approved :: MIT License",
        "Operating System :: OS Independent",
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Developers",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
    ],
    python_requires=">=3.11",
    install_requires=requirements,
    entry_points={
        "console_scripts": [
            "anus=main:main",
        ],
    },
)
```

## CHANGELOG.md

- Characters: 705
- Tokens: 0

```markdown
# CHANGELOG.md

# Changelog

All notable changes to the Anus AI project will be documented in this file.

The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).

## [Unreleased]

### Added
- Initial project structure
- Core engine components
- Agent system framework
- Tool ecosystem foundation
- Model integration interfaces
- User interface components
- Documentation framework
- Project logo and branding

### Changed
- N/A

### Deprecated
- N/A

### Removed
- N/A

### Fixed
- N/A

### Security
- N/A

## [0.1.0] - 2025-03-09
- Initial release
- Basic project structure and documentation
```

## requirements.txt

- Characters: 647
- Tokens: 0

```text
# Python dependencies for Anus AI
# Core dependencies
openai>=1.0.0
anthropic>=0.5.0
langchain>=0.0.267
pydantic>=2.0.0
PyYAML>=6.0
python-dotenv>=1.0.0
typer>=0.9.0
rich>=13.0.0
tqdm>=4.66.0
google-genai>=1.5.0

# Web and browser automation
playwright>=1.40.0
beautifulsoup4>=4.12.0
requests>=2.31.0
aiohttp>=3.8.5

# Document processing
pypdf>=3.15.0
python-docx>=0.8.11
openpyxl>=3.1.2
pillow>=10.0.0

# Code execution
jupyter-client>=8.3.0
nbformat>=5.9.0

# Testing
pytest>=7.4.0
pytest-cov>=4.1.0

# Development
black>=23.7.0
isort>=5.12.0
flake8>=6.1.0
mypy>=1.5.0

# API and web interface
fastapi>=0.103.0
uvicorn>=0.23.0
streamlit>=1.26.0
```

## assets/anus_logo.py

- Characters: 1908
- Tokens: 0

```python
import matplotlib.pyplot as plt
import numpy as np
from matplotlib.patches import Circle, Ellipse
from matplotlib.colors import LinearSegmentedColormap

# Set up the figure
fig, ax = plt.subplots(figsize=(10, 10))
ax.set_aspect('equal')
ax.axis('off')

# Create a custom colormap for the gradient background
colors = [(0.8, 0.4, 0.6), (0.6, 0.2, 0.5)]  # Pink to purple gradient
cmap = LinearSegmentedColormap.from_list("custom_cmap", colors, N=100)

# Create a circular background with gradient
circle_bg = Circle((0.5, 0.5), 0.45, transform=ax.transAxes, 
                  color='white', zorder=0)
ax.add_patch(circle_bg)

# Create the main shape (stylized "A" that resembles a peach)
# First half of the "A"
ellipse1 = Ellipse((0.4, 0.5), 0.4, 0.7, angle=-20, 
                  color=colors[0], alpha=0.9, zorder=1)
ax.add_patch(ellipse1)

# Second half of the "A"
ellipse2 = Ellipse((0.6, 0.5), 0.4, 0.7, angle=20, 
                  color=colors[1], alpha=0.9, zorder=1)
ax.add_patch(ellipse2)

# Add a small circle at the top to complete the "A"
circle_top = Circle((0.5, 0.8), 0.08, color=(0.7, 0.3, 0.5), zorder=2)
ax.add_patch(circle_top)

# Add a horizontal line to represent the crossbar of the "A"
ax.plot([0.35, 0.65], [0.5, 0.5], color='white', linewidth=8, zorder=3)

# Add AI-themed elements (circuit-like lines)
for i in range(5):
    angle = np.pi * 2 * i / 5
    x = 0.5 + 0.5 * np.cos(angle)
    y = 0.5 + 0.5 * np.sin(angle)
    ax.plot([0.5, x], [0.5, y], color='white', linewidth=1, alpha=0.5, zorder=4)

# Set the limits
ax.set_xlim(0, 1)
ax.set_ylim(0, 1)

# Save the logo
plt.savefig('/home/ubuntu/anus-ai-project/assets/anus_logo.png', 
           dpi=300, bbox_inches='tight', transparent=True)
plt.savefig('/home/ubuntu/anus-ai-project/assets/anus_logo_small.png', 
           dpi=100, bbox_inches='tight', transparent=True)

print("Logo created and saved to assets directory")
```

## assets/toc.md

- Characters: 352
- Tokens: 0

```markdown
# Table of Contents

- [Introduction](#-introduction)
- [Why Anus?](#-why-anus)
- [Features & Capabilities](#-features--capabilities)
- [Installation](#-installation)
- [Quick Start](#-quick-start)
- [Usage Examples](#-usage-examples)
- [Documentation](#-documentation)
- [Contributing](#-contributing)
- [Community](#-community)
- [License](#-license)
```

## assets/badges.md

- Characters: 1251
- Tokens: 0

```markdown
<!-- Badges for the Anus AI project -->

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)
[![Contributions welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg)](https://github.com/anus-ai/anus/blob/main/CONTRIBUTING.md)
[![GitHub stars](https://img.shields.io/github/stars/anus-ai/anus.svg?style=social&label=Star)](https://github.com/anus-ai/anus)
[![GitHub forks](https://img.shields.io/github/forks/anus-ai/anus.svg?style=social&label=Fork)](https://github.com/anus-ai/anus)
[![GitHub issues](https://img.shields.io/github/issues/anus-ai/anus.svg)](https://github.com/anus-ai/anus/issues)
[![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg)](https://makeapullrequest.com)
[![Documentation Status](https://img.shields.io/badge/docs-latest-brightgreen.svg)](https://anus-ai.github.io/docs)
[![Discord](https://img.shields.io/discord/1234567890?color=7289da&label=Discord&logo=discord&logoColor=white)](https://discord.gg/anus-ai)
```

## LICENSE

- Characters: 1068
- Tokens: 0

```text
MIT License

Copyright (c) 2025 Anus AI Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## repo.json

- Characters: 132
- Tokens: 0

```json
{
  "name": "ANUS",
  "description": "Advanced Neural Understanding System - AI Project",
  "private": false,
  "auto_init": false
}
```

## docs/advanced_usage.md

- Characters: 13567
- Tokens: 0

````markdown
# Advanced Usage Guide

This document provides advanced usage examples and techniques for getting the most out of the Anus AI framework.

## Table of Contents
- [Multi-Agent Collaboration](#multi-agent-collaboration)
- [Custom Tool Development](#custom-tool-development)
- [Advanced Configuration](#advanced-configuration)
- [Memory Management](#memory-management)
- [Performance Optimization](#performance-optimization)
- [Integration with External Systems](#integration-with-external-systems)
- [Deployment Strategies](#deployment-strategies)

## Multi-Agent Collaboration

### Creating Specialized Agent Roles

You can create specialized agents with different roles to handle complex tasks:

```python
from anus import Agent, Society

# Create specialized agents
researcher = Agent(
    role="researcher",
    tools=["search", "browser"],
    model="gpt-4o"
)

analyst = Agent(
    role="analyst",
    tools=["code", "document"],
    model="claude-3-opus"
)

writer = Agent(
    role="writer",
    tools=["document"],
    model="gpt-4o"
)

# Create a society of agents
society = Society(
    agents=[researcher, analyst, writer],
    coordination_strategy="consensus"
)

# Execute a complex task with collaboration
response = society.run(
    "Research the impact of artificial intelligence on healthcare, " 
    "analyze the findings, and write a comprehensive report"
)
```

### Custom Coordination Strategies

Anus supports different coordination strategies for multi-agent collaboration:

```python
# Consensus strategy - all agents must agree on decisions
society = Society(
    agents=[agent1, agent2, agent3],
    coordination_strategy="consensus"
)

# Hierarchical strategy - one agent leads and delegates to others
society = Society(
    agents=[leader_agent, worker_agent1, worker_agent2],
    coordination_strategy="hierarchical",
    leader_agent_id=leader_agent.id
)

# Autonomous strategy - agents work independently and share results
society = Society(
    agents=[agent1, agent2, agent3],
    coordination_strategy="autonomous"
)
```

### Inter-Agent Communication

You can customize how agents communicate with each other:

```python
from anus import Society, Agent, CommunicationProtocol

# Create a custom communication protocol
protocol = CommunicationProtocol(
    message_format="structured",
    synchronization="async",
    logging=True
)

# Create a society with the custom protocol
society = Society(
    agents=[agent1, agent2, agent3],
    communication_protocol=protocol
)
```

## Custom Tool Development

### Creating a Custom Tool

You can create custom tools by extending the `BaseTool` class:

```python
from anus.tools import BaseTool
from typing import Dict, Any

class WeatherTool(BaseTool):
    """Tool for getting weather information."""
    
    def __init__(self, api_key: str):
        super().__init__()
        self.api_key = api_key
        self.name = "weather_tool"
        self.description = "Gets weather information for a location"
    
    def _execute(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Execute the tool with the given parameters."""
        location = params.get("location")
        if not location:
            return {"error": "Location parameter is required"}
        
        # Implement weather API call here
        # ...
        
        return {
            "location": location,
            "temperature": 72,
            "conditions": "sunny",
            "humidity": 45
        }

# Use the custom tool
from anus import Agent

agent = Agent(tools=[WeatherTool(api_key="your_api_key")])
response = agent.run("What's the weather like in New York?")
```

### Tool Registration System

You can register custom tools with the tool registry:

```python
from anus.tools import register_tool, get_tool

# Register your custom tool
register_tool("weather", WeatherTool)

# Get the tool from the registry
weather_tool_class = get_tool("weather")
weather_tool = weather_tool_class(api_key="your_api_key")
```

### Tool Composition

You can compose multiple tools together:

```python
from anus.tools import ComposedTool, SearchTool, DocumentTool

# Create a composed tool that combines search and document processing
research_tool = ComposedTool(
    name="research_tool",
    tools=[SearchTool(), DocumentTool()],
    description="Searches for information and processes documents"
)

agent = Agent(tools=[research_tool])
```

## Advanced Configuration

### Environment-Specific Configuration

You can create different configurations for different environments:

```python
from anus import Config, Agent

# Development configuration
dev_config = Config.from_file("config.dev.yaml")

# Production configuration
prod_config = Config.from_file("config.prod.yaml")

# Choose configuration based on environment
import os
env = os.getenv("ANUS_ENV", "development")
config = dev_config if env == "development" else prod_config

agent = Agent(config=config)
```

### Dynamic Configuration

You can modify configuration at runtime:

```python
from anus import Agent, Config

# Create initial configuration
config = Config(
    llm={
        "provider": "openai",
        "model": "gpt-4o",
        "temperature": 0.7,
    }
)

# Create agent with initial config
agent = Agent(config=config)

# Modify configuration at runtime
agent.config.update({
    "llm": {
        "temperature": 0.2  # Lower temperature for more focused responses
    }
})

# Configuration changes take effect on next run
response = agent.run("Generate a creative story")
```

### Configuration Profiles

You can create and switch between configuration profiles:

```python
from anus import Agent, ConfigProfile

# Create configuration profiles
creative_profile = ConfigProfile(
    name="creative",
    llm={
        "temperature": 0.8,
        "top_p": 0.9
    }
)

precise_profile = ConfigProfile(
    name="precise",
    llm={
        "temperature": 0.2,
        "top_p": 0.5
    }
)

# Create agent with default configuration
agent = Agent()

# Switch to creative profile for creative tasks
agent.apply_profile(creative_profile)
creative_response = agent.run("Write a poem about AI")

# Switch to precise profile for factual tasks
agent.apply_profile(precise_profile)
precise_response = agent.run("Explain quantum computing")
```

## Memory Management

### Persistent Memory

You can save and load agent memory:

```python
from anus import Agent

# Create agent with persistent memory
agent = Agent(memory_type="persistent", memory_path="./agent_memory")

# Run some tasks
agent.run("Remember that my favorite color is blue")
agent.run("My birthday is on March 15")

# Save memory explicitly (also happens automatically on shutdown)
agent.save_memory()

# Later, create a new agent that loads the saved memory
new_agent = Agent(memory_type="persistent", memory_path="./agent_memory")

# The new agent remembers previous information
response = new_agent.run("What is my favorite color and when is my birthday?")
# Response will include blue and March 15
```

### Memory Types

Anus supports different types of memory:

```python
# Ephemeral memory (default) - lasts only for the current session
agent = Agent(memory_type="ephemeral")

# Persistent memory - saved to disk and can be loaded later
agent = Agent(memory_type="persistent", memory_path="./agent_memory")

# Vector memory - uses vector embeddings for more efficient retrieval
agent = Agent(memory_type="vector", memory_path="./vector_memory")

# Hybrid memory - combines different memory types
agent = Agent(memory_type="hybrid", memory_config={
    "short_term": "ephemeral",
    "long_term": "vector",
    "path": "./hybrid_memory"
})
```

### Memory Operations

You can perform operations on agent memory:

```python
# Add information to memory
agent.memory.add("User likes chocolate ice cream")

# Query memory
results = agent.memory.query("What does the user like?")

# Clear memory
agent.memory.clear()

# Get memory statistics
stats = agent.memory.stats()
print(f"Memory size: {stats['size']}, Items: {stats['items']}")
```

## Performance Optimization

### Batch Processing

You can process multiple tasks in batch for better performance:

```python
from anus import Agent

agent = Agent()

tasks = [
    "Summarize the benefits of exercise",
    "List 5 healthy breakfast ideas",
    "Explain the importance of sleep",
    "Provide tips for stress management",
    "Describe the benefits of meditation"
]

# Process tasks in batch
results = agent.batch_run(tasks, max_concurrency=3)

for task, result in zip(tasks, results):
    print(f"Task: {task}")
    print(f"Result: {result}")
    print("---")
```

### Caching

You can enable caching to improve performance for repeated tasks:

```python
from anus import Agent, CacheConfig

# Configure caching
cache_config = CacheConfig(
    enabled=True,
    ttl=3600,  # Cache entries expire after 1 hour
    max_size=1000  # Maximum number of cache entries
)

# Create agent with caching
agent = Agent(cache_config=cache_config)

# First call will execute normally
result1 = agent.run("What is the capital of France?")

# Second call with the same input will use cached result
result2 = agent.run("What is the capital of France?")  # Much faster
```

### Streaming Responses

You can stream responses for better user experience:

```python
from anus import Agent

agent = Agent()

# Stream the response
for chunk in agent.stream_run("Write a short story about a robot learning to feel emotions"):
    print(chunk, end="", flush=True)
```

## Integration with External Systems

### API Integration

You can expose Anus AI as an API:

```python
from fastapi import FastAPI
from anus import Agent
from pydantic import BaseModel

app = FastAPI()
agent = Agent()

class TaskRequest(BaseModel):
    task: str
    mode: str = "single"

@app.post("/run")
async def run_task(request: TaskRequest):
    response = agent.run(request.task, mode=request.mode)
    return {"result": response}

# Run with: uvicorn api:app --host 0.0.0.0 --port 8000
```

### Database Integration

You can integrate Anus with databases:

```python
import sqlite3
from anus import Agent

# Create a database connection
conn = sqlite3.connect("anus_data.db")
cursor = conn.cursor()

# Create a table
cursor.execute("""
CREATE TABLE IF NOT EXISTS tasks (
    id INTEGER PRIMARY KEY,
    task TEXT,
    result TEXT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
)
""")
conn.commit()

# Create an agent
agent = Agent()

# Run a task and store the result
task = "Explain the theory of relativity"
result = agent.run(task)

# Store in database
cursor.execute("INSERT INTO tasks (task, result) VALUES (?, ?)", (task, result))
conn.commit()

# Query the database
cursor.execute("SELECT * FROM tasks")
for row in cursor.fetchall():
    print(row)

# Close the connection
conn.close()
```

### Webhook Integration

You can set up webhooks for asynchronous processing:

```python
from anus import Agent, WebhookConfig
import requests

# Configure webhooks
webhook_config = WebhookConfig(
    success_url="https://example.com/webhooks/success",
    failure_url="https://example.com/webhooks/failure",
    headers={"Authorization": "Bearer your_token"}
)

# Create agent with webhook configuration
agent = Agent(webhook_config=webhook_config)

# Run task asynchronously
task_id = agent.run_async("Generate a marketing plan for a new product")

# The result will be sent to the success or failure webhook
# You can also check the status
status = agent.get_task_status(task_id)
print(f"Task status: {status}")
```

## Deployment Strategies

### Docker Deployment

You can deploy Anus AI using Docker:

```bash
# Build the Docker image
docker build -t anus-ai .

# Run the container
docker run -p 8000:8000 -v ./config:/app/config -v ./data:/app/data anus-ai
```

### Kubernetes Deployment

For more complex deployments, you can use Kubernetes:

```yaml
# anus-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: anus-ai
spec:
  replicas: 3
  selector:
    matchLabels:
      app: anus-ai
  template:
    metadata:
      labels:
        app: anus-ai
    spec:
      containers:
      - name: anus-ai
        image: anus-ai:latest
        ports:
        - containerPort: 8000
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
        - name: data-volume
          mountPath: /app/data
      volumes:
      - name: config-volume
        configMap:
          name: anus-config
      - name: data-volume
        persistentVolumeClaim:
          claimName: anus-data-pvc
```

### Serverless Deployment

You can deploy Anus AI as a serverless function:

```python
# AWS Lambda function
import json
from anus import Agent

agent = Agent()

def lambda_handler(event, context):
    task = event.get('task')
    if not task:
        return {
            'statusCode': 400,
            'body': json.dumps({'error': 'Task parameter is required'})
        }
    
    try:
        result = agent.run(task)
        return {
            'statusCode': 200,
            'body': json.dumps({'result': result})
        }
    except Exception as e:
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }
```

## Conclusion

This advanced usage guide demonstrates the flexibility and power of the Anus AI framework. By leveraging these advanced features, you can build sophisticated AI agent systems tailored to your specific needs.

For more information, refer to the [API Reference](api_reference.md) and [Architecture Overview](architecture_overview.md) documents.
````

## docs/architecture_overview.md

- Characters: 10690
- Tokens: 0

````markdown
# Architecture Overview

This document provides a detailed overview of the Anus AI architecture, explaining how the different components work together to create a powerful and flexible AI agent system.

## System Architecture

Anus AI is built on a modular architecture that allows for flexibility, extensibility, and robustness. The system is composed of several key components that work together to provide a comprehensive AI agent framework.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         Anus AI System                          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Core Engine ‚îÇ   ‚îÇ Agent System‚îÇ   ‚îÇ   Tool Ecosystem    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ         ‚îÇ                ‚îÇ                      ‚îÇ               ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                          ‚îÇ                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                   Model Integration                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                          ‚îÇ                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                   User Interface                        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Core Engine

The Core Engine is the heart of the Anus AI system, responsible for orchestrating the various components and managing the overall flow of information and control.

#### Components

- **Agent Orchestrator**: Manages the lifecycle of agents, handles agent creation, destruction, and resource allocation.
- **Task Planner**: Breaks down complex tasks into manageable steps, assigns steps to appropriate agents or tools.
- **Memory Manager**: Maintains short-term and long-term memory, manages conversation history and context.
- **Tool Manager**: Provides a standardized API for tool integration, tool discovery and registration system.

#### Key Features

- **Dynamic Resource Allocation**: Intelligently allocates computational resources based on task requirements.
- **Fault Tolerance**: Implements retry and recovery mechanisms for handling failures.
- **Scalability**: Designed to scale from simple single-agent tasks to complex multi-agent collaborations.

### Agent System

The Agent System provides the intelligence and decision-making capabilities of the Anus AI framework.

#### Components

- **Base Agent**: Abstract base class for all agent types with common functionality.
- **Single Agent**: Simplified agent implementation for straightforward tasks.
- **Multi-Agent System**: Implementation of multi-agent collaboration system.
- **Role Manager**: Manages predefined agent role templates and custom role creation.
- **Communication Protocol**: Handles inter-agent communication and message routing.

#### Key Features

- **Role-Based Specialization**: Agents can specialize in different roles (Researcher, Coder, Planner, etc.).
- **Adaptive Behavior**: Agents can adapt their behavior based on task requirements and context.
- **Collaborative Decision-Making**: Agents can work together to solve complex problems.

### Tool Ecosystem

The Tool Ecosystem provides the capabilities for agents to interact with the external world and perform specific tasks.

#### Components

- **Base Tool**: Abstract base class for all tools with common functionality and interface.
- **Web Tools**: Browser automation, web scraping, and data extraction.
- **Search Tools**: Search engine integration, Wikipedia access, and information retrieval.
- **Document Tools**: PDF parsing, Office document handling, and data extraction.
- **Code Tools**: Secure Python execution sandbox and code analysis.
- **Multimodal Tools**: Image, audio, and video processing capabilities.

#### Key Features

- **Standardized Interface**: All tools implement a common interface for easy integration.
- **Security**: Tools are designed with security in mind, with sandboxing and permission controls.
- **Extensibility**: New tools can be easily added to the ecosystem.

### Model Integration

The Model Integration layer provides the connection to various language models and AI capabilities.

#### Components

- **Model Manager**: Handles model selection, switching, and fallback mechanisms.
- **OpenAI Adapter**: Integration with OpenAI API models (GPT-4, etc.).
- **Open-Source Adapter**: Integration with open-source models (Llama, Mistral, etc.).
- **Vision Model Adapter**: Integration with vision models for image understanding.

#### Key Features

- **Model Agnostic**: Works with a variety of language models from different providers.
- **Fallback Mechanisms**: Gracefully handles API issues by switching to alternative models.
- **Cost Optimization**: Intelligently selects models based on task requirements and cost considerations.

### User Interface

The User Interface layer provides the means for users to interact with the Anus AI system.

#### Components

- **CLI**: Command-line interface for interacting with the Anus AI agent.
- **Web Interface**: Optional web-based user interface for the Anus AI agent.
- **API**: RESTful API for integration with external systems.

#### Key Features

- **Multiple Interaction Modes**: Supports different ways of interacting with the system.
- **Conversation History**: Maintains and displays conversation history.
- **Task Monitoring**: Provides visibility into task progress and status.

## Data Flow

The following diagram illustrates the flow of data through the Anus AI system:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ User Interface‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Core Engine ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ External ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇTool Ecosystem ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇAgent System ‚îÇ
‚îÇ Systems  ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ
                                              ‚ñº
                                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                       ‚îÇ    Model    ‚îÇ
                                       ‚îÇ Integration ‚îÇ
                                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

1. The user submits a task or query through the User Interface.
2. The User Interface forwards the request to the Core Engine.
3. The Core Engine analyzes the task and activates the appropriate Agent System components.
4. The Agent System processes the task, using the Model Integration layer for reasoning and decision-making.
5. The Agent System uses the Tool Ecosystem to interact with external systems as needed.
6. Results flow back through the system to the User Interface, which presents them to the user.

## Implementation Details

### Programming Language and Dependencies

Anus AI is implemented in Python 3.11+, leveraging the following key dependencies:

- **LangChain**: For building and connecting language model applications
- **Pydantic**: For data validation and settings management
- **Playwright**: For browser automation
- **FastAPI**: For API development
- **Rich**: For terminal user interface

### Code Organization

The codebase is organized into modules corresponding to the architectural components:

```
anus/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py
‚îÇ   ‚îú‚îÄ‚îÄ planner.py
‚îÇ   ‚îú‚îÄ‚îÄ memory.py
‚îÇ   ‚îî‚îÄ‚îÄ tool_manager.py
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ single_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ multi_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ roles.py
‚îÇ   ‚îî‚îÄ‚îÄ communication.py
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ base_tool.py
‚îÇ   ‚îú‚îÄ‚îÄ web_tools.py
‚îÇ   ‚îú‚îÄ‚îÄ search_tools.py
‚îÇ   ‚îú‚îÄ‚îÄ document_tools.py
‚îÇ   ‚îú‚îÄ‚îÄ code_tools.py
‚îÇ   ‚îî‚îÄ‚îÄ multimodal_tools.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ base_model.py
‚îÇ   ‚îú‚îÄ‚îÄ openai_model.py
‚îÇ   ‚îú‚îÄ‚îÄ open_source_model.py
‚îÇ   ‚îî‚îÄ‚îÄ vision_model.py
‚îî‚îÄ‚îÄ ui/
    ‚îú‚îÄ‚îÄ cli.py
    ‚îú‚îÄ‚îÄ web_interface.py
    ‚îî‚îÄ‚îÄ api.py
```

### Configuration System

Anus AI uses a flexible configuration system based on YAML files:

```yaml
llm:
  provider: openai
  model: gpt-4o
  api_key: ${OPENAI_API_KEY}
  temperature: 0.7

memory:
  type: persistent
  path: ./agent_memory

tools:
  browser:
    headless: true
    timeout: 30
  code:
    sandbox: true
    timeout: 10

logging:
  level: info
  file: anus.log
```

Environment variables can be used for sensitive information like API keys.

## Security Considerations

Anus AI is designed with security in mind:

- **Sandboxed Execution**: Code execution is performed in a sandboxed environment.
- **API Key Management**: Sensitive information is handled securely.
- **Permission System**: Fine-grained control over agent capabilities.
- **Audit Logging**: Comprehensive logging of all agent actions.

## Performance Optimization

Anus AI includes several performance optimizations:

- **Caching**: Results are cached to avoid redundant API calls.
- **Batching**: Requests are batched when possible to reduce API calls.
- **Streaming**: Responses are streamed for better user experience.
- **Parallel Execution**: Tasks are executed in parallel when possible.

## Extensibility

Anus AI is designed to be easily extended:

- **Plugin System**: Custom plugins can be developed to extend functionality.
- **Custom Tools**: New tools can be created by implementing the base tool interface.
- **Custom Agents**: New agent types can be created by extending the base agent class.
- **Custom Models**: Support for new models can be added by implementing the model interface.

## Future Directions

The Anus AI architecture is designed to evolve over time. Future directions include:

- **Enhanced Multi-Agent Collaboration**: More sophisticated agent interaction patterns.
- **Improved Tool Ecosystem**: Additional specialized tools for domain-specific tasks.
- **Advanced Memory Systems**: More sophisticated memory and context management.
- **Reinforcement Learning**: Integration of RL techniques for agent improvement.
- **Multimodal Capabilities**: Enhanced support for images, audio, and video.

## Conclusion

The Anus AI architecture provides a flexible, extensible, and powerful framework for building AI agent systems. By combining a modular design with a comprehensive tool ecosystem and support for multiple models, Anus AI enables a wide range of applications from simple task automation to complex multi-agent collaborations.
````

## docs/architecture.md

- Characters: 8201
- Tokens: 0

```markdown
# Anus AI Agent Architecture

## Overview
Anus (Autonomous Networked Utility System) is an open-source AI agent framework designed to provide accessible, powerful, and flexible AI assistance for a wide range of tasks. Inspired by OpenManus and OWL, Anus combines the simplicity and accessibility of OpenManus with the multi-agent collaboration capabilities of OWL to create a unique and effective AI agent system.

## Core Philosophy
- **Accessibility**: No barriers to entry, completely open-source with minimal setup requirements
- **Flexibility**: Support for multiple LLM backends and customizable components
- **Extensibility**: Modular design that allows for easy addition of new capabilities
- **Transparency**: Clear documentation and explainable AI processes
- **Community-Driven**: Designed for active community contribution and improvement

## System Architecture

### High-Level Components

1. **Core Engine**
   - Agent Orchestration System
   - Task Planning and Execution Framework
   - Memory and Context Management
   - Tool Integration Interface

2. **Agent System**
   - Single-Agent Mode
   - Multi-Agent Collaboration Mode
   - Agent Role Definition Framework
   - Inter-Agent Communication Protocol

3. **Tool Ecosystem**
   - Web Interaction Tools (Browser Automation)
   - Information Retrieval Tools (Search, Wikipedia)
   - Document Processing Tools (PDF, Word, Excel)
   - Code Execution Environment
   - Multimodal Processing (Images, Audio, Video)

4. **Model Integration**
   - OpenAI API Support
   - Open-Source Model Support (Llama, Mistral, etc.)
   - Model Switching and Fallback Mechanisms
   - Vision Model Integration

5. **User Interface**
   - Command-Line Interface
   - Web Interface (Optional)
   - API for Integration with Other Systems

### Detailed Architecture

#### Core Engine

**Agent Orchestration System**
- Manages the lifecycle of agents
- Handles agent creation, destruction, and resource allocation
- Provides monitoring and debugging capabilities

**Task Planning and Execution Framework**
- Breaks down complex tasks into manageable steps
- Assigns steps to appropriate agents or tools
- Monitors execution and handles failures
- Implements retry and recovery mechanisms

**Memory and Context Management**
- Maintains short-term and long-term memory
- Manages conversation history and context
- Implements efficient context window utilization
- Provides mechanisms for context prioritization

**Tool Integration Interface**
- Standardized API for tool integration
- Tool discovery and registration system
- Tool execution and result handling
- Security and permission management for tools

#### Agent System

**Single-Agent Mode**
- Simplified operation for straightforward tasks
- Streamlined configuration and setup
- Optimized for resource efficiency

**Multi-Agent Collaboration Mode**
- Dynamic agent creation based on task requirements
- Specialized agent roles (Researcher, Coder, Planner, etc.)
- Consensus mechanisms for decision-making
- Conflict resolution protocols

**Agent Role Definition Framework**
- Predefined role templates
- Custom role creation capabilities
- Role-specific knowledge and capabilities
- Role adaptation based on task requirements

**Inter-Agent Communication Protocol**
- Structured message format
- Conversation management
- Information sharing mechanisms
- Coordination primitives

#### Tool Ecosystem

**Web Interaction Tools**
- Browser automation using Playwright
- Web scraping and data extraction
- Form filling and submission
- Authentication handling

**Information Retrieval Tools**
- Search engine integration
- Wikipedia access
- News and current events sources
- Specialized knowledge bases

**Document Processing Tools**
- PDF parsing and analysis
- Office document handling (Word, Excel, PowerPoint)
- Image recognition and OCR
- Data extraction and transformation

**Code Execution Environment**
- Secure Python execution sandbox
- Multiple language support
- Package management
- Output capture and analysis

**Multimodal Processing**
- Image analysis and generation
- Audio processing and transcription
- Video analysis and summarization
- Chart and graph interpretation

#### Model Integration

**OpenAI API Support**
- GPT-4 and newer models
- Optimized prompt engineering
- Cost management and optimization
- Fallback mechanisms for API issues

**Open-Source Model Support**
- Integration with Hugging Face models
- Local model deployment options
- Quantization and optimization for efficiency
- Model selection based on task requirements

**Model Switching and Fallback Mechanisms**
- Automatic selection of appropriate models
- Fallback to alternative models on failure
- Performance monitoring and adaptation
- Cost-aware model selection

**Vision Model Integration**
- Image understanding capabilities
- Visual question answering
- Image generation and editing
- Multimodal reasoning

#### User Interface

**Command-Line Interface**
- Simple and intuitive commands
- Interactive mode for conversations
- Batch processing for automated tasks
- Configuration management

**Web Interface (Optional)**
- User-friendly dashboard
- Task monitoring and management
- History and conversation review
- Settings and configuration

**API for Integration**
- RESTful API for external systems
- WebSocket support for real-time applications
- Authentication and access control
- Rate limiting and usage monitoring

## Implementation Strategy

### Phase 1: Foundation
- Implement core engine with basic functionality
- Support for single-agent mode with OpenAI models
- Basic tool integration (search, code execution)
- Command-line interface

### Phase 2: Expansion
- Add multi-agent collaboration capabilities
- Expand tool ecosystem
- Integrate open-source model support
- Improve memory and context management

### Phase 3: Enhancement
- Implement advanced features (multimodal processing)
- Optimize performance and resource usage
- Add web interface
- Develop comprehensive documentation and examples

### Phase 4: Community
- Establish contribution guidelines
- Create plugin system for community extensions
- Implement feedback mechanisms
- Regular release cycle and versioning

## Unique Features of Anus AI

1. **Hybrid Agent Architecture**: Combines the simplicity of single-agent systems with the power of multi-agent collaboration.

2. **Adaptive Resource Allocation**: Dynamically allocates computational resources based on task complexity.

3. **Progressive Enhancement**: Works with minimal configuration but can scale up with additional resources and capabilities.

4. **Community-First Design**: Built from the ground up for community contributions and extensions.

5. **Transparent Operation**: Provides detailed explanations and logs of all agent actions and decisions.

6. **Cross-Platform Compatibility**: Works across different operating systems and environments.

7. **Ethical Considerations**: Built-in mechanisms for bias detection and mitigation.

8. **Privacy-Preserving Options**: Local execution capabilities for sensitive tasks.

## Comparison with Existing Systems

| Feature | Anus | OpenManus | OWL |
|---------|------|-----------|-----|
| Multi-Agent Support | ‚úÖ | ‚ùå | ‚úÖ |
| Open-Source Models | ‚úÖ | ‚úÖ | ‚úÖ |
| Browser Automation | ‚úÖ | ‚úÖ | ‚úÖ |
| Document Processing | ‚úÖ | ‚ùå | ‚úÖ |
| Code Execution | ‚úÖ | ‚úÖ | ‚úÖ |
| Local Deployment | ‚úÖ | ‚úÖ | ‚úÖ |
| Web Interface | ‚úÖ | ‚ùå | ‚ùå |
| Multimodal Support | ‚úÖ | ‚úÖ | ‚úÖ |
| Community Extensions | ‚úÖ | ‚ùå | ‚ùå |
| Ethical Framework | ‚úÖ | ‚ùå | ‚ùå |

## Technical Requirements

- Python 3.11+
- Support for various LLM APIs (OpenAI, Anthropic, etc.)
- Playwright for browser automation
- Docker support for containerized deployment
- Git for version control
- Various Python libraries for specific functionalities

## Conclusion

The Anus AI agent architecture combines the best aspects of OpenManus and OWL while introducing unique features that address limitations in both systems. By focusing on accessibility, flexibility, and community involvement, Anus aims to become a leading open-source AI agent framework that can be used for a wide range of applications, from simple task automation to complex multi-agent collaborations.
```

## docs/api_reference.md

- Characters: 7593
- Tokens: 0

````markdown
# API Reference

This document provides a comprehensive reference for the Anus AI API.

## Core Components

### Agent

The `Agent` class is the primary interface for interacting with the Anus AI system.

```python
from anus import Agent

agent = Agent(
    model="gpt-4o",
    tools=["search", "browser", "code"],
    memory_type="persistent",
    verbose=True
)
```

#### Parameters

- `model` (str, optional): The LLM model to use. Defaults to "gpt-4o".
- `tools` (list, optional): List of tools to enable. Defaults to None.
- `memory_type` (str, optional): Type of memory to use. Options: "ephemeral", "persistent". Defaults to "ephemeral".
- `verbose` (bool, optional): Whether to print verbose output. Defaults to False.
- `config` (Config, optional): Custom configuration object. Defaults to None.

#### Methods

##### run

```python
response = agent.run("Find the latest news about artificial intelligence")
```

**Parameters:**
- `task` (str): The task to execute.
- `mode` (str, optional): Execution mode. Options: "sync", "async". Defaults to "sync".
- `output_format` (str, optional): Format for the output. Options: "text", "markdown", "json". Defaults to "text".

**Returns:**
- `str`: The agent's response to the task.

##### chat

```python
response = agent.chat("What is the capital of France?")
```

**Parameters:**
- `message` (str): The message to send to the agent.
- `context` (dict, optional): Additional context for the conversation. Defaults to None.

**Returns:**
- `str`: The agent's response to the message.

##### save_memory

```python
agent.save_memory("memory.json")
```

**Parameters:**
- `path` (str): Path to save the memory to.

**Returns:**
- `bool`: True if successful, False otherwise.

##### load_memory

```python
agent.load_memory("memory.json")
```

**Parameters:**
- `path` (str): Path to load the memory from.

**Returns:**
- `bool`: True if successful, False otherwise.

### Society

The `Society` class enables multi-agent collaboration.

```python
from anus import Society, Agent

researcher = Agent(role="researcher")
analyst = Agent(role="analyst")
writer = Agent(role="writer")

society = Society(
    agents=[researcher, analyst, writer],
    coordination_strategy="consensus",
    verbose=True
)
```

#### Parameters

- `agents` (list): List of Agent objects.
- `coordination_strategy` (str, optional): Strategy for agent coordination. Options: "consensus", "hierarchical", "autonomous". Defaults to "consensus".
- `verbose` (bool, optional): Whether to print verbose output. Defaults to False.
- `config` (Config, optional): Custom configuration object. Defaults to None.

#### Methods

##### run

```python
response = society.run("Research the impact of AI on healthcare")
```

**Parameters:**
- `task` (str): The task to execute.
- `mode` (str, optional): Execution mode. Options: "sync", "async". Defaults to "sync".
- `output_format` (str, optional): Format for the output. Options: "text", "markdown", "json". Defaults to "text".

**Returns:**
- `str`: The society's response to the task.

##### add_agent

```python
society.add_agent(new_agent)
```

**Parameters:**
- `agent` (Agent): The agent to add to the society.

**Returns:**
- `bool`: True if successful, False otherwise.

##### remove_agent

```python
society.remove_agent(agent_id)
```

**Parameters:**
- `agent_id` (str): ID of the agent to remove.

**Returns:**
- `bool`: True if successful, False otherwise.

### Config

The `Config` class provides configuration options for the Anus AI system.

```python
from anus import Config

config = Config(
    llm={
        "provider": "anthropic",
        "model": "claude-3-opus",
        "temperature": 0.7,
    },
    memory={
        "type": "persistent",
        "path": "./agent_memory",
    },
    tools={
        "browser": {"headless": False},
        "code": {"sandbox": True},
    }
)
```

#### Parameters

- `llm` (dict, optional): LLM configuration.
- `memory` (dict, optional): Memory configuration.
- `tools` (dict, optional): Tool configuration.
- `ui` (dict, optional): UI configuration.
- `logging` (dict, optional): Logging configuration.

## Tools

### SearchTool

```python
from anus.tools import SearchTool

search_tool = SearchTool(
    engine="google",
    max_results=5
)
```

#### Parameters

- `engine` (str, optional): Search engine to use. Options: "google", "bing", "duckduckgo". Defaults to "google".
- `max_results` (int, optional): Maximum number of results to return. Defaults to 5.

### BrowserTool

```python
from anus.tools import BrowserTool

browser_tool = BrowserTool(
    headless=True,
    timeout=30
)
```

#### Parameters

- `headless` (bool, optional): Whether to run the browser in headless mode. Defaults to True.
- `timeout` (int, optional): Timeout in seconds for browser operations. Defaults to 30.

### DocumentTool

```python
from anus.tools import DocumentTool

document_tool = DocumentTool(
    supported_formats=["pdf", "docx", "xlsx"]
)
```

#### Parameters

- `supported_formats` (list, optional): List of supported document formats. Defaults to ["pdf", "docx", "xlsx", "pptx"].

### CodeTool

```python
from anus.tools import CodeTool

code_tool = CodeTool(
    sandbox=True,
    timeout=10
)
```

#### Parameters

- `sandbox` (bool, optional): Whether to run code in a sandbox. Defaults to True.
- `timeout` (int, optional): Timeout in seconds for code execution. Defaults to 10.

## Command-Line Interface

The Anus AI CLI provides a command-line interface for interacting with the system.

### Commands

#### run

```bash
anus run "Find the latest news about artificial intelligence"
```

**Options:**
- `--config`: Path to configuration file.
- `--mode`: Agent mode (single or multi).
- `--verbose`: Enable verbose output.
- `--output`: Output format (text, markdown, json).

#### interactive

```bash
anus interactive
```

**Options:**
- `--config`: Path to configuration file.
- `--mode`: Agent mode (single or multi).
- `--verbose`: Enable verbose output.

#### init

```bash
anus init
```

**Options:**
- `--force`: Overwrite existing configuration.
- `--minimal`: Create minimal configuration.

#### version

```bash
anus version
```

Displays the current version of Anus AI.

## Error Handling

Anus AI provides a comprehensive error handling system.

### AnusError

Base class for all Anus AI errors.

### ConfigError

Raised when there is an issue with the configuration.

### ModelError

Raised when there is an issue with the LLM model.

### ToolError

Raised when there is an issue with a tool.

### MemoryError

Raised when there is an issue with the memory system.

## Examples

### Basic Usage

```python
from anus import Agent

agent = Agent()
response = agent.run("What is the capital of France?")
print(response)
```

### Multi-Agent Collaboration

```python
from anus import Society, Agent

researcher = Agent(role="researcher")
analyst = Agent(role="analyst")
writer = Agent(role="writer")

society = Society(agents=[researcher, analyst, writer])
response = society.run("Research the impact of AI on healthcare")
print(response)
```

### Custom Configuration

```python
from anus import Agent, Config

config = Config(
    llm={
        "provider": "anthropic",
        "model": "claude-3-opus",
        "temperature": 0.7,
    },
    memory={
        "type": "persistent",
        "path": "./agent_memory",
    },
    tools={
        "browser": {"headless": False},
        "code": {"sandbox": True},
    }
)

agent = Agent(config=config)
response = agent.run("Create an interactive data visualization for climate change data")
print(response)
```
````

## docs/getting_started.md

- Characters: 3594
- Tokens: 0

````markdown
# Getting Started with Anus AI

This guide will help you get started with using the Anus AI framework for your projects.

## Prerequisites

Before you begin, ensure you have the following installed:
- Python 3.11 or higher
- pip (Python package installer)
- Git (optional, for cloning the repository)

## Installation

### Quick Installation

The easiest way to install Anus AI is via pip:

```bash
pip install anus-ai
```

### Development Installation

If you want to contribute to Anus AI or use the latest development version:

```bash
# Clone the repository
git clone https://github.com/anus-ai/anus.git
cd anus

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e .
```

## Configuration

After installation, you'll need to configure Anus AI with your API keys:

1. Create a configuration file:

```bash
anus init
```

2. Edit the generated `.anus/config.yaml` file with your API keys:

```yaml
llm:
  provider: openai
  api_key: your_openai_api_key
  model: gpt-4o

# Optional: Configure other providers
anthropic:
  api_key: your_anthropic_api_key
```

## Your First Anus AI Project

### Simple Question Answering

Create a file named `simple_question.py`:

```python
from anus import Agent

# Create a single agent
agent = Agent()

# Ask a simple question
response = agent.run("What is the capital of France?")
print(response)
```

Run the script:

```bash
python simple_question.py
```

### Web Search Example

Create a file named `web_search.py`:

```python
from anus import Agent
from anus.tools import SearchTool

# Create an agent with search capabilities
agent = Agent(tools=[SearchTool()])

# Search for information
response = agent.run("Find the latest research on quantum computing")
print(response)
```

Run the script:

```bash
python web_search.py
```

### Multi-Agent Collaboration

Create a file named `multi_agent.py`:

```python
from anus import Society, Agent

# Create specialized agents
researcher = Agent(role="researcher")
analyst = Agent(role="analyst")
writer = Agent(role="writer")

# Create a society of agents
society = Society(agents=[researcher, analyst, writer])

# Execute a complex task with collaboration
response = society.run(
    "Research the impact of artificial intelligence on healthcare, " 
    "analyze the findings, and write a comprehensive report"
)
print(response)
```

Run the script:

```bash
python multi_agent.py
```

## Using the Command-Line Interface

Anus AI comes with a powerful command-line interface:

```bash
# Run a simple task
anus run "What is the population of Tokyo?"

# Run in interactive mode
anus interactive

# Run with a specific configuration file
anus run --config custom_config.yaml "Summarize this article: https://example.com/article"
```

## Next Steps

- Explore the [Documentation](https://anus-ai.github.io/docs) for more detailed information
- Check out the [Examples](https://github.com/anus-ai/anus/tree/main/examples) directory for more use cases
- Join our [Community](https://discord.gg/anus-ai) to connect with other users and developers
- Consider [Contributing](https://github.com/anus-ai/anus/blob/main/CONTRIBUTING.md) to the project

## Getting Help

If you encounter any issues or have questions:

- Check the [FAQ](https://anus-ai.github.io/docs/faq)
- Search for existing [Issues](https://github.com/anus-ai/anus/issues)
- Ask for help in our [Discord](https://discord.gg/anus-ai) community
- Open a new [Issue](https://github.com/anus-ai/anus/issues/new) if you found a bug
````

## __init__.py

- Characters: 0
- Tokens: 0

```python

```

## todo.md

- Characters: 825
- Tokens: 0

```markdown
# Anus AI Project Todo List

## Research Phase
- [x] Research open-source AI agents
- [x] Analyze OpenManus repository (github.com/mannaandpoem/OpenManus)
- [x] Analyze OWL repository (github.com/camel-ai/owl)

## Design Phase
- [x] Define Anus AI agent architecture
- [x] Create project structure

## Documentation Phase
- [x] Draft README introduction
- [x] Draft README features and capabilities
- [x] Draft README installation instructions
- [x] Draft README usage examples
- [x] Draft README contribution guidelines
- [x] Draft README license information
- [x] Create project logo and badges
- [x] Finalize README.md
- [x] Create additional documentation

## Finalization Phase
- [x] Prepare GitHub repository files
- [ ] Review and refine all content
- [ ] Compile final deliverables
- [ ] Report and send files to user
```

## Statistics

- Total Files: 61
- Total Characters: 341821
- Total Tokens: 0
`````

## docs/advanced_usage.md

- Characters: 13567
- Tokens: 0

````markdown
# Advanced Usage Guide

This document provides advanced usage examples and techniques for getting the most out of the Anus AI framework.

## Table of Contents
- [Multi-Agent Collaboration](#multi-agent-collaboration)
- [Custom Tool Development](#custom-tool-development)
- [Advanced Configuration](#advanced-configuration)
- [Memory Management](#memory-management)
- [Performance Optimization](#performance-optimization)
- [Integration with External Systems](#integration-with-external-systems)
- [Deployment Strategies](#deployment-strategies)

## Multi-Agent Collaboration

### Creating Specialized Agent Roles

You can create specialized agents with different roles to handle complex tasks:

```python
from anus import Agent, Society

# Create specialized agents
researcher = Agent(
    role="researcher",
    tools=["search", "browser"],
    model="gpt-4o"
)

analyst = Agent(
    role="analyst",
    tools=["code", "document"],
    model="claude-3-opus"
)

writer = Agent(
    role="writer",
    tools=["document"],
    model="gpt-4o"
)

# Create a society of agents
society = Society(
    agents=[researcher, analyst, writer],
    coordination_strategy="consensus"
)

# Execute a complex task with collaboration
response = society.run(
    "Research the impact of artificial intelligence on healthcare, " 
    "analyze the findings, and write a comprehensive report"
)
```

### Custom Coordination Strategies

Anus supports different coordination strategies for multi-agent collaboration:

```python
# Consensus strategy - all agents must agree on decisions
society = Society(
    agents=[agent1, agent2, agent3],
    coordination_strategy="consensus"
)

# Hierarchical strategy - one agent leads and delegates to others
society = Society(
    agents=[leader_agent, worker_agent1, worker_agent2],
    coordination_strategy="hierarchical",
    leader_agent_id=leader_agent.id
)

# Autonomous strategy - agents work independently and share results
society = Society(
    agents=[agent1, agent2, agent3],
    coordination_strategy="autonomous"
)
```

### Inter-Agent Communication

You can customize how agents communicate with each other:

```python
from anus import Society, Agent, CommunicationProtocol

# Create a custom communication protocol
protocol = CommunicationProtocol(
    message_format="structured",
    synchronization="async",
    logging=True
)

# Create a society with the custom protocol
society = Society(
    agents=[agent1, agent2, agent3],
    communication_protocol=protocol
)
```

## Custom Tool Development

### Creating a Custom Tool

You can create custom tools by extending the `BaseTool` class:

```python
from anus.tools import BaseTool
from typing import Dict, Any

class WeatherTool(BaseTool):
    """Tool for getting weather information."""
    
    def __init__(self, api_key: str):
        super().__init__()
        self.api_key = api_key
        self.name = "weather_tool"
        self.description = "Gets weather information for a location"
    
    def _execute(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Execute the tool with the given parameters."""
        location = params.get("location")
        if not location:
            return {"error": "Location parameter is required"}
        
        # Implement weather API call here
        # ...
        
        return {
            "location": location,
            "temperature": 72,
            "conditions": "sunny",
            "humidity": 45
        }

# Use the custom tool
from anus import Agent

agent = Agent(tools=[WeatherTool(api_key="your_api_key")])
response = agent.run("What's the weather like in New York?")
```

### Tool Registration System

You can register custom tools with the tool registry:

```python
from anus.tools import register_tool, get_tool

# Register your custom tool
register_tool("weather", WeatherTool)

# Get the tool from the registry
weather_tool_class = get_tool("weather")
weather_tool = weather_tool_class(api_key="your_api_key")
```

### Tool Composition

You can compose multiple tools together:

```python
from anus.tools import ComposedTool, SearchTool, DocumentTool

# Create a composed tool that combines search and document processing
research_tool = ComposedTool(
    name="research_tool",
    tools=[SearchTool(), DocumentTool()],
    description="Searches for information and processes documents"
)

agent = Agent(tools=[research_tool])
```

## Advanced Configuration

### Environment-Specific Configuration

You can create different configurations for different environments:

```python
from anus import Config, Agent

# Development configuration
dev_config = Config.from_file("config.dev.yaml")

# Production configuration
prod_config = Config.from_file("config.prod.yaml")

# Choose configuration based on environment
import os
env = os.getenv("ANUS_ENV", "development")
config = dev_config if env == "development" else prod_config

agent = Agent(config=config)
```

### Dynamic Configuration

You can modify configuration at runtime:

```python
from anus import Agent, Config

# Create initial configuration
config = Config(
    llm={
        "provider": "openai",
        "model": "gpt-4o",
        "temperature": 0.7,
    }
)

# Create agent with initial config
agent = Agent(config=config)

# Modify configuration at runtime
agent.config.update({
    "llm": {
        "temperature": 0.2  # Lower temperature for more focused responses
    }
})

# Configuration changes take effect on next run
response = agent.run("Generate a creative story")
```

### Configuration Profiles

You can create and switch between configuration profiles:

```python
from anus import Agent, ConfigProfile

# Create configuration profiles
creative_profile = ConfigProfile(
    name="creative",
    llm={
        "temperature": 0.8,
        "top_p": 0.9
    }
)

precise_profile = ConfigProfile(
    name="precise",
    llm={
        "temperature": 0.2,
        "top_p": 0.5
    }
)

# Create agent with default configuration
agent = Agent()

# Switch to creative profile for creative tasks
agent.apply_profile(creative_profile)
creative_response = agent.run("Write a poem about AI")

# Switch to precise profile for factual tasks
agent.apply_profile(precise_profile)
precise_response = agent.run("Explain quantum computing")
```

## Memory Management

### Persistent Memory

You can save and load agent memory:

```python
from anus import Agent

# Create agent with persistent memory
agent = Agent(memory_type="persistent", memory_path="./agent_memory")

# Run some tasks
agent.run("Remember that my favorite color is blue")
agent.run("My birthday is on March 15")

# Save memory explicitly (also happens automatically on shutdown)
agent.save_memory()

# Later, create a new agent that loads the saved memory
new_agent = Agent(memory_type="persistent", memory_path="./agent_memory")

# The new agent remembers previous information
response = new_agent.run("What is my favorite color and when is my birthday?")
# Response will include blue and March 15
```

### Memory Types

Anus supports different types of memory:

```python
# Ephemeral memory (default) - lasts only for the current session
agent = Agent(memory_type="ephemeral")

# Persistent memory - saved to disk and can be loaded later
agent = Agent(memory_type="persistent", memory_path="./agent_memory")

# Vector memory - uses vector embeddings for more efficient retrieval
agent = Agent(memory_type="vector", memory_path="./vector_memory")

# Hybrid memory - combines different memory types
agent = Agent(memory_type="hybrid", memory_config={
    "short_term": "ephemeral",
    "long_term": "vector",
    "path": "./hybrid_memory"
})
```

### Memory Operations

You can perform operations on agent memory:

```python
# Add information to memory
agent.memory.add("User likes chocolate ice cream")

# Query memory
results = agent.memory.query("What does the user like?")

# Clear memory
agent.memory.clear()

# Get memory statistics
stats = agent.memory.stats()
print(f"Memory size: {stats['size']}, Items: {stats['items']}")
```

## Performance Optimization

### Batch Processing

You can process multiple tasks in batch for better performance:

```python
from anus import Agent

agent = Agent()

tasks = [
    "Summarize the benefits of exercise",
    "List 5 healthy breakfast ideas",
    "Explain the importance of sleep",
    "Provide tips for stress management",
    "Describe the benefits of meditation"
]

# Process tasks in batch
results = agent.batch_run(tasks, max_concurrency=3)

for task, result in zip(tasks, results):
    print(f"Task: {task}")
    print(f"Result: {result}")
    print("---")
```

### Caching

You can enable caching to improve performance for repeated tasks:

```python
from anus import Agent, CacheConfig

# Configure caching
cache_config = CacheConfig(
    enabled=True,
    ttl=3600,  # Cache entries expire after 1 hour
    max_size=1000  # Maximum number of cache entries
)

# Create agent with caching
agent = Agent(cache_config=cache_config)

# First call will execute normally
result1 = agent.run("What is the capital of France?")

# Second call with the same input will use cached result
result2 = agent.run("What is the capital of France?")  # Much faster
```

### Streaming Responses

You can stream responses for better user experience:

```python
from anus import Agent

agent = Agent()

# Stream the response
for chunk in agent.stream_run("Write a short story about a robot learning to feel emotions"):
    print(chunk, end="", flush=True)
```

## Integration with External Systems

### API Integration

You can expose Anus AI as an API:

```python
from fastapi import FastAPI
from anus import Agent
from pydantic import BaseModel

app = FastAPI()
agent = Agent()

class TaskRequest(BaseModel):
    task: str
    mode: str = "single"

@app.post("/run")
async def run_task(request: TaskRequest):
    response = agent.run(request.task, mode=request.mode)
    return {"result": response}

# Run with: uvicorn api:app --host 0.0.0.0 --port 8000
```

### Database Integration

You can integrate Anus with databases:

```python
import sqlite3
from anus import Agent

# Create a database connection
conn = sqlite3.connect("anus_data.db")
cursor = conn.cursor()

# Create a table
cursor.execute("""
CREATE TABLE IF NOT EXISTS tasks (
    id INTEGER PRIMARY KEY,
    task TEXT,
    result TEXT,
    timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
)
""")
conn.commit()

# Create an agent
agent = Agent()

# Run a task and store the result
task = "Explain the theory of relativity"
result = agent.run(task)

# Store in database
cursor.execute("INSERT INTO tasks (task, result) VALUES (?, ?)", (task, result))
conn.commit()

# Query the database
cursor.execute("SELECT * FROM tasks")
for row in cursor.fetchall():
    print(row)

# Close the connection
conn.close()
```

### Webhook Integration

You can set up webhooks for asynchronous processing:

```python
from anus import Agent, WebhookConfig
import requests

# Configure webhooks
webhook_config = WebhookConfig(
    success_url="https://example.com/webhooks/success",
    failure_url="https://example.com/webhooks/failure",
    headers={"Authorization": "Bearer your_token"}
)

# Create agent with webhook configuration
agent = Agent(webhook_config=webhook_config)

# Run task asynchronously
task_id = agent.run_async("Generate a marketing plan for a new product")

# The result will be sent to the success or failure webhook
# You can also check the status
status = agent.get_task_status(task_id)
print(f"Task status: {status}")
```

## Deployment Strategies

### Docker Deployment

You can deploy Anus AI using Docker:

```bash
# Build the Docker image
docker build -t anus-ai .

# Run the container
docker run -p 8000:8000 -v ./config:/app/config -v ./data:/app/data anus-ai
```

### Kubernetes Deployment

For more complex deployments, you can use Kubernetes:

```yaml
# anus-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: anus-ai
spec:
  replicas: 3
  selector:
    matchLabels:
      app: anus-ai
  template:
    metadata:
      labels:
        app: anus-ai
    spec:
      containers:
      - name: anus-ai
        image: anus-ai:latest
        ports:
        - containerPort: 8000
        volumeMounts:
        - name: config-volume
          mountPath: /app/config
        - name: data-volume
          mountPath: /app/data
      volumes:
      - name: config-volume
        configMap:
          name: anus-config
      - name: data-volume
        persistentVolumeClaim:
          claimName: anus-data-pvc
```

### Serverless Deployment

You can deploy Anus AI as a serverless function:

```python
# AWS Lambda function
import json
from anus import Agent

agent = Agent()

def lambda_handler(event, context):
    task = event.get('task')
    if not task:
        return {
            'statusCode': 400,
            'body': json.dumps({'error': 'Task parameter is required'})
        }
    
    try:
        result = agent.run(task)
        return {
            'statusCode': 200,
            'body': json.dumps({'result': result})
        }
    except Exception as e:
        return {
            'statusCode': 500,
            'body': json.dumps({'error': str(e)})
        }
```

## Conclusion

This advanced usage guide demonstrates the flexibility and power of the Anus AI framework. By leveraging these advanced features, you can build sophisticated AI agent systems tailored to your specific needs.

For more information, refer to the [API Reference](api_reference.md) and [Architecture Overview](architecture_overview.md) documents.
````

## docs/architecture_overview.md

- Characters: 10690
- Tokens: 0

````markdown
# Architecture Overview

This document provides a detailed overview of the Anus AI architecture, explaining how the different components work together to create a powerful and flexible AI agent system.

## System Architecture

Anus AI is built on a modular architecture that allows for flexibility, extensibility, and robustness. The system is composed of several key components that work together to provide a comprehensive AI agent framework.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         Anus AI System                          ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ Core Engine ‚îÇ   ‚îÇ Agent System‚îÇ   ‚îÇ   Tool Ecosystem    ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ         ‚îÇ                ‚îÇ                      ‚îÇ               ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                          ‚îÇ                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                   Model Integration                     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                          ‚îÇ                                      ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ                   User Interface                        ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Core Engine

The Core Engine is the heart of the Anus AI system, responsible for orchestrating the various components and managing the overall flow of information and control.

#### Components

- **Agent Orchestrator**: Manages the lifecycle of agents, handles agent creation, destruction, and resource allocation.
- **Task Planner**: Breaks down complex tasks into manageable steps, assigns steps to appropriate agents or tools.
- **Memory Manager**: Maintains short-term and long-term memory, manages conversation history and context.
- **Tool Manager**: Provides a standardized API for tool integration, tool discovery and registration system.

#### Key Features

- **Dynamic Resource Allocation**: Intelligently allocates computational resources based on task requirements.
- **Fault Tolerance**: Implements retry and recovery mechanisms for handling failures.
- **Scalability**: Designed to scale from simple single-agent tasks to complex multi-agent collaborations.

### Agent System

The Agent System provides the intelligence and decision-making capabilities of the Anus AI framework.

#### Components

- **Base Agent**: Abstract base class for all agent types with common functionality.
- **Single Agent**: Simplified agent implementation for straightforward tasks.
- **Multi-Agent System**: Implementation of multi-agent collaboration system.
- **Role Manager**: Manages predefined agent role templates and custom role creation.
- **Communication Protocol**: Handles inter-agent communication and message routing.

#### Key Features

- **Role-Based Specialization**: Agents can specialize in different roles (Researcher, Coder, Planner, etc.).
- **Adaptive Behavior**: Agents can adapt their behavior based on task requirements and context.
- **Collaborative Decision-Making**: Agents can work together to solve complex problems.

### Tool Ecosystem

The Tool Ecosystem provides the capabilities for agents to interact with the external world and perform specific tasks.

#### Components

- **Base Tool**: Abstract base class for all tools with common functionality and interface.
- **Web Tools**: Browser automation, web scraping, and data extraction.
- **Search Tools**: Search engine integration, Wikipedia access, and information retrieval.
- **Document Tools**: PDF parsing, Office document handling, and data extraction.
- **Code Tools**: Secure Python execution sandbox and code analysis.
- **Multimodal Tools**: Image, audio, and video processing capabilities.

#### Key Features

- **Standardized Interface**: All tools implement a common interface for easy integration.
- **Security**: Tools are designed with security in mind, with sandboxing and permission controls.
- **Extensibility**: New tools can be easily added to the ecosystem.

### Model Integration

The Model Integration layer provides the connection to various language models and AI capabilities.

#### Components

- **Model Manager**: Handles model selection, switching, and fallback mechanisms.
- **OpenAI Adapter**: Integration with OpenAI API models (GPT-4, etc.).
- **Open-Source Adapter**: Integration with open-source models (Llama, Mistral, etc.).
- **Vision Model Adapter**: Integration with vision models for image understanding.

#### Key Features

- **Model Agnostic**: Works with a variety of language models from different providers.
- **Fallback Mechanisms**: Gracefully handles API issues by switching to alternative models.
- **Cost Optimization**: Intelligently selects models based on task requirements and cost considerations.

### User Interface

The User Interface layer provides the means for users to interact with the Anus AI system.

#### Components

- **CLI**: Command-line interface for interacting with the Anus AI agent.
- **Web Interface**: Optional web-based user interface for the Anus AI agent.
- **API**: RESTful API for integration with external systems.

#### Key Features

- **Multiple Interaction Modes**: Supports different ways of interacting with the system.
- **Conversation History**: Maintains and displays conversation history.
- **Task Monitoring**: Provides visibility into task progress and status.

## Data Flow

The following diagram illustrates the flow of data through the Anus AI system:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User    ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ User Interface‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ Core Engine ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                              ‚îÇ
                                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ External ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇTool Ecosystem ‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇAgent System ‚îÇ
‚îÇ Systems  ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ
                                              ‚ñº
                                       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                       ‚îÇ    Model    ‚îÇ
                                       ‚îÇ Integration ‚îÇ
                                       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

1. The user submits a task or query through the User Interface.
2. The User Interface forwards the request to the Core Engine.
3. The Core Engine analyzes the task and activates the appropriate Agent System components.
4. The Agent System processes the task, using the Model Integration layer for reasoning and decision-making.
5. The Agent System uses the Tool Ecosystem to interact with external systems as needed.
6. Results flow back through the system to the User Interface, which presents them to the user.

## Implementation Details

### Programming Language and Dependencies

Anus AI is implemented in Python 3.11+, leveraging the following key dependencies:

- **LangChain**: For building and connecting language model applications
- **Pydantic**: For data validation and settings management
- **Playwright**: For browser automation
- **FastAPI**: For API development
- **Rich**: For terminal user interface

### Code Organization

The codebase is organized into modules corresponding to the architectural components:

```
anus/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îú‚îÄ‚îÄ orchestrator.py
‚îÇ   ‚îú‚îÄ‚îÄ planner.py
‚îÇ   ‚îú‚îÄ‚îÄ memory.py
‚îÇ   ‚îî‚îÄ‚îÄ tool_manager.py
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ base_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ single_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ multi_agent.py
‚îÇ   ‚îú‚îÄ‚îÄ roles.py
‚îÇ   ‚îî‚îÄ‚îÄ communication.py
‚îú‚îÄ‚îÄ tools/
‚îÇ   ‚îú‚îÄ‚îÄ base_tool.py
‚îÇ   ‚îú‚îÄ‚îÄ web_tools.py
‚îÇ   ‚îú‚îÄ‚îÄ search_tools.py
‚îÇ   ‚îú‚îÄ‚îÄ document_tools.py
‚îÇ   ‚îú‚îÄ‚îÄ code_tools.py
‚îÇ   ‚îî‚îÄ‚îÄ multimodal_tools.py
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ base_model.py
‚îÇ   ‚îú‚îÄ‚îÄ openai_model.py
‚îÇ   ‚îú‚îÄ‚îÄ open_source_model.py
‚îÇ   ‚îî‚îÄ‚îÄ vision_model.py
‚îî‚îÄ‚îÄ ui/
    ‚îú‚îÄ‚îÄ cli.py
    ‚îú‚îÄ‚îÄ web_interface.py
    ‚îî‚îÄ‚îÄ api.py
```

### Configuration System

Anus AI uses a flexible configuration system based on YAML files:

```yaml
llm:
  provider: openai
  model: gpt-4o
  api_key: ${OPENAI_API_KEY}
  temperature: 0.7

memory:
  type: persistent
  path: ./agent_memory

tools:
  browser:
    headless: true
    timeout: 30
  code:
    sandbox: true
    timeout: 10

logging:
  level: info
  file: anus.log
```

Environment variables can be used for sensitive information like API keys.

## Security Considerations

Anus AI is designed with security in mind:

- **Sandboxed Execution**: Code execution is performed in a sandboxed environment.
- **API Key Management**: Sensitive information is handled securely.
- **Permission System**: Fine-grained control over agent capabilities.
- **Audit Logging**: Comprehensive logging of all agent actions.

## Performance Optimization

Anus AI includes several performance optimizations:

- **Caching**: Results are cached to avoid redundant API calls.
- **Batching**: Requests are batched when possible to reduce API calls.
- **Streaming**: Responses are streamed for better user experience.
- **Parallel Execution**: Tasks are executed in parallel when possible.

## Extensibility

Anus AI is designed to be easily extended:

- **Plugin System**: Custom plugins can be developed to extend functionality.
- **Custom Tools**: New tools can be created by implementing the base tool interface.
- **Custom Agents**: New agent types can be created by extending the base agent class.
- **Custom Models**: Support for new models can be added by implementing the model interface.

## Future Directions

The Anus AI architecture is designed to evolve over time. Future directions include:

- **Enhanced Multi-Agent Collaboration**: More sophisticated agent interaction patterns.
- **Improved Tool Ecosystem**: Additional specialized tools for domain-specific tasks.
- **Advanced Memory Systems**: More sophisticated memory and context management.
- **Reinforcement Learning**: Integration of RL techniques for agent improvement.
- **Multimodal Capabilities**: Enhanced support for images, audio, and video.

## Conclusion

The Anus AI architecture provides a flexible, extensible, and powerful framework for building AI agent systems. By combining a modular design with a comprehensive tool ecosystem and support for multiple models, Anus AI enables a wide range of applications from simple task automation to complex multi-agent collaborations.
````

## docs/architecture.md

- Characters: 8201
- Tokens: 0

```markdown
# Anus AI Agent Architecture

## Overview
Anus (Autonomous Networked Utility System) is an open-source AI agent framework designed to provide accessible, powerful, and flexible AI assistance for a wide range of tasks. Inspired by OpenManus and OWL, Anus combines the simplicity and accessibility of OpenManus with the multi-agent collaboration capabilities of OWL to create a unique and effective AI agent system.

## Core Philosophy
- **Accessibility**: No barriers to entry, completely open-source with minimal setup requirements
- **Flexibility**: Support for multiple LLM backends and customizable components
- **Extensibility**: Modular design that allows for easy addition of new capabilities
- **Transparency**: Clear documentation and explainable AI processes
- **Community-Driven**: Designed for active community contribution and improvement

## System Architecture

### High-Level Components

1. **Core Engine**
   - Agent Orchestration System
   - Task Planning and Execution Framework
   - Memory and Context Management
   - Tool Integration Interface

2. **Agent System**
   - Single-Agent Mode
   - Multi-Agent Collaboration Mode
   - Agent Role Definition Framework
   - Inter-Agent Communication Protocol

3. **Tool Ecosystem**
   - Web Interaction Tools (Browser Automation)
   - Information Retrieval Tools (Search, Wikipedia)
   - Document Processing Tools (PDF, Word, Excel)
   - Code Execution Environment
   - Multimodal Processing (Images, Audio, Video)

4. **Model Integration**
   - OpenAI API Support
   - Open-Source Model Support (Llama, Mistral, etc.)
   - Model Switching and Fallback Mechanisms
   - Vision Model Integration

5. **User Interface**
   - Command-Line Interface
   - Web Interface (Optional)
   - API for Integration with Other Systems

### Detailed Architecture

#### Core Engine

**Agent Orchestration System**
- Manages the lifecycle of agents
- Handles agent creation, destruction, and resource allocation
- Provides monitoring and debugging capabilities

**Task Planning and Execution Framework**
- Breaks down complex tasks into manageable steps
- Assigns steps to appropriate agents or tools
- Monitors execution and handles failures
- Implements retry and recovery mechanisms

**Memory and Context Management**
- Maintains short-term and long-term memory
- Manages conversation history and context
- Implements efficient context window utilization
- Provides mechanisms for context prioritization

**Tool Integration Interface**
- Standardized API for tool integration
- Tool discovery and registration system
- Tool execution and result handling
- Security and permission management for tools

#### Agent System

**Single-Agent Mode**
- Simplified operation for straightforward tasks
- Streamlined configuration and setup
- Optimized for resource efficiency

**Multi-Agent Collaboration Mode**
- Dynamic agent creation based on task requirements
- Specialized agent roles (Researcher, Coder, Planner, etc.)
- Consensus mechanisms for decision-making
- Conflict resolution protocols

**Agent Role Definition Framework**
- Predefined role templates
- Custom role creation capabilities
- Role-specific knowledge and capabilities
- Role adaptation based on task requirements

**Inter-Agent Communication Protocol**
- Structured message format
- Conversation management
- Information sharing mechanisms
- Coordination primitives

#### Tool Ecosystem

**Web Interaction Tools**
- Browser automation using Playwright
- Web scraping and data extraction
- Form filling and submission
- Authentication handling

**Information Retrieval Tools**
- Search engine integration
- Wikipedia access
- News and current events sources
- Specialized knowledge bases

**Document Processing Tools**
- PDF parsing and analysis
- Office document handling (Word, Excel, PowerPoint)
- Image recognition and OCR
- Data extraction and transformation

**Code Execution Environment**
- Secure Python execution sandbox
- Multiple language support
- Package management
- Output capture and analysis

**Multimodal Processing**
- Image analysis and generation
- Audio processing and transcription
- Video analysis and summarization
- Chart and graph interpretation

#### Model Integration

**OpenAI API Support**
- GPT-4 and newer models
- Optimized prompt engineering
- Cost management and optimization
- Fallback mechanisms for API issues

**Open-Source Model Support**
- Integration with Hugging Face models
- Local model deployment options
- Quantization and optimization for efficiency
- Model selection based on task requirements

**Model Switching and Fallback Mechanisms**
- Automatic selection of appropriate models
- Fallback to alternative models on failure
- Performance monitoring and adaptation
- Cost-aware model selection

**Vision Model Integration**
- Image understanding capabilities
- Visual question answering
- Image generation and editing
- Multimodal reasoning

#### User Interface

**Command-Line Interface**
- Simple and intuitive commands
- Interactive mode for conversations
- Batch processing for automated tasks
- Configuration management

**Web Interface (Optional)**
- User-friendly dashboard
- Task monitoring and management
- History and conversation review
- Settings and configuration

**API for Integration**
- RESTful API for external systems
- WebSocket support for real-time applications
- Authentication and access control
- Rate limiting and usage monitoring

## Implementation Strategy

### Phase 1: Foundation
- Implement core engine with basic functionality
- Support for single-agent mode with OpenAI models
- Basic tool integration (search, code execution)
- Command-line interface

### Phase 2: Expansion
- Add multi-agent collaboration capabilities
- Expand tool ecosystem
- Integrate open-source model support
- Improve memory and context management

### Phase 3: Enhancement
- Implement advanced features (multimodal processing)
- Optimize performance and resource usage
- Add web interface
- Develop comprehensive documentation and examples

### Phase 4: Community
- Establish contribution guidelines
- Create plugin system for community extensions
- Implement feedback mechanisms
- Regular release cycle and versioning

## Unique Features of Anus AI

1. **Hybrid Agent Architecture**: Combines the simplicity of single-agent systems with the power of multi-agent collaboration.

2. **Adaptive Resource Allocation**: Dynamically allocates computational resources based on task complexity.

3. **Progressive Enhancement**: Works with minimal configuration but can scale up with additional resources and capabilities.

4. **Community-First Design**: Built from the ground up for community contributions and extensions.

5. **Transparent Operation**: Provides detailed explanations and logs of all agent actions and decisions.

6. **Cross-Platform Compatibility**: Works across different operating systems and environments.

7. **Ethical Considerations**: Built-in mechanisms for bias detection and mitigation.

8. **Privacy-Preserving Options**: Local execution capabilities for sensitive tasks.

## Comparison with Existing Systems

| Feature | Anus | OpenManus | OWL |
|---------|------|-----------|-----|
| Multi-Agent Support | ‚úÖ | ‚ùå | ‚úÖ |
| Open-Source Models | ‚úÖ | ‚úÖ | ‚úÖ |
| Browser Automation | ‚úÖ | ‚úÖ | ‚úÖ |
| Document Processing | ‚úÖ | ‚ùå | ‚úÖ |
| Code Execution | ‚úÖ | ‚úÖ | ‚úÖ |
| Local Deployment | ‚úÖ | ‚úÖ | ‚úÖ |
| Web Interface | ‚úÖ | ‚ùå | ‚ùå |
| Multimodal Support | ‚úÖ | ‚úÖ | ‚úÖ |
| Community Extensions | ‚úÖ | ‚ùå | ‚ùå |
| Ethical Framework | ‚úÖ | ‚ùå | ‚ùå |

## Technical Requirements

- Python 3.11+
- Support for various LLM APIs (OpenAI, Anthropic, etc.)
- Playwright for browser automation
- Docker support for containerized deployment
- Git for version control
- Various Python libraries for specific functionalities

## Conclusion

The Anus AI agent architecture combines the best aspects of OpenManus and OWL while introducing unique features that address limitations in both systems. By focusing on accessibility, flexibility, and community involvement, Anus aims to become a leading open-source AI agent framework that can be used for a wide range of applications, from simple task automation to complex multi-agent collaborations.
```

## docs/api_reference.md

- Characters: 7593
- Tokens: 0

````markdown
# API Reference

This document provides a comprehensive reference for the Anus AI API.

## Core Components

### Agent

The `Agent` class is the primary interface for interacting with the Anus AI system.

```python
from anus import Agent

agent = Agent(
    model="gpt-4o",
    tools=["search", "browser", "code"],
    memory_type="persistent",
    verbose=True
)
```

#### Parameters

- `model` (str, optional): The LLM model to use. Defaults to "gpt-4o".
- `tools` (list, optional): List of tools to enable. Defaults to None.
- `memory_type` (str, optional): Type of memory to use. Options: "ephemeral", "persistent". Defaults to "ephemeral".
- `verbose` (bool, optional): Whether to print verbose output. Defaults to False.
- `config` (Config, optional): Custom configuration object. Defaults to None.

#### Methods

##### run

```python
response = agent.run("Find the latest news about artificial intelligence")
```

**Parameters:**
- `task` (str): The task to execute.
- `mode` (str, optional): Execution mode. Options: "sync", "async". Defaults to "sync".
- `output_format` (str, optional): Format for the output. Options: "text", "markdown", "json". Defaults to "text".

**Returns:**
- `str`: The agent's response to the task.

##### chat

```python
response = agent.chat("What is the capital of France?")
```

**Parameters:**
- `message` (str): The message to send to the agent.
- `context` (dict, optional): Additional context for the conversation. Defaults to None.

**Returns:**
- `str`: The agent's response to the message.

##### save_memory

```python
agent.save_memory("memory.json")
```

**Parameters:**
- `path` (str): Path to save the memory to.

**Returns:**
- `bool`: True if successful, False otherwise.

##### load_memory

```python
agent.load_memory("memory.json")
```

**Parameters:**
- `path` (str): Path to load the memory from.

**Returns:**
- `bool`: True if successful, False otherwise.

### Society

The `Society` class enables multi-agent collaboration.

```python
from anus import Society, Agent

researcher = Agent(role="researcher")
analyst = Agent(role="analyst")
writer = Agent(role="writer")

society = Society(
    agents=[researcher, analyst, writer],
    coordination_strategy="consensus",
    verbose=True
)
```

#### Parameters

- `agents` (list): List of Agent objects.
- `coordination_strategy` (str, optional): Strategy for agent coordination. Options: "consensus", "hierarchical", "autonomous". Defaults to "consensus".
- `verbose` (bool, optional): Whether to print verbose output. Defaults to False.
- `config` (Config, optional): Custom configuration object. Defaults to None.

#### Methods

##### run

```python
response = society.run("Research the impact of AI on healthcare")
```

**Parameters:**
- `task` (str): The task to execute.
- `mode` (str, optional): Execution mode. Options: "sync", "async". Defaults to "sync".
- `output_format` (str, optional): Format for the output. Options: "text", "markdown", "json". Defaults to "text".

**Returns:**
- `str`: The society's response to the task.

##### add_agent

```python
society.add_agent(new_agent)
```

**Parameters:**
- `agent` (Agent): The agent to add to the society.

**Returns:**
- `bool`: True if successful, False otherwise.

##### remove_agent

```python
society.remove_agent(agent_id)
```

**Parameters:**
- `agent_id` (str): ID of the agent to remove.

**Returns:**
- `bool`: True if successful, False otherwise.

### Config

The `Config` class provides configuration options for the Anus AI system.

```python
from anus import Config

config = Config(
    llm={
        "provider": "anthropic",
        "model": "claude-3-opus",
        "temperature": 0.7,
    },
    memory={
        "type": "persistent",
        "path": "./agent_memory",
    },
    tools={
        "browser": {"headless": False},
        "code": {"sandbox": True},
    }
)
```

#### Parameters

- `llm` (dict, optional): LLM configuration.
- `memory` (dict, optional): Memory configuration.
- `tools` (dict, optional): Tool configuration.
- `ui` (dict, optional): UI configuration.
- `logging` (dict, optional): Logging configuration.

## Tools

### SearchTool

```python
from anus.tools import SearchTool

search_tool = SearchTool(
    engine="google",
    max_results=5
)
```

#### Parameters

- `engine` (str, optional): Search engine to use. Options: "google", "bing", "duckduckgo". Defaults to "google".
- `max_results` (int, optional): Maximum number of results to return. Defaults to 5.

### BrowserTool

```python
from anus.tools import BrowserTool

browser_tool = BrowserTool(
    headless=True,
    timeout=30
)
```

#### Parameters

- `headless` (bool, optional): Whether to run the browser in headless mode. Defaults to True.
- `timeout` (int, optional): Timeout in seconds for browser operations. Defaults to 30.

### DocumentTool

```python
from anus.tools import DocumentTool

document_tool = DocumentTool(
    supported_formats=["pdf", "docx", "xlsx"]
)
```

#### Parameters

- `supported_formats` (list, optional): List of supported document formats. Defaults to ["pdf", "docx", "xlsx", "pptx"].

### CodeTool

```python
from anus.tools import CodeTool

code_tool = CodeTool(
    sandbox=True,
    timeout=10
)
```

#### Parameters

- `sandbox` (bool, optional): Whether to run code in a sandbox. Defaults to True.
- `timeout` (int, optional): Timeout in seconds for code execution. Defaults to 10.

## Command-Line Interface

The Anus AI CLI provides a command-line interface for interacting with the system.

### Commands

#### run

```bash
anus run "Find the latest news about artificial intelligence"
```

**Options:**
- `--config`: Path to configuration file.
- `--mode`: Agent mode (single or multi).
- `--verbose`: Enable verbose output.
- `--output`: Output format (text, markdown, json).

#### interactive

```bash
anus interactive
```

**Options:**
- `--config`: Path to configuration file.
- `--mode`: Agent mode (single or multi).
- `--verbose`: Enable verbose output.

#### init

```bash
anus init
```

**Options:**
- `--force`: Overwrite existing configuration.
- `--minimal`: Create minimal configuration.

#### version

```bash
anus version
```

Displays the current version of Anus AI.

## Error Handling

Anus AI provides a comprehensive error handling system.

### AnusError

Base class for all Anus AI errors.

### ConfigError

Raised when there is an issue with the configuration.

### ModelError

Raised when there is an issue with the LLM model.

### ToolError

Raised when there is an issue with a tool.

### MemoryError

Raised when there is an issue with the memory system.

## Examples

### Basic Usage

```python
from anus import Agent

agent = Agent()
response = agent.run("What is the capital of France?")
print(response)
```

### Multi-Agent Collaboration

```python
from anus import Society, Agent

researcher = Agent(role="researcher")
analyst = Agent(role="analyst")
writer = Agent(role="writer")

society = Society(agents=[researcher, analyst, writer])
response = society.run("Research the impact of AI on healthcare")
print(response)
```

### Custom Configuration

```python
from anus import Agent, Config

config = Config(
    llm={
        "provider": "anthropic",
        "model": "claude-3-opus",
        "temperature": 0.7,
    },
    memory={
        "type": "persistent",
        "path": "./agent_memory",
    },
    tools={
        "browser": {"headless": False},
        "code": {"sandbox": True},
    }
)

agent = Agent(config=config)
response = agent.run("Create an interactive data visualization for climate change data")
print(response)
```
````

## docs/getting_started.md

- Characters: 3594
- Tokens: 0

````markdown
# Getting Started with Anus AI

This guide will help you get started with using the Anus AI framework for your projects.

## Prerequisites

Before you begin, ensure you have the following installed:
- Python 3.11 or higher
- pip (Python package installer)
- Git (optional, for cloning the repository)

## Installation

### Quick Installation

The easiest way to install Anus AI is via pip:

```bash
pip install anus-ai
```

### Development Installation

If you want to contribute to Anus AI or use the latest development version:

```bash
# Clone the repository
git clone https://github.com/anus-ai/anus.git
cd anus

# Create and activate a virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install in development mode
pip install -e .
```

## Configuration

After installation, you'll need to configure Anus AI with your API keys:

1. Create a configuration file:

```bash
anus init
```

2. Edit the generated `.anus/config.yaml` file with your API keys:

```yaml
llm:
  provider: openai
  api_key: your_openai_api_key
  model: gpt-4o

# Optional: Configure other providers
anthropic:
  api_key: your_anthropic_api_key
```

## Your First Anus AI Project

### Simple Question Answering

Create a file named `simple_question.py`:

```python
from anus import Agent

# Create a single agent
agent = Agent()

# Ask a simple question
response = agent.run("What is the capital of France?")
print(response)
```

Run the script:

```bash
python simple_question.py
```

### Web Search Example

Create a file named `web_search.py`:

```python
from anus import Agent
from anus.tools import SearchTool

# Create an agent with search capabilities
agent = Agent(tools=[SearchTool()])

# Search for information
response = agent.run("Find the latest research on quantum computing")
print(response)
```

Run the script:

```bash
python web_search.py
```

### Multi-Agent Collaboration

Create a file named `multi_agent.py`:

```python
from anus import Society, Agent

# Create specialized agents
researcher = Agent(role="researcher")
analyst = Agent(role="analyst")
writer = Agent(role="writer")

# Create a society of agents
society = Society(agents=[researcher, analyst, writer])

# Execute a complex task with collaboration
response = society.run(
    "Research the impact of artificial intelligence on healthcare, " 
    "analyze the findings, and write a comprehensive report"
)
print(response)
```

Run the script:

```bash
python multi_agent.py
```

## Using the Command-Line Interface

Anus AI comes with a powerful command-line interface:

```bash
# Run a simple task
anus run "What is the population of Tokyo?"

# Run in interactive mode
anus interactive

# Run with a specific configuration file
anus run --config custom_config.yaml "Summarize this article: https://example.com/article"
```

## Next Steps

- Explore the [Documentation](https://anus-ai.github.io/docs) for more detailed information
- Check out the [Examples](https://github.com/anus-ai/anus/tree/main/examples) directory for more use cases
- Join our [Community](https://discord.gg/anus-ai) to connect with other users and developers
- Consider [Contributing](https://github.com/anus-ai/anus/blob/main/CONTRIBUTING.md) to the project

## Getting Help

If you encounter any issues or have questions:

- Check the [FAQ](https://anus-ai.github.io/docs/faq)
- Search for existing [Issues](https://github.com/anus-ai/anus/issues)
- Ask for help in our [Discord](https://discord.gg/anus-ai) community
- Open a new [Issue](https://github.com/anus-ai/anus/issues/new) if you found a bug
````

## __init__.py

- Characters: 0
- Tokens: 0

```python

```

## todo.md

- Characters: 825
- Tokens: 0

```markdown
# Anus AI Project Todo List

## Research Phase
- [x] Research open-source AI agents
- [x] Analyze OpenManus repository (github.com/mannaandpoem/OpenManus)
- [x] Analyze OWL repository (github.com/camel-ai/owl)

## Design Phase
- [x] Define Anus AI agent architecture
- [x] Create project structure

## Documentation Phase
- [x] Draft README introduction
- [x] Draft README features and capabilities
- [x] Draft README installation instructions
- [x] Draft README usage examples
- [x] Draft README contribution guidelines
- [x] Draft README license information
- [x] Create project logo and badges
- [x] Finalize README.md
- [x] Create additional documentation

## Finalization Phase
- [x] Prepare GitHub repository files
- [ ] Review and refine all content
- [ ] Compile final deliverables
- [ ] Report and send files to user
```

## Statistics

- Total Files: 62
- Total Characters: 688305
- Total Tokens: 0
